{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausgewählte Kapitel sozial Webtechnologien - Neuronale Netze\n",
    "## Trainieren eines Word2Vec Modells und Darstellung von Wort- und Dokumentenvektoren anhand von Anfragetexten des FragDenStaat-Projektes\n",
    "\n",
    "Bearbeiten von:\n",
    "* Sebastian Jüngling (558556)\n",
    "* Konstantin Bruckert (558290)\n",
    "\n",
    "Prüfer:\n",
    "* Benjamin Voigt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einleitung\n",
    "Über das FragDenStaat-Portal werden Anfragen an Behörden in Deutschland gesammelt und zur Verfügung gestellt. Durch die stetig wachsende Popularität des Portals liegt diesem Projekt ein umfangreicher Datensatz vor, dessen Informationsgehalt im Laufe dieses Notebooks mithilfe eines Word2Vec Modells möglichst weit ausgeschöpft werden soll.\n",
    "\n",
    "**Grober Ablauf**<br>\n",
    "Zunächst werden die bereits bereinigten Daten für die Weiterverarbeitung aufbereitet und randomisiert. Tatsächliche Input-Daten werden daraufhin durch die Indexierung und Speicherung in Lookup-Tables generiert. Mithilfe von Context-Windows können nun Target-Label Paare aus Daten abgeleitet und für alle Sätze erzeugt werden. Das eigentliche Training innerhalb des Notebooks findet dann mithilfe eines Skip-Gram Modells statt, welches in sequenziellen Batches über mehrere Epochen hinweg die Word-Emebddings trainiert. Die daraus resultierenden Word-Embeddings können nun genutzt werden, um Dokumenten-Vektoren aufzubauen und diese oder auch einfache Wort-Vektoren dann mithilfe der Cosine-Similarity zu vergleichen. Abschließend wird versucht, die Word-Embeddings in verschieden Arten und unter Zuhilfenahme des t-SNE Dimensionsreduktionsverfahrens zu visualisieren bzw. Ähnlichkeiten zu clustern.\n",
    "\n",
    "**Grundlage/Inspiration**<br>\n",
    "Als Grundlage und grober Leitfaden für das Projekt diente das TensoFlow-Tutorial [Vector Representations of Words](https://www.tensorflow.org/tutorials/representation/word2vec). Ein Großteil der Architekturideen und Implementationsbausteine musste jedoch umgebaut werden und auf die speziellen Bedürfnisse unseres Datensatzes, als auch die Ziele der Projektarbeit angepasst werden.\n",
    "\n",
    "**Hintergrundinformationen**<br>\n",
    "Für allgemeine Hintergrundinformationen zu den einzelnen, hier im Modul angewandte Techniken und auch Details zur Entscheidungsfindung für bestimmte Ansätze, lohnt sich zudem ein Blick in das [Exposé](Documents/NN-Projekt-Expose.pdf).\n",
    "\n",
    "**Quellen**<br>\n",
    "Quellengestützte Aussagen und direkt/indirekt übernommene Inhalte sind mit einem dreistelligen Tag [XXX] versehen und können anhand diesem im Literaturverzeichnis am Ende des Notebooks eingesehen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "us2jJuCTNzou"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Für Dependency-Installation siehe README.md\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from tempfile import gettempdir\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten:\n",
    "Hier findet das Einladen des Anfragen-Katalogs des FragDenStaat-Projektes statt.  \n",
    "Die Daten wurden schon im Zuge der Werkstudententätigkeit von S. Jüngling im Vorfeld bezogen und weitestgehend aufbereitet.\n",
    "Dabei wurden die Texte auf ihre bedeutungstragenden Begriffe reduziert und die Wörter lemmatisiert.\n",
    "\n",
    "Beim Ausführen dieses Notebooks bitte darauf achten, die Daten gemäß der Anleitung in der README.md Datei herunterzuladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "id": "6jy-dki-Sbxc",
    "outputId": "19e9db64-9618-4bad-bf42-fee7bb83b4dd"
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('fds_requests_preprocessed.json', orient='records', encoding='utf-8')\n",
    "data = data.set_index('id') #set column 'id' as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "3VhuI9WkXbeH",
    "outputId": "5128ec4d-42eb-4cc7-fbab-7ed22836cf73",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>textrank</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47033</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, parkstern, berlin], [betrie...</td>\n",
       "      <td>[[parkstern, Parkstern, 1.1227777778], [berlin...</td>\n",
       "      <td>Kontrollbericht zu Parkstern, Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131943</th>\n",
       "      <td>Die Stellungnahme des BfR zur IARC- Monographi...</td>\n",
       "      <td>[[stellungnahme, bfr], [iarc, monographie, gly...</td>\n",
       "      <td>[[stellungnahme, Stellungnahme, 1.0], [bfr, Bf...</td>\n",
       "      <td>Stellungnahme des BfR zur IARC- Monographie üb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47827</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, aroma, berlin], [betriebsüb...</td>\n",
       "      <td>[[aroma, Aroma, 1.1227777778], [berlin, Berlin...</td>\n",
       "      <td>Kontrollbericht zu Aroma, Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131938</th>\n",
       "      <td>Die Stellungnahme des BfR zur IARC- Monographi...</td>\n",
       "      <td>[[stellungnahme, bfr], [iarc, monographie, gly...</td>\n",
       "      <td>[[stellungnahme, Stellungnahme, 1.0], [bfr, Bf...</td>\n",
       "      <td>Stellungnahme des BfR zur IARC- Monographie üb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48091</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht], [hans, glück, bonn], [betr...</td>\n",
       "      <td>[[bonn, Bonn, 1.2479166667000001], [hans, Hans...</td>\n",
       "      <td>Kontrollbericht zu \"Hans im Glück\", Bonn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  \\\n",
       "id                                                          \n",
       "47033   1. Wann haben die beiden letzten lebensmittelr...   \n",
       "131943  Die Stellungnahme des BfR zur IARC- Monographi...   \n",
       "47827   1. Wann haben die beiden letzten lebensmittelr...   \n",
       "131938  Die Stellungnahme des BfR zur IARC- Monographi...   \n",
       "48091   1. Wann haben die beiden letzten lebensmittelr...   \n",
       "\n",
       "                                             preprocessed  \\\n",
       "id                                                          \n",
       "47033   [[kontrollbericht, parkstern, berlin], [betrie...   \n",
       "131943  [[stellungnahme, bfr], [iarc, monographie, gly...   \n",
       "47827   [[kontrollbericht, aroma, berlin], [betriebsüb...   \n",
       "131938  [[stellungnahme, bfr], [iarc, monographie, gly...   \n",
       "48091   [[kontrollbericht], [hans, glück, bonn], [betr...   \n",
       "\n",
       "                                                 textrank  \\\n",
       "id                                                          \n",
       "47033   [[parkstern, Parkstern, 1.1227777778], [berlin...   \n",
       "131943  [[stellungnahme, Stellungnahme, 1.0], [bfr, Bf...   \n",
       "47827   [[aroma, Aroma, 1.1227777778], [berlin, Berlin...   \n",
       "131938  [[stellungnahme, Stellungnahme, 1.0], [bfr, Bf...   \n",
       "48091   [[bonn, Bonn, 1.2479166667000001], [hans, Hans...   \n",
       "\n",
       "                                                    title  \n",
       "id                                                         \n",
       "47033                Kontrollbericht zu Parkstern, Berlin  \n",
       "131943  Stellungnahme des BfR zur IARC- Monographie üb...  \n",
       "47827                    Kontrollbericht zu Aroma, Berlin  \n",
       "131938  Stellungnahme des BfR zur IARC- Monographie üb...  \n",
       "48091            Kontrollbericht zu \"Hans im Glück\", Bonn  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel für Preprocessing des Anfragetextes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titel und Description für Beispielanfrage:\n",
      "\n",
      "Kontrollbericht zu Aroma, Berlin\n",
      "1. Wann haben die beiden letzten lebensmittelrechtlichen Betriebsüberprüfungen im folgenden Betrieb stattgefunden:\r\n",
      "Aroma\r\n",
      "Kantstraße\r\n",
      "10625 Berlin\r\n",
      "\r\n",
      "2. Kam es hierbei zu Beanstandungen? Falls ja, beantrage ich hiermit die Herausgabe des entsprechenden Kontrollberichts an mich.\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Preprocessed Anfragetext für Titel und Anfragetext:\n",
      "\n",
      "[['kontrollbericht', 'aroma', 'berlin'], ['betriebsüberprüfungen', 'betrieb'], ['aroma', 'kantstraße', 'berlin'], ['beanstandung'], ['herausgabe', 'kontrollberichts']]\n"
     ]
    }
   ],
   "source": [
    "print('Titel und Description für Beispielanfrage:\\n')\n",
    "print(data.loc[47827]['title'])\n",
    "print(data.loc[47827]['description'])\n",
    "\n",
    "print('-------------------------------------------------------------------------')\n",
    "\n",
    "print('\\nPreprocessed Anfragetext für Titel und Anfragetext:\\n')\n",
    "print(data.loc[47827]['preprocessed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduzierung der Anzahl der Anfragen zu Glyphosat\n",
    "Immer wieder kommt es bei FragDenStaat zu einer Häufung tagespolitischer Themen, wie z.B. die Fragen rund um das Thema Glyphosat. Seit März 2019 sind hierzu bereits mehr als 30.000 Anfragen eingegangen, welche anhand eines immer gleichen Musters ausformuliert werden und somit das Training der globalen Datenmenge zu stark beeinflussen. Zur Reduzierung dieses Einflusses werden die Anfragen zu diesem Thema bei 3000 gedeckelt.\n",
    "Um auch in Zukunft und ggf. bei der Nutzung andersartiger Datensätze einwandfreie Ergebnisse zu erzielen, sollte regelmäßig geprüft werden, ob die Daten von einem bestimmten Thema dominiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Anfragen zu Glyphosat: 36199 von insgesamt: 92374 Anfragen\n",
      "Anzahl der Anfragen zu Glyphosat nach Bereinigung: 3000 von insgesamt: 59175 Anfragen\n"
     ]
    }
   ],
   "source": [
    "glyphosat_title = 'Stellungnahme des BfR zur IARC- Monographie über Glyphosat'\n",
    "glyphosat_ids = data[data['title'] == glyphosat_title].index\n",
    "\n",
    "print('Anzahl der Anfragen zu Glyphosat:', len(glyphosat_ids), 'von insgesamt:', len(data), 'Anfragen')\n",
    "\n",
    "# Da dies alle gleiche Anfragen sind und diese hohe Anzahl den Trainingsprozess verfälschen würde, \n",
    "# wird die Anzahl der Anfragen zu Glyphosat auf 3000 beschränkt\n",
    "remain_glyphosat_requests = 3000\n",
    "data.drop(glyphosat_ids[remain_glyphosat_requests:], inplace=True) # drop by id\n",
    "\n",
    "print('Anzahl der Anfragen zu Glyphosat nach Bereinigung:', len(data[data['title'] == glyphosat_title]), 'von insgesamt:', len(data), 'Anfragen')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Data:\n",
    "Während des Trainings mit den Daten konnte trotz der sorgfältigen Beseitigung dominanter Themen immer noch eine überproportionale Gewichtung der Glyphosat-Themen festgestellt werden. Das Problem lag hierbei im chronologisch vorliegenden Datensatz, welcher eine natürliche, große Abfolge von gleichen Themen nacheinander besitzt. Um die Word-Embeddings dadurch nicht zu stark in eine Richtung zu trainieren, werden die Anfragen randomisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>textrank</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30037</th>\n",
       "      <td>Sämtliche Einsatzprotokolle der Sicherungsgrup...</td>\n",
       "      <td>[[einsatzprotokolle, übergriff, kriminalpolize...</td>\n",
       "      <td>[[jugendwohngruppe, Jugendwohngruppe, 1.369075...</td>\n",
       "      <td>Einsatzprotokolle von Übergriff der Berliner K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41614</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, schützenhof, eitorf], [betr...</td>\n",
       "      <td>[[schützenhof, Schützenhof, 1.3868680556], [wi...</td>\n",
       "      <td>Kontrollbericht zu Schützenhof, Eitorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9663</th>\n",
       "      <td>ich bitte um eine Übersicht der aktuellen Krip...</td>\n",
       "      <td>[[kita-gebühren, verbandsgemeinde], [übersicht...</td>\n",
       "      <td>[[verbandsgemeinde, Verbandsgemeinden, 1.24791...</td>\n",
       "      <td>Übersicht über die Kita-Gebühren in den einzel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>In verschiedenen Quellen wird die Weitergabe v...</td>\n",
       "      <td>[[weitergabe, daten/akten, behörde], [quell, w...</td>\n",
       "      <td>[[behörde, Behörden, 2.8602611613], [informati...</td>\n",
       "      <td>Weitergabe von Daten/Akten an andere Behörden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>Bitte übersenden Sie folgende Informationen zu...</td>\n",
       "      <td>[[information, abendessen, herr, ackermann, ap...</td>\n",
       "      <td>[[abendessen, Abendessen, 2.0533034722], [urte...</td>\n",
       "      <td>Informationen zu Abendessen mit Herrn Ackerman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "id                                                         \n",
       "30037  Sämtliche Einsatzprotokolle der Sicherungsgrup...   \n",
       "41614  1. Wann haben die beiden letzten lebensmittelr...   \n",
       "9663   ich bitte um eine Übersicht der aktuellen Krip...   \n",
       "2536   In verschiedenen Quellen wird die Weitergabe v...   \n",
       "1333   Bitte übersenden Sie folgende Informationen zu...   \n",
       "\n",
       "                                            preprocessed  \\\n",
       "id                                                         \n",
       "30037  [[einsatzprotokolle, übergriff, kriminalpolize...   \n",
       "41614  [[kontrollbericht, schützenhof, eitorf], [betr...   \n",
       "9663   [[kita-gebühren, verbandsgemeinde], [übersicht...   \n",
       "2536   [[weitergabe, daten/akten, behörde], [quell, w...   \n",
       "1333   [[information, abendessen, herr, ackermann, ap...   \n",
       "\n",
       "                                                textrank  \\\n",
       "id                                                         \n",
       "30037  [[jugendwohngruppe, Jugendwohngruppe, 1.369075...   \n",
       "41614  [[schützenhof, Schützenhof, 1.3868680556], [wi...   \n",
       "9663   [[verbandsgemeinde, Verbandsgemeinden, 1.24791...   \n",
       "2536   [[behörde, Behörden, 2.8602611613], [informati...   \n",
       "1333   [[abendessen, Abendessen, 2.0533034722], [urte...   \n",
       "\n",
       "                                                   title  \n",
       "id                                                        \n",
       "30037  Einsatzprotokolle von Übergriff der Berliner K...  \n",
       "41614             Kontrollbericht zu Schützenhof, Eitorf  \n",
       "9663   Übersicht über die Kita-Gebühren in den einzel...  \n",
       "2536       Weitergabe von Daten/Akten an andere Behörden  \n",
       "1333   Informationen zu Abendessen mit Herrn Ackerman...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input-Daten generieren:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten aufbereiten\n",
    "Für die späteren Bearbeitungsschritte müssen die vorliegenden Anfragen aufbereitet und um Metainformationen erweitert werden.  \n",
    "Besonders die Indizierung der benutzten Wörter und das Erstellen entsprechender Lookup-Tables spielt im weiteren Verlauf des Notebooks eine vitale Rolle. \n",
    "Mit den daraus gewonnenen Wort-Indizes werden die Sätze der Anfragetexte nachgebaut. Für das Training wird außerdem die Gesamtanzahl der einzigartigen Wörter in allen Anfragetexten benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nxCqoQSTYBn"
   },
   "outputs": [],
   "source": [
    "def build_lookup_tables(docs, vocabulary_size=None):\n",
    "    '''\n",
    "    :param docs: Spalte eines pandas-DF: data['preprocessed'].values\n",
    "    :return sentences: Alle Sätze aller Dokumente in einer Liste\n",
    "    :return words: Alle Wörter aller Dokumente in einer Liste\n",
    "    :return word_count: Häufigkeiten der jeweiligen Wörter in allen Dokumenten\n",
    "    :return word_2_index_dict: Lookup-Table\n",
    "    :return index_2_word_dict: Lookup-Table\n",
    "    :return sentences_as_index: Alle Sätze aller Dokumente mit Wortindex, anstatt des Wortes\n",
    "    :return sentences_as_index_flattened: wie sentences_as_index, aber ohne subarrays (flattened)\n",
    "    :return vocabulary_size: Anzahl der einzigartigen Wörter\n",
    "    '''\n",
    "    sentences = [sent for pd_list in docs for sent in pd_list]\n",
    "    words = [word for sent in sentences for word in sent]\n",
    "  \n",
    "    if not vocabulary_size:\n",
    "        # Anzahl der einzigartigen Wörter\n",
    "        vocabulary_size = len(set(words))\n",
    " \n",
    "    # Anzahl der Worthäufigkeiten\n",
    "    word_count = collections.Counter(words).most_common(vocabulary_size)\n",
    "    word_count.append(['UNK', -1]) # Flag für Wörter, die nicht oft vorkommen (nur wichtig bei begrenzter Vokabulargröße)\n",
    "  \n",
    "    # Lookup-Tables\n",
    "    word_2_index_dict = {}\n",
    "    for index, word in enumerate(word_count):\n",
    "        word_2_index_dict[word[0]] = index\n",
    "  \n",
    "    index_2_word_dict = dict(zip(word_2_index_dict.values(), word_2_index_dict.keys()))\n",
    "  \n",
    "    # Wörter der Anfragetexte durch Indizes austauschen:\n",
    "    sentences_as_index = []\n",
    "    unknown_word_count = 0\n",
    "    for sent in sentences:\n",
    "        sent_index = []\n",
    "        for word in sent:\n",
    "            if word in word_2_index_dict:\n",
    "                sent_index.append(word_2_index_dict[word])\n",
    "            else:\n",
    "                unknown_word_count += 1\n",
    "        if sent_index:\n",
    "            sentences_as_index.append(sent_index)\n",
    "    word_count[-1][1] = unknown_word_count\n",
    "\n",
    "    sentences_as_index_flattened = [word for sent in sentences_as_index for word in sent]\n",
    "  \n",
    "    return sentences, words, word_count, word_2_index_dict, index_2_word_dict, sentences_as_index, sentences_as_index_flattened, vocabulary_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2axsWl9ii25H"
   },
   "outputs": [],
   "source": [
    "sentences, words, word_count, word_2_index_dict, index_2_word_dict, sentences_as_index, sentences_as_index_flattened, vocabulary_size = build_lookup_tables(data['preprocessed'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiele:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Sätze der Anfragetexte in einer Liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "htJa8Opejkgl",
    "outputId": "592c135e-96e3-4ae4-c706-0b372efaee26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['einsatzprotokolle', 'übergriff', 'kriminalpolizei', 'jugendwohngruppe'],\n",
       " ['einsatzprotokolle',\n",
       "  'sicherungsgruppe',\n",
       "  'kriminalpolizei',\n",
       "  'mai',\n",
       "  'jugendwohngruppe',\n",
       "  'verband',\n",
       "  'geflüchteter'],\n",
       " ['kontrollbericht', 'schützenhof', 'eitorf'],\n",
       " ['betriebsüberprüfungen',\n",
       "  'betrieb',\n",
       "  'schützenhof',\n",
       "  'windecker',\n",
       "  'straße',\n",
       "  'eitorf'],\n",
       " ['beanstandung']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Wörter aller Anfragetexte chronologisch in einer Liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CC0x0bS2jk93",
    "outputId": "7658adac-e306-4c36-c37b-73b83cd2fa77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['einsatzprotokolle',\n",
       " 'übergriff',\n",
       " 'kriminalpolizei',\n",
       " 'jugendwohngruppe',\n",
       " 'einsatzprotokolle']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzahl der Worthäufigkeiten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "o7AXFIVPjlPc",
    "outputId": "40571fd8-1d1a-4008-c7a3-2bc918fe47dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('betrieb', 24351),\n",
       " ('herausgabe', 24007),\n",
       " ('kontrollbericht', 23946),\n",
       " ('beanstandung', 23880),\n",
       " ('betriebsüberprüfungen', 23782)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wort zu Wortindex Lookup-Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "uYVuDGdRjlin",
    "outputId": "a2c897db-6785-478f-8d9f-fcaa4f980c49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'betrieb': 0,\n",
       " 'herausgabe': 1,\n",
       " 'kontrollbericht': 2,\n",
       " 'beanstandung': 3,\n",
       " 'betriebsüberprüfungen': 4,\n",
       " 'kontrollberichts': 5,\n",
       " 'dokument': 6,\n",
       " 'information': 7,\n",
       " 'abs.': 8,\n",
       " 'stellungnahme': 9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_2_index_dict\n",
    "# nur für Anschauungszwecke (erste 10 Key-Value-Paaare):\n",
    "{k: word_2_index_dict[k] for k in list(word_2_index_dict)[:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wortindex zu Wort Lookup-Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "2ZhDExldjlzf",
    "outputId": "f71b8bb2-bbbd-477c-b86e-5c9b8c4f4316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'betrieb',\n",
       " 1: 'herausgabe',\n",
       " 2: 'kontrollbericht',\n",
       " 3: 'beanstandung',\n",
       " 4: 'betriebsüberprüfungen',\n",
       " 5: 'kontrollberichts',\n",
       " 6: 'dokument',\n",
       " 7: 'information',\n",
       " 8: 'abs.',\n",
       " 9: 'stellungnahme'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index_2_word_dict\n",
    "# nur für Anschauungszwecke (erste 10 Key-Value-Paaare):\n",
    "{k: index_2_word_dict[k] for k in list(index_2_word_dict)[:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Wörter in allen Anfragesätzen ausgetauscht durch den jeweiligen Wortindex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "xjRpEGCGkHud",
    "outputId": "023dd201-62d0-4556-b4f9-c903648f7778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13598, 2349, 13599, 29978],\n",
       " [13598, 53908, 13599, 453, 29978, 272, 3883],\n",
       " [2, 13600, 10080],\n",
       " [4, 0, 13600, 53909, 24, 10080],\n",
       " [3]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_as_index[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Wörter aller Anfragetexte chronologisch in einer Liste, ausgetauscht durch den Wortindex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pnrYmbeJMVpm",
    "outputId": "825ce233-a7f8-4b29-b506-e1b878de3bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13598, 2349, 13599, 29978, 13598, 53908, 13599, 453, 29978, 272]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_as_index_flattened[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzahl aller einzigartigen Wörter aus allen Anfragetexten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mDjh9g9Tk5WS",
    "outputId": "36a24c11-c75f-4bfc-a283-b5fd71bbf659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95602"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Input-)Target-Wörter mit entsprechenden Labels aus Daten ableiten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Embeddings\n",
    "Essenziell für die folgenden Schritte ist ein generelles Verständnis von Word-Embeddings. Ein Wort kann als ein Vektor mit einer beliebigen Anzahl von Features dargestellt werden. Die voreingestellten Parameter dieses Notebooks arbeiten mit 300 Features (Vektordimension).\n",
    "Vergleichen wir beispielsweise die Word-Embeddings der Wörter \"Hund\" und \"Katze\", so werden bestimmte Features innerhalb der beiden Vektoren eine Ähnlichkeit haben, u.a. an der Stelle wo das Modell die Kategorie \"Tier\" trainiert hat. Anhand eines Beispiels, in dem die Word-Embedding Values mit Farben je nach Wert ersetzt wurden, lässt sich dieses Prinzip gut veranschaulichen:\n",
    "\n",
    "<img src=\"Images/king-man-woman-embedding.png\" alt=\"drawing\" width=\"500\"/>\n",
    "Quelle: [WED]\n",
    "\n",
    "\n",
    "### Language Modelling\n",
    "Je nach Ansatz ist es das Ziel eines Language Modells, für ein gegebenes Wort möglichst Präzise Vorhersagen zu treffen, welches Wort darauf folgen könnte (CBOW) oder anhand eines Wortes die umgebenden Wörter vorherzusagen (Skip-Gram). Anhand der im vorherigen Abschnitt erstellten Word-Embeddings können wir einzelne Wörter oder ganze Sätze leicht vergleichen und prüfen, ob Sie in einem kontextuellen Zusammenhang stehen. \n",
    "\n",
    "### Skip-Gram Model und Context-Windows\n",
    "Folgende Abbildung skizziert die generelle Architektur eines Skip-Gram Modells:\n",
    "\n",
    "<img src=\"Images/skip_gram_net_architecuture.png\" alt=\"drawing\" width=\"600\"/>\n",
    "Quelle: [SAM]\n",
    "\n",
    "Im Notebook kommt es jedoch zu einigen Abweichungen von der Standard-Architektur, insbesondere bei der Klassifikation/Loss-Funktion (siehe folgende Kapitel: NCE). <br>\n",
    "\n",
    "Natürlich muss ein solches Language-Modell zunächst ausgiebig trainiert werden. Mittels Context-Windows, also ein Ausschnitt von umgebenden Wörtern, versuchen wir Wort-Paare aus Target- und Label-Wörtern zu erstellen, die häufig zusammen auftreten. Angenommen wir nutzen Window-Size=2, dann betrachten wir an jedem Wort eines Satzes die zwei Wörter (\"labels\") vor und nach dem fokussierten Wort (\"target\") und notieren dieses gemeinsame Auftreten. In folgendem Beispiel wird die Context-Window Methode an einem Skip-Gram Modell dargestellt. Blau markierte Target-Wörter (Input) mit den entsprechenden Labels, abhängig von der Window-Size, gespeichert als Target-Label Paare (Tupel).\n",
    "\n",
    "<img src=\"Images/skipgram-sliding-window-samples.png\" alt=\"drawing\" width=\"400\"/>\n",
    "Quelle: [SWS]\n",
    "\n",
    "Context-Windows arbeiten mit einzelnen Sätzen und beim Beginn und Ende eines jeden Satzes muss zudem darauf geachtet werden, dass mit dem Window nicht vor oder nach dem Satz geslided wird. Die folgende Implementierung erzeugt nun die Target-Label Paare, wobei anstelle realer Wörter im weiteren Verlauf die Wort-Indizes verwendet werden (siehe Beispiel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-0DEefWVVgF"
   },
   "outputs": [],
   "source": [
    "def get_context_window(input_data, target_index, window_size):\n",
    "    '''\n",
    "    Ermittelt umgebene Wörter abhängig von window_size und target_index des Wortes\n",
    "    :param input_data: Liste mit Wortindizes\n",
    "    :param: target_index: Listenindex des jeweiligen Wortes\n",
    "    :param window_size: Anzahl der Wörter links und rechts des target wortes\n",
    "    :return target value und liste der umgebenen Wörter\n",
    "    '''\n",
    "  \n",
    "    left_start_index = target_index - window_size if (target_index - window_size) >= 0 else 0\n",
    "  \n",
    "    right_start_index = target_index + 1\n",
    "    right_stop_index = target_index + window_size + 1\n",
    "  \n",
    "    target = input_data[target_index]\n",
    "    left_window = input_data[left_start_index:target_index]\n",
    "    right_window = input_data[right_start_index:right_stop_index]\n",
    "  \n",
    "    return target, left_window + right_window\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "tL2BjvxTXoHm",
    "outputId": "8209c344-3151-4a41-dea8-5b03b38096e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispielsatz aus Indizes: [0, 1, 2, 3, 4, 5]\n",
      "\n",
      "Target-Wort für Index: 0\n",
      "Context-Wörter für window_size 2: [1, 2]\n",
      "\n",
      "Target-Wort für Index:: 2\n",
      "Context-Wörter für window_size 2: [0, 1, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "input_data = list(range(6))\n",
    "print('Beispielsatz aus Indizes:', input_data)\n",
    "print()\n",
    "\n",
    "target_word_index, context_words = get_context_window(input_data, 0, 2)\n",
    "print('Target-Wort für Index:', target_word_index)\n",
    "print('Context-Wörter für window_size 2:', context_words)\n",
    "\n",
    "target_word_index, context_words = get_context_window(input_data, 2, 2)\n",
    "print('\\nTarget-Wort für Index::', target_word_index)\n",
    "print('Context-Wörter für window_size 2:', context_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generiere Target-Wortliste mit entsprechenden Wortkontexten für alle Sätze der Anfragetexte:\n",
    "Nach den Beispielen kann die Context-Window Funktion nun auf alle Sätze in den Input-Daten angewandt werden. Weitere Beispiele mit Ausschnitten aus dem Gesamtdatenbestand bieten zudem zur besseren Veranschaulichung ein Re-Mapping der Word-Indexe auf die realen Wörter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-3OJiQbbPw1"
   },
   "outputs": [],
   "source": [
    "def build_targets_and_labels(input_data, window_size):\n",
    "    '''\n",
    "    Ermittelt alle Targets und Labels abhängig von der window_size\n",
    "    :param input_data: Liste mit Sublisten (Sätze)\n",
    "    :param window_size: Anzahl der Wörter links und rechts des target wortes\n",
    "    :return targets: Liste aller Targetwörter\n",
    "    :return labels: Liste aller Labels zu jeweiligem Targetwort\n",
    "    '''\n",
    "    targets = []\n",
    "    labels = []\n",
    "    for sent in input_data:\n",
    "        for index, word in enumerate(sent):\n",
    "            target_word_index, context_words = get_context_window(sent, index, window_size)\n",
    "            for context_word in context_words:\n",
    "                targets.append(target_word_index)\n",
    "                labels.append(context_word)\n",
    "    return targets, labels\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "t6nlmt7jgwj3",
    "outputId": "3b343462-481e-42c3-c52b-4dfb6d457db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die ersten drei Beispielsätze mit Wortinidizes:\n",
      " [[13598, 2349, 13599, 29978], [13598, 53908, 13599, 453, 29978, 272, 3883], [2, 13600, 10080]] \n",
      "\n",
      "Target Wortindizes: \n",
      " [13598, 13598, 2349, 2349, 2349, 13599, 13599, 13599, 29978, 29978, 13598, 13598, 53908, 53908, 53908, 13599, 13599, 13599, 13599, 453, 453, 453, 453, 29978, 29978, 29978, 29978, 272, 272, 272, 3883, 3883, 2, 2, 13600, 13600, 10080, 10080]\n",
      "Label Wortindizes: \n",
      " [2349, 13599, 13598, 13599, 29978, 13598, 2349, 29978, 2349, 13599, 53908, 13599, 13598, 13599, 453, 13598, 53908, 453, 29978, 53908, 13599, 29978, 272, 13599, 453, 272, 3883, 453, 29978, 3883, 29978, 272, 13600, 10080, 2, 10080, 2, 13600]\n",
      "\n",
      "Beispiel für Mapping der Wortinindizes der Target und Label-Liste:\n",
      "13598 einsatzprotokolle -> 2349 übergriff\n",
      "13598 einsatzprotokolle -> 13599 kriminalpolizei\n",
      "2349 übergriff -> 13598 einsatzprotokolle\n",
      "2349 übergriff -> 13599 kriminalpolizei\n",
      "2349 übergriff -> 29978 jugendwohngruppe\n",
      "13599 kriminalpolizei -> 13598 einsatzprotokolle\n",
      "13599 kriminalpolizei -> 2349 übergriff\n",
      "13599 kriminalpolizei -> 29978 jugendwohngruppe\n",
      "29978 jugendwohngruppe -> 2349 übergriff\n",
      "29978 jugendwohngruppe -> 13599 kriminalpolizei\n",
      "13598 einsatzprotokolle -> 53908 sicherungsgruppe\n",
      "13598 einsatzprotokolle -> 13599 kriminalpolizei\n",
      "53908 sicherungsgruppe -> 13598 einsatzprotokolle\n",
      "53908 sicherungsgruppe -> 13599 kriminalpolizei\n",
      "53908 sicherungsgruppe -> 453 mai\n",
      "13599 kriminalpolizei -> 13598 einsatzprotokolle\n",
      "13599 kriminalpolizei -> 53908 sicherungsgruppe\n",
      "13599 kriminalpolizei -> 453 mai\n",
      "13599 kriminalpolizei -> 29978 jugendwohngruppe\n",
      "453 mai -> 53908 sicherungsgruppe\n",
      "453 mai -> 13599 kriminalpolizei\n",
      "453 mai -> 29978 jugendwohngruppe\n",
      "453 mai -> 272 verband\n",
      "29978 jugendwohngruppe -> 13599 kriminalpolizei\n",
      "29978 jugendwohngruppe -> 453 mai\n",
      "29978 jugendwohngruppe -> 272 verband\n",
      "29978 jugendwohngruppe -> 3883 geflüchteter\n",
      "272 verband -> 453 mai\n",
      "272 verband -> 29978 jugendwohngruppe\n",
      "272 verband -> 3883 geflüchteter\n",
      "3883 geflüchteter -> 29978 jugendwohngruppe\n",
      "3883 geflüchteter -> 272 verband\n",
      "2 kontrollbericht -> 13600 schützenhof\n",
      "2 kontrollbericht -> 10080 eitorf\n",
      "13600 schützenhof -> 2 kontrollbericht\n",
      "13600 schützenhof -> 10080 eitorf\n",
      "10080 eitorf -> 2 kontrollbericht\n",
      "10080 eitorf -> 13600 schützenhof\n"
     ]
    }
   ],
   "source": [
    "input_data = sentences_as_index[:3]\n",
    "print('Die ersten drei Beispielsätze mit Wortinidizes:\\n', input_data, '\\n')\n",
    "\n",
    "targets_list, labels_list = build_targets_and_labels(input_data, window_size=2)\n",
    "print('Target Wortindizes: \\n', targets_list)\n",
    "print('Label Wortindizes: \\n', labels_list)\n",
    "\n",
    "print('\\nBeispiel für Mapping der Wortinindizes der Target und Label-Liste:')\n",
    "for i in range(len(targets_list)):\n",
    "    print(targets_list[i], index_2_word_dict[targets_list[i]], '->', labels_list[i], index_2_word_dict[labels_list[i]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generiere Trainings-Batch:\n",
    "Folgende Hilfsfunktion generiert iterativ Teilsequenzen (Batches) aus den Target-Label Paaren. Im Return der Funktion ist ein einzelner Batch und mithilfe der Variable `data_index` wird die aktuelle Iterationsposition im Gesamtdatensatz zwischengespeichert und resetted, sobald das Ende des Gesamtdatensatzes erreicht wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yiUq2UkhBtA"
   },
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "def generate_batch(batch_size, targets_list, labels_list):\n",
    "    '''\n",
    "    Generiert den Trainigs-Batch\n",
    "    :return batch: Liste mit Target-Indizes\n",
    "    :return labels: Liste mit Label-Indizes, zugehörig zu Target an gleicher Position in batch\n",
    "    '''\n",
    "    global data_index\n",
    "    if data_index + batch_size > len(targets_list):\n",
    "        data_index = 0\n",
    "    batch = np.array(targets_list[data_index:data_index + batch_size], dtype=np.int32)\n",
    "    labels = np.array(labels_list[data_index:data_index + batch_size], dtype=np.int32)[:, np.newaxis]\n",
    "    data_index += batch_size\n",
    "  \n",
    "    return batch, labels\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel für batch_size = 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "iUXnETiMiERm",
    "outputId": "e2299c78-fe77-423f-da90-a9691a4bd611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Indizes:\n",
      "[13598 13598  2349  2349  2349 13599 13599 13599]\n",
      "\n",
      "Label Indizes\n",
      "[[ 2349]\n",
      " [13599]\n",
      " [13598]\n",
      " [13599]\n",
      " [29978]\n",
      " [13598]\n",
      " [ 2349]\n",
      " [29978]]\n",
      "\n",
      "Beispiel für Mapping der Wortinindizes der Target und Label-liste:\n",
      "13598 einsatzprotokolle -> 2349 übergriff\n",
      "13598 einsatzprotokolle -> 13599 kriminalpolizei\n",
      "2349 übergriff -> 13598 einsatzprotokolle\n",
      "2349 übergriff -> 13599 kriminalpolizei\n",
      "2349 übergriff -> 29978 jugendwohngruppe\n",
      "13599 kriminalpolizei -> 13598 einsatzprotokolle\n",
      "13599 kriminalpolizei -> 2349 übergriff\n",
      "13599 kriminalpolizei -> 29978 jugendwohngruppe\n"
     ]
    }
   ],
   "source": [
    "batch, labels = generate_batch(8, targets_list, labels_list)\n",
    "print('Target Indizes:')\n",
    "print(batch)\n",
    "\n",
    "print('\\nLabel Indizes')\n",
    "print(labels)\n",
    "\n",
    "print('\\nBeispiel für Mapping der Wortinindizes der Target und Label-liste:')\n",
    "for i in range(len(batch)):\n",
    "    print(batch[i], index_2_word_dict[batch[i]], '->', labels[i, 0], index_2_word_dict[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baue und Trainiere das Skip-Gram Modell\n",
    "Bis hierhin sollte klar sein was die Funktion eines Skip-Gram Models und deren Target-Label Paaren, eines Context-Window und eines Batches ist. Mit diesem Wissen steht dem eigentlichen Model-Training nichts mehr im Wege! Fast. Vor dem Training bietet sich zunächst die letzte Möglichkeit, mit einstellbaren Parametern Einfluss auf den Verlauf des Trainings zu nehmen. Neben den bereits bekannten Begriffen müssen noch ein paar wenige, neue Parameter verstanden und eingestellt werden, die einen erheblichen Einfluss auf den weiteren Trainingsverlauf ausüben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstellbare Parameter:\n",
    "\n",
    "* `batch_size`: Anzahl der berücksichtigten Target-Label Paare pro Trainingsiteration\n",
    "* `embedding_size`: Dimensionsgröße der Word-Embeddings \n",
    "    * -> Wert von 300 zeigt sich als guter Kompromiss von Performance und Genauigkeit\n",
    "* `window_size`: Anzahl der berüchtigten Wörter links und rechts (Nachbarwörter) eines Targetwortes für Bildung der Target-Label Paare\n",
    "* `negative_samples` Anzahl der Negative Samples für NCE Loss (siehe weiter unten)\n",
    "* Anpassung der sich exponentiell verringerten Lernrate (Start-/End-Learning-Rate)\n",
    "* `epochs`: Anzahl der Epochen, also Anzahl der Iterationen die benötigt werden, um einmal alle Target-Label Paare zu durchlaufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVj4YN6KTK40"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "embedding_size = 300 # Dimension der Word-Embeddings\n",
    "window_size = 2  # Anzahl der Wörter links und rechts vom Target-Wort\n",
    "negative_samples = 64 # Anzahl der negative samples\n",
    "\n",
    "# Die Lernrate wird je Iteration verringert:\n",
    "starter_learning_rate = 1.0\n",
    "end_learning_rate = 0.1\n",
    "\n",
    "epochs = 6 # Anzahl der Epochen. Eine Epoche ist eine Iteration durch den kompletten Trainingsbestand\n",
    "print_every_x_step = 2000 # alle x Iterationen werden infos geprintet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generieren der Target- und Labelliste für alle Anfragetexte, basierend auf der eingestellten Window-Size:\n",
    "\n",
    "Zu Beginn des Trainings werden nun alle Target-Label Paare aller Anfragetexte des Gesamtdatenbestandes aufgrund der im vorherigen Schritt eingestellten Window-Size generiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_list, labels_list = build_targets_and_labels(sentences_as_index, window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es folgen einige Berechnungen für wichtige, fixe Parameter, die aus den einstellbaren Parametern abgeleitet werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Target-Label-Paare: 3099230\n",
      "24213 Iterationen werden benötigt um einmal während des Trainings durch alle Target-Label Paare zu iterieren\n",
      "Iterationen während des Trainings: 145278\n"
     ]
    }
   ],
   "source": [
    "data_index = 0 # für batch start\n",
    "\n",
    "exp_decay_lr = starter_learning_rate - end_learning_rate\n",
    "\n",
    "input_length = len(targets_list) # Anzahl der Target-Label-Paare\n",
    "print('Anzahl Target-Label-Paare:', input_length)\n",
    "\n",
    "full_iteration_cycle = int(math.ceil(input_length / batch_size))\n",
    "print(full_iteration_cycle, 'Iterationen werden benötigt um einmal während des Trainings durch alle Target-Label Paare zu iterieren')\n",
    "\n",
    "num_steps = full_iteration_cycle * epochs\n",
    "print('Iterationen während des Trainings:', num_steps)\n",
    "\n",
    "epsilon=1e-12 # dont touch -> vermeidet Division mit Null bei Normalisierung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Graph:\n",
    "\n",
    "Mit eingestellten Parametern und allen generierten Target-Label Paaren der Anfragetexte kann nun die Modellarchitektur festgelegt werden. Zunächst werden Tensorflow Placeholder definiert und dann die Word-Embedings (Anzahl einzigartiger Wörter x Anzahl Features/Dimension) mit einem random Wert zwischen 0 und 1 initialisiert. Auf die gleiche Weiße erhalten auch unsere NCE-Weights (Erklärung folgt) initiale Werte. Der Bias wird mit Nullen initialisiert. Bereits im vorherigen Schritt wurde die Start-Lernrate errechnet (delta aus maximal- und minimal-Lernrate), welche nun in der Modell-Architektur in eine exponential-decay Funktion gepackt wird und somit im späteren Training evolutionär angepasst werden kann. Für die komplette Trainingsarchitektur fehlt jetzt nur noch ein(e) Klassifizierungsverfahren/Loss-Funktion.\n",
    "\n",
    "## Noise Contrastive estimation (NCE)\n",
    "\n",
    "Remember: Für ein gegebenes Wort (Target) soll das Modell die Wahrscheinlichkeit der passenden Kontextwörter (Labels) bestimmen. Ein weitverbreitetes und erfahrungsgemäß gutes Klassifizierungsverfahren hierfür ist der Softmax-Classifier. Dieser stellte sich aber während des Trainings als maximal rechenintensiv heraus, da für jedes Wort das ganze Vokabular (mehr als 1 Mio Wörter) mit Wahrscheinlichkeiten belegt werden muss, bzw. die Gewichtsmatrix `[embedding_dim x vocab_dim]` sehr groß ist ([Wiederholung: Softmax-Klassifier](https://www.pyimagesearch.com/2016/09/12/softmax-classifiers-explained/), [Hintergrundwissen: Warum kein Softmax?](https://arxiv.org/pdf/1410.8251.pdf))\n",
    "\n",
    "Um diese Rechenoperation zu vermeiden, aber trotzdem keine spürbaren Einbußen beim Training der Word-Emebdings zu erleiden, kann der NCE-Loss genutzt werden. Hierbei wird das Gesamtvokabular, also die Menge an Wörtern die auf Ähnlichkeit überprüft werden, auf einen Teil mit dem/den passenden Label/n und einen Teil mit gänzlich unpassenden Wörtern (\"Contrastive Noise\") reduziert. Zudem wird die Vorhersage auf ein Klassifikationsproblem (richtig/falsch) reduziert (vgl. Softmax: Normalverteilt), (korrekte) Labels und (gegensätzliche) Noise bekommen also die Werte 0 und 1. Das Modell kann somit anhand sehr guter und schlechter Begriffe lernen, ohne dabei jedes Mal das gesamte Vokabular durchforsten zu müssen. Hierin liegt zugleich der entscheidende Punkt bei NCE: Wir können unsere Noise-Verteilung frei bestimmen, z.B. können nur Wörter mit ganz geringer Häufigkeit, alle Wörter mit gleicher Wahrscheinlichkeit oder einfach eine Normalverteilung selektiert werden. Durch diese künstliche Reduzierung der Grunddatenmenge wird jedoch nicht die Genauigkeit des Models in Mitleidenschaft gezogen (QUELLE: [NCE]). \n",
    "Da das Problem bereits auf eine klassische \"Richtig oder Falsch\"-Frage reduziert wurde, kann in NCE die logistische Regression zur Klassifikation herangezogen werden und dann unsere Word-Embeddings mit dem GradientDescentOptimizer optimiert werden. Eine weiterführende Erklärung mit detaillierten Hintergrundinfos zu NCE findet sich [hier](https://towardsdatascience.com/noise-contrastive-estimation-246446ea9aba) und [hier](http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf).\n",
    "\n",
    "In einer früheren Version des Notebooks wurde in diesem Abschnitt auch noch eine Normalisierung der Word-Embeddings auf Werte zwischen 0 und 1 durchgeführt. In zahlreichen Testläufen konnte sich dadurch jedoch keine verbesserte Genauigkeit oder Performance ausmachen und die Ergebnisse der Cosine-Similarity wurden verfälscht, weswegen dieser Part auskommentiert ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "vpEXenMKUWkk",
    "outputId": "666d61c9-50f4-4931-c5be-800356a3fa4b"
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input Daten\n",
    "    with tf.name_scope('inputs'):\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "        train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "        iteration = tf.placeholder(tf.int32)\n",
    "  \n",
    "    # Benutze CPU:\n",
    "    with tf.device('/cpu:0'):\n",
    "        with tf.name_scope('embeddings'):\n",
    "            #embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "            # Initialisiere Embeddings:\n",
    "            embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], 0.001, 1.0))\n",
    "            # Embeddings Lookup-Table:\n",
    "            embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "     \n",
    "        # Initialisiere NCE-Weights für den NCE-Loss\n",
    "        with tf.name_scope('weights'):\n",
    "            nce_weights = tf.Variable(\n",
    "                tf.truncated_normal(\n",
    "                    [vocabulary_size, embedding_size],\n",
    "                    stddev=1.0 / math.sqrt(embedding_size)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Bias:\n",
    "        with tf.name_scope('biases'):\n",
    "            nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Berechnet der durchschnittlichen NCE-Loss pro Batch\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(\n",
    "                weights=nce_weights,\n",
    "                biases=nce_biases,\n",
    "                labels=train_labels,\n",
    "                inputs=embed,\n",
    "                num_sampled=negative_samples,\n",
    "                num_classes=vocabulary_size)\n",
    "        )      \n",
    "  \n",
    "    # Lernrate:\n",
    "    with tf.name_scope('lr'):\n",
    "        # Verringert Lernrate exponentiell, abhäging von der aktuellen Trainigsiteration\n",
    "        lr = end_learning_rate +  tf.train.exponential_decay(exp_decay_lr, iteration, 10000, 1/math.e)\n",
    "\n",
    "    # Gradient Descent optimizer mit entsprechender Lernrate und Minimieren des Loss\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    \n",
    "    # Normalisierung der Embeddings in Range [0, 1] --> Disabled\n",
    "    '''normalized_embeddings = tf.math.divide(\n",
    "        tf.subtract(\n",
    "            embeddings,\n",
    "            tf.reduce_min(embeddings)\n",
    "        ),\n",
    "        tf.maximum(\n",
    "            tf.subtract(\n",
    "                tf.reduce_max(embeddings),\n",
    "                tf.reduce_min(embeddings)\n",
    "            ),\n",
    "            epsilon\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #normalized_embeddings = tf.to_float(normalized_embeddings)\n",
    "    normalized_embeddings = tf.dtypes.cast(normalized_embeddings, tf.float32)'''\n",
    " \n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: \n",
    "Alle Vorbereitungsschritte des Notebooks werden hier zusammengeführt. Das Modell wird mit den eingestellten Parametern und den definierten Input-Daten trainiert, die Zwischenstände werden ausgegeben und die finalen Word-Embeddings werden gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "NB2sTAXdXE5a",
    "outputId": "df06d536-cb21-4ee5-e5c9-2e26b7aeb7eb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration-Step: 0\n",
      "\tAverage loss:\t 315.8806457519531 \n",
      "\tlearning-rate:\t 1.0\n",
      "Iteration-Step: 2000\n",
      "\tAverage loss:\t 147.57861945724488 \n",
      "\tlearning-rate:\t 0.8368577\n",
      "Iteration-Step: 4000\n",
      "\tAverage loss:\t 82.67597859477996 \n",
      "\tlearning-rate:\t 0.7032881\n",
      "Iteration-Step: 6000\n",
      "\tAverage loss:\t 60.39438907146454 \n",
      "\tlearning-rate:\t 0.5939305\n",
      "Iteration-Step: 8000\n",
      "\tAverage loss:\t 46.222604497790336 \n",
      "\tlearning-rate:\t 0.5043961\n",
      "Iteration-Step: 10000\n",
      "\tAverage loss:\t 36.790105431139466 \n",
      "\tlearning-rate:\t 0.4310915\n",
      "Iteration-Step: 12000\n",
      "\tAverage loss:\t 31.503256531476975 \n",
      "\tlearning-rate:\t 0.37107483\n",
      "Iteration-Step: 14000\n",
      "\tAverage loss:\t 26.07833284395933 \n",
      "\tlearning-rate:\t 0.32193726\n",
      "Iteration-Step: 16000\n",
      "\tAverage loss:\t 22.53845557963848 \n",
      "\tlearning-rate:\t 0.2817069\n",
      "Iteration-Step: 18000\n",
      "\tAverage loss:\t 20.246237768888474 \n",
      "\tlearning-rate:\t 0.24876902\n",
      "Iteration-Step: 20000\n",
      "\tAverage loss:\t 18.25406939935684 \n",
      "\tlearning-rate:\t 0.22180176\n",
      "Iteration-Step: 22000\n",
      "\tAverage loss:\t 16.7635548517704 \n",
      "\tlearning-rate:\t 0.19972284\n",
      "Iteration-Step: 24000\n",
      "\tAverage loss:\t 15.543987832248211 \n",
      "\tlearning-rate:\t 0.18164617\n",
      "Iteration-Step: 26000\n",
      "\tAverage loss:\t 14.24976732200384 \n",
      "\tlearning-rate:\t 0.16684623\n",
      "Iteration-Step: 28000\n",
      "\tAverage loss:\t 13.116464449107648 \n",
      "\tlearning-rate:\t 0.15472907\n",
      "Iteration-Step: 30000\n",
      "\tAverage loss:\t 13.053084845840932 \n",
      "\tlearning-rate:\t 0.14480837\n",
      "Iteration-Step: 32000\n",
      "\tAverage loss:\t 12.31602375304699 \n",
      "\tlearning-rate:\t 0.136686\n",
      "Iteration-Step: 34000\n",
      "\tAverage loss:\t 11.383820090532303 \n",
      "\tlearning-rate:\t 0.13003595\n",
      "Iteration-Step: 36000\n",
      "\tAverage loss:\t 11.467268664389849 \n",
      "\tlearning-rate:\t 0.12459136\n",
      "Iteration-Step: 38000\n",
      "\tAverage loss:\t 10.761207957446576 \n",
      "\tlearning-rate:\t 0.1201337\n",
      "Iteration-Step: 40000\n",
      "\tAverage loss:\t 10.396627091169357 \n",
      "\tlearning-rate:\t 0.116484076\n",
      "Iteration-Step: 42000\n",
      "\tAverage loss:\t 10.159511275351047 \n",
      "\tlearning-rate:\t 0.11349602\n",
      "Iteration-Step: 44000\n",
      "\tAverage loss:\t 10.177673943817615 \n",
      "\tlearning-rate:\t 0.11104961\n",
      "Iteration-Step: 46000\n",
      "\tAverage loss:\t 9.685349273860455 \n",
      "\tlearning-rate:\t 0.10904665\n",
      "Iteration-Step: 48000\n",
      "\tAverage loss:\t 9.61848762178421 \n",
      "\tlearning-rate:\t 0.10740678\n",
      "Iteration-Step: 50000\n",
      "\tAverage loss:\t 9.215141718268395 \n",
      "\tlearning-rate:\t 0.106064156\n",
      "Iteration-Step: 52000\n",
      "\tAverage loss:\t 8.952930246412754 \n",
      "\tlearning-rate:\t 0.10496491\n",
      "Iteration-Step: 54000\n",
      "\tAverage loss:\t 8.820645410895347 \n",
      "\tlearning-rate:\t 0.10406493\n",
      "Iteration-Step: 56000\n",
      "\tAverage loss:\t 8.799601983010769 \n",
      "\tlearning-rate:\t 0.10332808\n",
      "Iteration-Step: 58000\n",
      "\tAverage loss:\t 8.364814687013626 \n",
      "\tlearning-rate:\t 0.102724805\n",
      "Iteration-Step: 60000\n",
      "\tAverage loss:\t 8.649501547634602 \n",
      "\tlearning-rate:\t 0.10223088\n",
      "Iteration-Step: 62000\n",
      "\tAverage loss:\t 8.26846972605586 \n",
      "\tlearning-rate:\t 0.10182649\n",
      "Iteration-Step: 64000\n",
      "\tAverage loss:\t 8.140179198294877 \n",
      "\tlearning-rate:\t 0.1014954\n",
      "Iteration-Step: 66000\n",
      "\tAverage loss:\t 8.078179807662965 \n",
      "\tlearning-rate:\t 0.10122433\n",
      "Iteration-Step: 68000\n",
      "\tAverage loss:\t 8.232385183304547 \n",
      "\tlearning-rate:\t 0.1010024\n",
      "Iteration-Step: 70000\n",
      "\tAverage loss:\t 7.913437042415142 \n",
      "\tlearning-rate:\t 0.1008207\n",
      "Iteration-Step: 72000\n",
      "\tAverage loss:\t 7.994076158076525 \n",
      "\tlearning-rate:\t 0.10067193\n",
      "Iteration-Step: 74000\n",
      "\tAverage loss:\t 7.873139380216599 \n",
      "\tlearning-rate:\t 0.10055013\n",
      "Iteration-Step: 76000\n",
      "\tAverage loss:\t 7.504154848217964 \n",
      "\tlearning-rate:\t 0.10045041\n",
      "Iteration-Step: 78000\n",
      "\tAverage loss:\t 7.647728327870369 \n",
      "\tlearning-rate:\t 0.10036876\n",
      "Iteration-Step: 80000\n",
      "\tAverage loss:\t 7.746330189883709 \n",
      "\tlearning-rate:\t 0.10030192\n",
      "Iteration-Step: 82000\n",
      "\tAverage loss:\t 7.31004301828146 \n",
      "\tlearning-rate:\t 0.10024719\n",
      "Iteration-Step: 84000\n",
      "\tAverage loss:\t 7.516152036488056 \n",
      "\tlearning-rate:\t 0.10020238\n",
      "Iteration-Step: 86000\n",
      "\tAverage loss:\t 7.403916082501412 \n",
      "\tlearning-rate:\t 0.100165695\n",
      "Iteration-Step: 88000\n",
      "\tAverage loss:\t 7.238942575484514 \n",
      "\tlearning-rate:\t 0.10013566\n",
      "Iteration-Step: 90000\n",
      "\tAverage loss:\t 7.237218382000923 \n",
      "\tlearning-rate:\t 0.10011107\n",
      "Iteration-Step: 92000\n",
      "\tAverage loss:\t 7.386992692768573 \n",
      "\tlearning-rate:\t 0.100090936\n",
      "Iteration-Step: 94000\n",
      "\tAverage loss:\t 7.194828695476055 \n",
      "\tlearning-rate:\t 0.100074455\n",
      "Iteration-Step: 96000\n",
      "\tAverage loss:\t 7.2158471134901045 \n",
      "\tlearning-rate:\t 0.100060955\n",
      "Iteration-Step: 98000\n",
      "\tAverage loss:\t 7.27560411131382 \n",
      "\tlearning-rate:\t 0.100049905\n",
      "Iteration-Step: 100000\n",
      "\tAverage loss:\t 6.910221883893013 \n",
      "\tlearning-rate:\t 0.10004086\n",
      "Iteration-Step: 102000\n",
      "\tAverage loss:\t 7.021875444382429 \n",
      "\tlearning-rate:\t 0.100033455\n",
      "Iteration-Step: 104000\n",
      "\tAverage loss:\t 7.053150572299957 \n",
      "\tlearning-rate:\t 0.10002739\n",
      "Iteration-Step: 106000\n",
      "\tAverage loss:\t 6.837984975844622 \n",
      "\tlearning-rate:\t 0.10002243\n",
      "Iteration-Step: 108000\n",
      "\tAverage loss:\t 6.906158117234707 \n",
      "\tlearning-rate:\t 0.10001836\n",
      "Iteration-Step: 110000\n",
      "\tAverage loss:\t 6.955070690691471 \n",
      "\tlearning-rate:\t 0.10001503\n",
      "Iteration-Step: 112000\n",
      "\tAverage loss:\t 6.760592640906572 \n",
      "\tlearning-rate:\t 0.10001231\n",
      "Iteration-Step: 114000\n",
      "\tAverage loss:\t 6.7769896466732025 \n",
      "\tlearning-rate:\t 0.100010075\n",
      "Iteration-Step: 116000\n",
      "\tAverage loss:\t 6.877067320674658 \n",
      "\tlearning-rate:\t 0.10000825\n",
      "Iteration-Step: 118000\n",
      "\tAverage loss:\t 6.731492525875568 \n",
      "\tlearning-rate:\t 0.10000676\n",
      "Iteration-Step: 120000\n",
      "\tAverage loss:\t 6.761915376424789 \n",
      "\tlearning-rate:\t 0.10000553\n",
      "Iteration-Step: 122000\n",
      "\tAverage loss:\t 6.838653305590153 \n",
      "\tlearning-rate:\t 0.10000453\n",
      "Iteration-Step: 124000\n",
      "\tAverage loss:\t 6.491105623602867 \n",
      "\tlearning-rate:\t 0.10000371\n",
      "Iteration-Step: 126000\n",
      "\tAverage loss:\t 6.629691123157739 \n",
      "\tlearning-rate:\t 0.100003034\n",
      "Iteration-Step: 128000\n",
      "\tAverage loss:\t 6.683156307756901 \n",
      "\tlearning-rate:\t 0.10000248\n",
      "Iteration-Step: 130000\n",
      "\tAverage loss:\t 6.434065323770046 \n",
      "\tlearning-rate:\t 0.100002035\n",
      "Iteration-Step: 132000\n",
      "\tAverage loss:\t 6.417571308255195 \n",
      "\tlearning-rate:\t 0.10000167\n",
      "Iteration-Step: 134000\n",
      "\tAverage loss:\t 6.712364354789257 \n",
      "\tlearning-rate:\t 0.100001365\n",
      "Iteration-Step: 136000\n",
      "\tAverage loss:\t 6.399904703557492 \n",
      "\tlearning-rate:\t 0.10000112\n",
      "Iteration-Step: 138000\n",
      "\tAverage loss:\t 6.373747378468513 \n",
      "\tlearning-rate:\t 0.10000092\n",
      "Iteration-Step: 140000\n",
      "\tAverage loss:\t 6.547849009811878 \n",
      "\tlearning-rate:\t 0.10000075\n",
      "Iteration-Step: 142000\n",
      "\tAverage loss:\t 6.452703505098819 \n",
      "\tlearning-rate:\t 0.10000061\n",
      "Iteration-Step: 144000\n",
      "\tAverage loss:\t 6.339839556753636 \n",
      "\tlearning-rate:\t 0.1000005\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    # Initialisieren alle Variablen\n",
    "    init.run()\n",
    "  \n",
    "    average_loss = 0\n",
    "  \n",
    "    # Training:\n",
    "    for step in xrange(num_steps):\n",
    "        # generieren der Batches\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size, targets_list, labels_list)\n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels, iteration: step}\n",
    "    \n",
    "        # Ausführen eines einzelnen Update Steps, durch Evaluierung des GradientDescent Optimizers\n",
    "        # Minimieren des Loss und Updaten der Gewichte\n",
    "        _, loss_val, learn_rate = session.run(\n",
    "            [optimizer, loss, lr],\n",
    "            feed_dict=feed_dict)\n",
    "    \n",
    "        average_loss += loss_val\n",
    "        \n",
    "        # print Lernrate\n",
    "        if step % print_every_x_step == 0: \n",
    "            if step > 0:\n",
    "                average_loss /= print_every_x_step\n",
    "            print('Iteration-Step:', step)\n",
    "            print('\\tAverage loss:\\t', average_loss, '\\n\\tlearning-rate:\\t', learn_rate)\n",
    "            average_loss = 0\n",
    "        \n",
    "    # Generierte Embeddings für weitere Schritte verfügbar machen:\n",
    "    #final_embeddings = normalized_embeddings.eval() # --> Disabled\n",
    "    final_embeddings = embeddings.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dokumenten-Vektoren generieren:\n",
    "Die im vorherigen Schritt trainierten Word-Embeddings können nun genutzt werden, um pro Anfragetext einen Dokumenten-Vektor aus den Word-Embeddings der jeweiligen Wörter des Textes abzuleiten.\n",
    "Dabei werden alle Word-Embeddings eines Dokuments spaltenweise gemittelt, um dieses Dokument dann anhand eines einzelnen Vektors zu repräsentieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_embedding(doc):\n",
    "    '''\n",
    "    Generiert Dokumenten-Vektor für ein Dokument, abhängig von den zugehörigen Word-Embeddings\n",
    "    :param doc: Liste aller Sätze mit preprocessed Words\n",
    "    :return: Dokumenten-Vektor\n",
    "    '''\n",
    "    word_vecs = np.array([\n",
    "        final_embeddings[word_2_index_dict[word]] for sent in doc for word in sent if word in word_2_index_dict\n",
    "    ])\n",
    "    return np.mean(word_vecs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dokumenten-Vektoren für alle Anfragen generieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['doc_vector'] = data['preprocessed'].apply(lambda prepr_text: get_doc_embedding(prepr_text) if prepr_text else np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgrund vereinzelter Fehler im Preprocessing entstehen einige Null-Rows die hier manuell korriegiert werden müssen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description     0\n",
       "preprocessed    0\n",
       "textrank        0\n",
       "title           0\n",
       "doc_vector      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description     0\n",
       "preprocessed    0\n",
       "textrank        0\n",
       "title           0\n",
       "doc_vector      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auszug aus den Daten mit Dokumenten-Vektoren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>textrank</th>\n",
       "      <th>title</th>\n",
       "      <th>doc_vector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30037</th>\n",
       "      <td>Sämtliche Einsatzprotokolle der Sicherungsgrup...</td>\n",
       "      <td>[[einsatzprotokolle, übergriff, kriminalpolize...</td>\n",
       "      <td>[[jugendwohngruppe, Jugendwohngruppe, 1.369075...</td>\n",
       "      <td>Einsatzprotokolle von Übergriff der Berliner K...</td>\n",
       "      <td>[0.5323159, 0.5101424, 0.38201094, 0.39275265,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41614</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, schützenhof, eitorf], [betr...</td>\n",
       "      <td>[[schützenhof, Schützenhof, 1.3868680556], [wi...</td>\n",
       "      <td>Kontrollbericht zu Schützenhof, Eitorf</td>\n",
       "      <td>[0.4522284, 0.737864, -0.09975869, 0.73455733,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9663</th>\n",
       "      <td>ich bitte um eine Übersicht der aktuellen Krip...</td>\n",
       "      <td>[[kita-gebühren, verbandsgemeinde], [übersicht...</td>\n",
       "      <td>[[verbandsgemeinde, Verbandsgemeinden, 1.24791...</td>\n",
       "      <td>Übersicht über die Kita-Gebühren in den einzel...</td>\n",
       "      <td>[0.24316639, 0.5112184, 0.020094834, 0.3383331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>In verschiedenen Quellen wird die Weitergabe v...</td>\n",
       "      <td>[[weitergabe, daten/akten, behörde], [quell, w...</td>\n",
       "      <td>[[behörde, Behörden, 2.8602611613], [informati...</td>\n",
       "      <td>Weitergabe von Daten/Akten an andere Behörden</td>\n",
       "      <td>[0.25974184, 0.44923338, 0.17856327, 0.3782094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>Bitte übersenden Sie folgende Informationen zu...</td>\n",
       "      <td>[[information, abendessen, herr, ackermann, ap...</td>\n",
       "      <td>[[abendessen, Abendessen, 2.0533034722], [urte...</td>\n",
       "      <td>Informationen zu Abendessen mit Herrn Ackerman...</td>\n",
       "      <td>[0.30172154, 0.40615717, 0.1527618, 0.26614517...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "id                                                         \n",
       "30037  Sämtliche Einsatzprotokolle der Sicherungsgrup...   \n",
       "41614  1. Wann haben die beiden letzten lebensmittelr...   \n",
       "9663   ich bitte um eine Übersicht der aktuellen Krip...   \n",
       "2536   In verschiedenen Quellen wird die Weitergabe v...   \n",
       "1333   Bitte übersenden Sie folgende Informationen zu...   \n",
       "\n",
       "                                            preprocessed  \\\n",
       "id                                                         \n",
       "30037  [[einsatzprotokolle, übergriff, kriminalpolize...   \n",
       "41614  [[kontrollbericht, schützenhof, eitorf], [betr...   \n",
       "9663   [[kita-gebühren, verbandsgemeinde], [übersicht...   \n",
       "2536   [[weitergabe, daten/akten, behörde], [quell, w...   \n",
       "1333   [[information, abendessen, herr, ackermann, ap...   \n",
       "\n",
       "                                                textrank  \\\n",
       "id                                                         \n",
       "30037  [[jugendwohngruppe, Jugendwohngruppe, 1.369075...   \n",
       "41614  [[schützenhof, Schützenhof, 1.3868680556], [wi...   \n",
       "9663   [[verbandsgemeinde, Verbandsgemeinden, 1.24791...   \n",
       "2536   [[behörde, Behörden, 2.8602611613], [informati...   \n",
       "1333   [[abendessen, Abendessen, 2.0533034722], [urte...   \n",
       "\n",
       "                                                   title  \\\n",
       "id                                                         \n",
       "30037  Einsatzprotokolle von Übergriff der Berliner K...   \n",
       "41614             Kontrollbericht zu Schützenhof, Eitorf   \n",
       "9663   Übersicht über die Kita-Gebühren in den einzel...   \n",
       "2536       Weitergabe von Daten/Akten an andere Behörden   \n",
       "1333   Informationen zu Abendessen mit Herrn Ackerman...   \n",
       "\n",
       "                                              doc_vector  \n",
       "id                                                        \n",
       "30037  [0.5323159, 0.5101424, 0.38201094, 0.39275265,...  \n",
       "41614  [0.4522284, 0.737864, -0.09975869, 0.73455733,...  \n",
       "9663   [0.24316639, 0.5112184, 0.020094834, 0.3383331...  \n",
       "2536   [0.25974184, 0.44923338, 0.17856327, 0.3782094...  \n",
       "1333   [0.30172154, 0.40615717, 0.1527618, 0.26614517...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity:\n",
    "Cosine Similarity ist eine gängige Möglichkeit, um die Ähnlichkeit zweier Vektoren zu ermitteln. Mithilfe des Abstandswinkels zwischen den beiden Vektoren wird ein Wert zwischen 0 und 1 erzeugt, welcher das Ähnlichkeitsmaß ausdrückt. Einfache, 2-Dimensionale Vektoren können hierbei noch per Hand errechnet werden. Cosine-Similarity funktioniert jedoch mit einer beliebigen Anzahl von Vektor-Dimensionen und ist somit für den Vergleich unserer Dokumenten- oder Wort-Vektoren hervorragend geeignet.\n",
    "\n",
    "Formel:\n",
    "![image](Images/Cosine_Similarity_Formula.png)\n",
    "\n",
    "\n",
    "Quelle: [CSM]\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "|Person/Eigenschaft|  EG1 \t| EG2 \t|  EG3 \t|\n",
    "|:-----------:\t|:----:\t|:---:\t|:----:\t|\n",
    "|  Konstantin \t| 10 \t| 50 \t|  200 \t|\n",
    "|  Sebastian  \t|  400 \t| 100 \t| 20 \t|\n",
    "| Prof. Herta \t|  10 \t| 5 \t|  1 \t|\n",
    "\n",
    "Ähnlichkeit von Konstantin und Sebastian: <br>\n",
    "Cosine_Similarity ( [10,50,200] , [400, 100, 20]) = 0.15\n",
    "\n",
    "Ähnlichkeit von Sebastian und Prof. Herta: <br>\n",
    "Cosine_Similarity ( [400, 100, 20], [10, 5, 1]) = 0.23\n",
    "\n",
    "Ähnlichkeit von Konstantin und Prof. Herta: <br>\n",
    "Cosine_Similarity ( [10,50,200], [10, 5, 1]) = 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(v1, v2):\n",
    "    n1 = np.linalg.norm(v1)\n",
    "    n2 = np.linalg.norm(v2)\n",
    "    return np.dot(v1, v2) / n1 / n2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negativbeispiel für Vergleich unterschiedlicher Wörter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity for herausgabe and bekleidung\n",
      "\t 0.42096847\n"
     ]
    }
   ],
   "source": [
    "word1 = 'herausgabe'\n",
    "word2 = 'bekleidung'\n",
    "print('cosine similarity for', word1, 'and', word2)\n",
    "print('\\t', similarity(final_embeddings[word_2_index_dict[word1]], final_embeddings[word_2_index_dict[word2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positivbeispiel für Vergleich ähnlicher Wörter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity for bfr and iarc\n",
      "\t 0.74131197\n"
     ]
    }
   ],
   "source": [
    "word1 = 'bfr'\n",
    "word2 = 'iarc' # beide Kürzel stehen in Zusammenhang durch Verwendung in Glyphosatberichten\n",
    "print('cosine similarity for', word1, 'and', word2)\n",
    "print('\\t', similarity(final_embeddings[word_2_index_dict[word1]], final_embeddings[word_2_index_dict[word2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vergleich von Dokumentenvektoren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_similarity(df, id_1, id_2):\n",
    "    print('Doc #1:')\n",
    "    print('\\tTitel:', df.loc[id_1]['title'])\n",
    "    \n",
    "    print('\\nDoc #2:')\n",
    "    print('\\tTitel:', df.loc[id_2]['title'])\n",
    "    \n",
    "    print('\\nSimilarity [0-1]:', similarity(df.loc[id_1]['doc_vector'], df.loc[id_2]['doc_vector']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positivbeispiel für Vergleich ähnlicher Dokumente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc #1:\n",
      "\tTitel: Kontrollbericht zu Bartz, Arzfeld\n",
      "\n",
      "Doc #2:\n",
      "\tTitel: Kontrollbericht zu Mamma Italia, Esslingen am Neckar\n",
      "\n",
      "Similarity [0-1]: 0.9522405\n"
     ]
    }
   ],
   "source": [
    "doc_similarity(data, 58945, 48729)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negativbeispiel für Vergleich unterschiedlicher Dokumente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc #1:\n",
      "\tTitel: Kontrollbericht zu Bartz, Arzfeld\n",
      "\n",
      "Doc #2:\n",
      "\tTitel: Ortsumgehung Barnstorf, Landreis Diepholz\n",
      "\n",
      "Similarity [0-1]: 0.79113513\n"
     ]
    }
   ],
   "source": [
    "doc_similarity(data, 58945, 58948)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den errechneten Document-Embeddings erhalten wir eine hochdimensionale (in unserem Fall 300) und komplexe Datenmatrix, die sich dank des t-SNE Algorithmus in geringeren Dimensionen, meist 2- oder 3-dimensional, visualisieren lässt. Natürlich erzeugt diese Verringerung einen gewissen Informationsverlust, der wie im folgendem Beschrieben möglichst gering gehalten werden soll. Eine Darstellung unserer Document-Embeddings mittels t-SNE ist besonders geeignet um Strukturen im visualisierten Datensatz, wie lokale Nachbarschaften oder Wort-/Dokumenten-Gruppierung, zu erkennen. Ähnliche Anfragen werden sich somit voraussichtlich clustern und es entsteht eine dreidimensionale Visualisierung, die einen ersten Überblick über die semantischen Zusammenhänge zwischen den Anfragetexten gibt.\n",
    "\n",
    "## t-SNE Grundprinzip:\n",
    "Wie so oft, muss das Rad nicht neu erfunden werden und man kann eine optimierte Implementierung des t-SNE bereits über das sklearn-kit beziehen. Um zu verstehen, was sich im Hintergrund abspielt, hier ein Versuch die Funktionsweise anhand eines Beispiels zu erläutern:\n",
    "\n",
    "**Das Ziel**: Punkte aus dem 2-dimensionalen Raum, 1-dimensional darzustellen.\n",
    "\n",
    "<img src=\"Images/tSNE_Ziel.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**Abstände Messen:** Dazu wird ein Punkt in den Fokus genommen und die Abstände zu den anderen Punkten wird normalverteilt gemessen. Aus der höheren Dimension wird also die Entfernung auf der reduzierten Dimension abgebildet und dann die Entfernung zur Normalverteilungskurve gemessen.\n",
    "\n",
    "<img src=\"Images/tSNE_Normalverteilt.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**Normalverteilung in Matrix überführen:** Dadurch ist es möglich, eine Matrix aufzubauen, wo zu jedem Punkt die Entfernung zu einem anderen Punkt (bzw. dessen Entfernung zur Normalverteilungskurve) abgebildet werden kann. Eine Entfernung von einem Punkt zu sich selbst macht hierbei natürlich keinen Sinn.\n",
    "\n",
    "<img src=\"Images/tSNE_Matrix1.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**Wiederholung mit t-Verteilung:** Im nächsten Schritt wird der gesamte Prozess bis hierhin wiederholt, jedoch nicht mit der t-Verteilung und einem Freiheitsgrad (Cauchy-Verteilung) anstelle der Normalverteilung. Es entsteht eine weit unpräzisere Anordnung der Punkte in unserer t-Matrix:\n",
    "\n",
    "<img src=\"Images/tSNE_Matrix2.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "Auch auf die x-Achse projiziert ergeben die Entfernungen (noch) keinen Sinn:\n",
    "\n",
    "<img src=\"Images/tSNE_t_map.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**t-Verteilung und Normalverteilung angleichen:** Im nächsten Schritt versuchen wir, die Punkte in der niedrigeren Dimension (hier: 1-D, bzw. x-Achse) der t-Verteilung so lange zu verschieben, bis dieser denen, der Normalverteilung gleichen. Dazu schiebt der t-SNE Algorithmus immer einen Punkt in der Matrix näher an seine Ziel-Koordinate und vollzieht den gleichen Schritt auf der x-Achse.\n",
    "\n",
    "<img src=\"Images/tSNE_t_finish.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**Weiterer Verlauf:** Im Beispiel wurde von 2- auf 1-Dimensionalität reduziert. Voreingestellte Parameter im Notebook trainieren jedoch Word-Embeddings mit deutlich mehr Dimensionen (hier: 300). Schrittweise reduziert t-SNE die Dimensionen, eine nach der anderen, bis zur gewünschten Ziel-Dimension. Für normale Bildschirme wären das die Dimensionen 1-3 (Beispiel siehe folgende Kapitel).\n",
    "\n",
    "\n",
    "### Warum wird die t-Verteilung hier benötigt? \n",
    "Hier wird es kompliziert: Das zugrunde liegende Verfahren erfordert ein tiefer gehendes mathematisches Verständnis von Verteilungsfunktionen und sprengt den Rahmen des Notebooks. Hilfreiche Links und Sekundärliteratur finden sich [hier](https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm) und [hier](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf). \n",
    "<br><br>Eine kurze Erklärung in eigenen Worten:\n",
    "Der Ansatz für die Nutzung der t-Verteilung liegt im Unterschied der Verteilungsfunktionen. \n",
    "Würde beim Reduzieren der Dimensionen eines Datensatzes die Normalverteilung herangezogen werden, so käme es zu einer Disbalance der Verteilung von Punkten und deren Distanz zu Ihren Nachbarn. Der Grund hierfür ist der große Unterschied des Maßes einer Entfernung in unterschiedlichen Dimensionen, welche der Algorithmus versucht abzubilden. Um dieser Divergenz an Maßen gerecht zu werden, nutzt t-SNE die t-Verteilung (daher auch das \"t\"), welche in den Außenbereichen einen viel geringeren Abstieg hat und generell flacher und nicht so intensiv gipfelnd ist wie die Normalverteilung. Konkret bedeutet das: Trotzdem zwei Punkte in der Ausgangsdimension sehr weit voneinander entfernt sind, können diese in der niedrigeren Dimension eine Ähnlichkeit aufweisen.\n",
    "Quelle: [TDS]\n",
    "\n",
    "### Hyperparameter\n",
    "\n",
    "Neben den Input-Daten, der Zieldimension und der Lern-Rate gibt es zwei entscheidende Parameter, die helfen, das meiste aus t-SNE herauszuholen: Perplexity und Iterationsanzahl.\n",
    "\n",
    "Beim Tunen der **Anzahl an Iterationen** konnten auf den FragDenStaat Datensatz beste Ergebnisse bei ca. 1000 Iterationen festgestellt werden. Diese Zahl stellt jedoch keine fixe Empfehlung dar und muss je nach Grunddatenmenge und Struktur des Datensatzes ausprobiert und angepasst werden. Am Beispiel in der folgenden Grafik lässt sich demonstrativ erkennen, dass bei zu wenigen Iterationen eine schlechte, punktlastige Gruppierung erfolgt. Tritt dieses Symptom beim Plotten der Graphen auf, so ist höchstwahrscheinlich das Training zu früh beendet worden. \n",
    "\n",
    "<img src=\"Images/tSNE_iterations.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "Quelle: [HYP] \n",
    "\n",
    "\n",
    "**Perplexity**, dass zweite wichtige Feature bei der Feineinstellung des t-SNE bestimmt, wie die Gewichtung von lokalen und globalen Eigenschaften der Punkte in unserem Datensatz in die Erstellung der niedrig-dimensionalen Plots mit einfließen soll. Die Auswirkungen verschiedener Werte bei der perplexity sind weitreichend und zugleich nur schwer nachvollziehbar. Während des Trainings wurde hier mit viel Try-And-Error ein idealer Wert versucht anzunähern (hier: 25). Im bebilderten Beispiel wird ein Datensatz mit zwei Clustern und unterschiedlichen Perplexity-Werten (2-100) mittels t-SNE neu berechnet. Im Paper [TODO]: Quelle [\"Visualizing Data using t-SNE\"](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) wird empfohlen, die Perplexity-Werte zwischen fünf und 50 zu initialisieren. Im Beispiel können wir das ursprüngliche Clustering, wenn auch in unterschiedlichen Formen und Intensitäten, gut nachvollziehen. Werte außerhalb dieses empfohlenen Bereichs erzeugen aber gänzlich andere Strukturen. Zu geringe Perplexity-Werte (2) zeigen Cluster mit zu hoher lokaler Dominanz. Bei zu hohen Perplexity-Werten (100) werden die beiden Cluster vereint und können gar nicht mehr unterschieden werden.\n",
    "Abschließend lässt sich zusammenfassen, dass der Perplexity-Wert eine grobe Richtung vorgibt, wie viele enge Nachbarn ein Punkt unseres Datensatzes hat und individuell für jeden Datensatz ermittelt werden muss.\n",
    "\n",
    "<img src=\"Images/tSNE_perplexity.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "Quelle: [HYP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tsne_doc(data_df, amount, dimension=2, perplexity=30, learning_rate=200, n_iter=5000):\n",
    "    '''\n",
    "    Berechnet t-SNE Embeddings für zufällige Stichprobe aus dem Set der Anfragetexte\n",
    "    :param data_df: pandas DataFrame mit Spalte 'doc_vector' und 'title'\n",
    "    :param amount: Größe der Stichprobe\n",
    "    :param dimension: 2 für 2D oder 3 für 3D\n",
    "    '''\n",
    "    tsne = TSNE(perplexity=perplexity, learning_rate=learning_rate, n_components=dimension, init='pca', n_iter=n_iter, method='exact', verbose=1)\n",
    "    sample = data_df.sample(n=amount)\n",
    "\n",
    "    doc_vecs = np.array([doc_vec for doc_vec in sample['doc_vector'].values])\n",
    "    tsne_embeddings = tsne.fit_transform(doc_vecs)\n",
    "\n",
    "    labels = sample['title'].values\n",
    "    return tsne_embeddings, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaktiver 2D/3D Plot mit ploty\n",
    "Mithilfe von Plotly können wir nun einen ersten 2- oder 3-Dimensionalen Plot unserer Daten die mittels t-SNE errechnet wurden, versuchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_plot_tsne(tsne_embeddings, labels, dimension=3):\n",
    "    \n",
    "    marker=dict(\n",
    "                size=6,\n",
    "                line=dict(\n",
    "                    color='rgb(225, 225, 225)',\n",
    "                    width=0.5\n",
    "                ),\n",
    "                opacity=1\n",
    "            )\n",
    "    \n",
    "    if dimension==3:\n",
    "        x, y, z = zip(*tsne_embeddings)\n",
    "        \n",
    "        trace1 = go.Scatter3d(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            z=z,\n",
    "            mode='markers',\n",
    "            marker=marker,\n",
    "            text=labels,\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "    else:\n",
    "        x, y = zip(*tsne_embeddings)\n",
    "        \n",
    "        trace1 = go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode='markers',\n",
    "            marker=marker,\n",
    "            text=labels,\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "    \n",
    "    \n",
    "\n",
    "    data = [trace1]\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        ),\n",
    "        xaxis = dict(\n",
    "            zeroline = False\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            zeroline = False\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        #paper_bgcolor= 'rgb(240, 240, 240)',\n",
    "        #plot_bgcolor= 'rgb(240, 240, 240)'\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D TSNE Visualisierung für Stichprobe von Anfragen\n",
    "Im finalen Abschnitt des Notebooks reduzieren wir die Dimensionen einer Stichprobe (Umfang: 200 Dokumente) mittels t-SNE auf 3D und visualisieren diese dann mit Plotly interaktiv.\n",
    "Reduzierte Stichprobengröße aufgrund von limitierter Hardware, da t-SNE sehr rechenintensiv ist.\n",
    "\n",
    "**Achtung:** Hier gibt es nur Ergebnisse zu sehen, wenn das Notebook lokal ausgeführt wird, das Modell trainiert und der Datensatz eingeladen wurde. Eine Darstellung auf GitHub selbst ist somit leider nicht möglich.\n",
    "Auf eine 2D-Darstellung wurde in diesem Fall verzichtet, wäre mit der gleichen Funktion aber auch möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computed conditional probabilities for sample 200 / 200\n",
      "[t-SNE] Mean sigma: 0.967027\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 46.496586\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.182286\n"
     ]
    }
   ],
   "source": [
    "plot_x_docs = 200\n",
    "tsne_embeddings_3d, labels_3d = compute_tsne_doc(\n",
    "    data, \n",
    "    plot_x_docs, \n",
    "    dimension=3,\n",
    "    perplexity=25,\n",
    "    learning_rate=10,\n",
    "    n_iter=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interaktiver 3D Plot der t-SNE Embeddings**  \n",
    "* Linksklick: Rotieren\n",
    "* Rechtsklick: Verschieben\n",
    "* Mausrad: Zoom in/out\n",
    "* Hover über Punkt: Anzeige des Dokumenten-Titels\n",
    "\n",
    "Obwohl nur eine Stichprobengröße von 200 gewählt wurde, können lokale Ballungsgebiete, ähnlicher Dokumente gleicher Thematik, identifiziert werden (Hover über Punkt für Titelanzeige)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "line": {
           "color": "rgb(225, 225, 225)",
           "width": 0.5
          },
          "opacity": 1,
          "size": 6
         },
         "mode": "markers",
         "text": [
          "Interne Anwendungshinweise zum IFG",
          "Kontrollbericht zu A la Turka, Wilhelmshaven",
          "Kontrollbericht zu Berlin Döner, Hannover",
          "Kontrollbericht zu Haibacher Döner & Pizza, Haibach",
          "Aufstellung über die Verteilung der sog. Selbstbewirtschaftungsmittel auf die Ortsverbände innerhalb Ihres LV mit Auflistung der OV und der jeweils zugewiesenen Beträge sowie des zugehörigen Verteilungsschlüssels",
          "§268AO Antrag auf Beschränkung der Vollstreckung auf den eigenen Rundfunkbeitragsanteil",
          "Kontrollbericht zu Nomiya, München",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Stellungnahme von Bundesfachverband unbegleitete minderjährige Flüchtlinge e.V. zu Entwurf eines Gesetzes zur besseren Durchsetzung der Ausreisepflicht",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Kontrollbericht zu Klosterhof, Söflingen",
          "Kontrollbericht zu La Perla, Bielefeld",
          "Weisungen des Jobcenters - Jobcenter im Landkreis Rhön Grabfeld",
          "Gutachten Dietenbach",
          "Kontrollbericht zu Sriphen's Thai Küche, Emmendingen",
          "Gesprächsnotizen vom Staatsbesuch aus China",
          "Kontrollbericht zu Kecha, Dresden",
          "Liste zu Ablehnungsentscheiden von Tierversuchsanträgen",
          "Zielvereinbarung mit der Bundesagentur für Arbeit - Jobcenter Bayreuth Stadt",
          "Kontrollbericht zu Sternenbäck, Plauen",
          "WD 5 - 124/10 – Arbeitsplatzeffekte der „Grünen Gentechnik“",
          "Deutscher Bundestag: WD Ausarbeitung „Informationszugangsfreiheit als Grundrecht“ (WD 3 – 322/11)",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "WD 4 - 156/10 – Besonderes Kirchgeld und Vorschläge zur Reform der Kirchensteuer",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Datencodes in den Brieffenstern des Beitragsservice",
          "Kontrollbericht zu Alte Liebe, Berlin",
          "Studie \"Politisch Netzaktive und Politik in Deutschland\" von TNS Infratest",
          "Baupläne Versorgungstunnel Uni Stuttgart",
          "Masterstudiengang \"Intelligence and Security Studies\" (MISS)",
          "Asphaltierung Malmöer Straße/Sperrung Boesebrücke",
          "Bundesministerium für Arbeit und Soziales (BMAS): Von Deutschland umzusetzende EU-Gesetze im Sozialbereich gemäß Art. 4 Abs. 2 und Art. 153 AEUV",
          "Kontrollbericht zu Sushi Park, Karlsruhe",
          "Kontrollbericht zu Café - Restaurant Michaelsberg, Bruchsal",
          "Zertifizierungsrichtlinie (CPS) der Bundesagentur für Arbeit",
          "Kontrollbericht zu Hasina Eatery, Berlin",
          "Kontrollbericht zu Diego, Leipzig",
          "Studie \"zu den Political Net Activists\" des Instituts für Demoskopie in Allensbach",
          "Kontrollbericht zu Futterkrippe, Moringen",
          "Feststellung des Hauptwohnsitzes",
          "Einsatz von Arbeitsgelegenheiten 2010",
          "Kontrollbericht zu Ristorante da Gerardo Bad Furth",
          "Liste/n Grundstoffe für die Herstellung von Chemiewaffen in maschinenlesbarer Form",
          "Kontrollbericht zu Aras Kebap Haus, Hamburg",
          "Kontrollbericht zu Ristorante & Pizzeria Bacco, Mönchweiler",
          "funk Musterverträge und aktive Veträge mit Influencern",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Fahrradweg beim Ausbau der St 2027 bei Forsthofen (Projekt KE500-07)",
          "Geschäftsordnung der BGE",
          "Gutachten \"Rechtsfragen im Kontext der Abgeordnetenkorruption\"",
          "LDA - Brandenburg - Themengebiet interne Verwaltung - Akte 089/12/133",
          "Detaillierte Rohdaten angezeigter Straftaten",
          "Dokumente zur Umbenennung des „Bundesministerium für Umwelt, Naturschutz und Reaktorsicherheit“ in  „Bundesministerium für Umwelt, Naturschutz und nukleare Sicherheit“",
          "elektronische Patientenakte (EPA) SGB5 §291a - aktueller Stand des gematik-Auftrages zur Schaffung der Voraussetzungen für die EPA (Fristablauf 31.12.2018)",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Datenverarbeitung beim Verfassungsschutz / Innenministerium",
          "Abiturklausuren 2011",
          "Kontrollbericht zu Efsane Bistro, Laupheim",
          "Kontrollbericht zu New Ceylon Imbiss, Dortmund",
          "Gründung eines \"Sicherheitsclubs\"",
          "Kontrollbericht zu Pizzeria B30, Ravensburg",
          "Kontrollbericht zu Nostalgia Zur Delle, Düsseldorf",
          "BNetzA-Vortrag \"Regulierung der Netze\" auf der Handelsblatt-Tagung am 21.1.2016",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Stellungnahme von Deutscher Genossenschafts- und Raiffeisenverband e.V. zu Entwurf eines Gesetzes zur Weiterentwicklung des Strommarktes (StrommarktG)",
          "Kontrollbericht zu Domino's, Mannheim",
          "Aufschlüsselung der Kosten für \"Der Bastard\"-Mitschnitt beim WDR Mitschnitt-Service",
          "Lizenzbedingungen für die Inhalte der \"Ankommen\"-App ",
          "Kontrollbericht zu Catwalk, München",
          "Stellungnahme von Deutscher Weinfonds zu Neuntes Gesetz zur Änderung des Weingesetzes",
          "Kontrollbericht zu Pizza Hut, Köln",
          "Verträge und Zulässigkeitsprüfung zu Außenwerbungsanlagen auf öffentlichem Grund",
          "WD 4 - 128/12 – Situation der Sparkassen in Europa",
          "Haushaltspläne maschinenlesbare Form",
          "Kontrollbericht zu Tegut, Langenselbold",
          "Aufsichtsratstätigkeit der Bürgermeisterin bei den DEW",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Strasse Namibia Sossusvlei",
          "Kontrollbericht zu Ristorante \"Alte Münze\", Hildesheim",
          "Baumfällung im Alten Elbpark Frühjahr 2015",
          "Kontrollbericht zu Restaurant Aquila, Füssen",
          "Kontrollbericht zu Hellas Restaurant, Hamburg",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Antrag IFG Papier-und Druckerkosten 2017",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Baumaßnahmen auf dem Tempelhofer Feld",
          "Stellungnahme von IG Metall Vorstand zu 15. Gesetz zur Änderung des Atomgesetzes",
          "Externe Berater*innen Digitalpakt",
          "Prüfungsaufgaben Jahrgangsstufe 10 des Jahres 2018 für Gymnasien",
          "Angaben zu ausgefallenen Unterrichtsstunden und Schülerzahlen Essener Schulen 2015/2016",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Kontrollbericht zu Brauereigasthof Hirsch, Sonthofen",
          "Verbleib des Herrenduftes",
          "Beitragsschuldner",
          "Verwaltungsvereinbarung \"ARD ZDF DR Beitragsservice\"",
          "Kontrollbericht zu Senats's, Lübeck",
          "Brandschutzbedarfsplan und aktuelle Brandschutzsatzung!",
          "Kontrollbericht zu Grill Royal, Berlin",
          "Stellungnahme von Bundesvereinigung der Deutschen Arbeitgeberverbände zu Gesetz zur Reform der Strukturen der Krankenhausversorgung  (Krankenhausstrukturgesetz – KHSG)",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Kontrollbericht zu McDonald's Pfungstadt, Pfungstadt",
          "Bericht Unterhaltsvorschuss - wurde in die Ressortabstimmung gegeben",
          "Bitte um Übermittelung der Rechercheergebnisse im Zuge des Prüfvorgangs bzgl. Paragraph 99 des Strafgesetzbuchs ",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Kontrollbericht zu Minh Minh Asia Bistro, Lengerich",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Subskriptionskosten für wissenschaftliche Verlage",
          "Kontrollbericht zu Renoir, Bremen",
          "Deutschlandradio / ZDF und Beitragsservice",
          "Kontrollbericht zu Karstadt Bamberg, Bamberg",
          "Kontrollbericht zu Bäckerei Grimm, Sittensen",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Kontrollbericht zu McDonald's, Bad Pyrmont",
          "Übersicht der Ausarbeitungen des Wissenschaftlichen Dienstes des Landtages SA",
          "Kontrollbericht zu King's Garden Restaurant, Olching",
          "Kontrollbericht zu Wolf Genießerwelt, Otzberg",
          "Anzahl der verkauften Wahlergebnis CDs",
          "Kontrollbericht zu Curry-Palast, Aachen",
          "Schreiben von Lorenz Caffier an den Generalbundesanwalt bzgl. des Todeslisten-Vorfalls",
          "Den Abschlussbericht des Expertengremiums über die Sicherheitsgesetze",
          "Sponsorings",
          "Kontrollbericht zu da remo, Berlin",
          "Kontrollbericht zu Mongols Garden, Wunstorf",
          "Kontrollbericht zu Tapas Factory, Dortmund",
          "Kontrollbericht zu Ristorante Il Sogno, Eggstätt",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Kontrollbericht zu Netto, Schwielowsee",
          "Pünktlichkeit der Straßenbahn-Linie M17",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Kontrollbericht zu Efsane Deluxe, Duisburg",
          "Adressen aller Bürgermeister",
          "Kosten für die Bewachung von ausländischen militärischen Einrichtungen",
          "Stellungnahme von Verband der Deutschen Automaten-Industrie e. V. zu Entwurf eines Gesetzes zur Aktualisierung der Strukturreform des Gebührenrechts des Bundes",
          "Presse- und Informationsamt der Bundesregierung (BPA): Umfragen im Auftrag des BPAs 2009-2013",
          "Einfuhrmenge Zigaretten aus Polen",
          "Kontrollbericht zu Indisches Restaurant Tandoori, Marburg",
          "FeV Anlage 4, Punkte 9.2.1.und 9.2.2.: Regelmäßige und gelegentliche Einnahme von Cannabis",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Kontrollbericht zu Sternenbäck, Sigmaringen",
          "Kontrollbericht zu McDonald's Restaurant, Berlin",
          "Kontrollbericht zu zur Platane, Mörfelden-Walldorf",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "[Kita-Satzungen] Anzahl der anhängigen Normenkontrollverfahren",
          "Förderung des Internationalen Maritimen Museums",
          "Kontrollbericht zu House Journal, Groß-Umstadt",
          "Neues Konzept zu Unterkunftskosten im Märkischen Kreis",
          "Pestizideinsatz im Wald",
          "Informationen zum \"Gemeinsamen Kompetenz- und Dienstleistungszentrum“ (GKDZ) zur Telekommunikationsüberwachung",
          "Kontrollbericht zu McDonald's Restaurant, Mönchengladbach",
          "WD 1 - 043/06 – Politische Dimension der Fußball-Weltmeisterschaft 2006 in Deutschland",
          "Kontrollbericht zu Gourmet Tempel, Porta Westfalica",
          "Kontrollbericht zu Hotel NH Ingolstadt, Ingolstadt",
          "Verschlüsselung",
          "WD 3 - 353/11 – Zulässigkeit des Auslesens von Daten aus mobilen Datenträgern aufgrund § 48 Abs. 3 AufenthG",
          "Anzahl und Ergebnisse der Verkehrskontrollen in Rheine Höhe Emsland Gymnasiums",
          "Kontrollbericht zu Alte Post, Kreuzau",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Liste - Wirtschaftlichkeitsbetrachtungsdokumente",
          "Kontrollbericht zu Ebl, Würzburg",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Kontrollbericht zu Steinhoff, Beckum",
          "Studie \"Politisch Netzaktive und Politik in Deutschland\" von TNS Infratest",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Kontrollbericht zu CQ Flavour, Stuttgart",
          "Finanzverfassungsrechtliche Fragen zur Ausgestaltung des Europäischen Stabilitätsmechanismus (ESM) ",
          "Kontrollbericht zu meiwei, Bielefeld",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Zuständigkeitsstreiten Deutsche Rentenversicherung - Jobcenter",
          "Speicherung der Akten",
          "Gutachten \"Rechtsfragen im Kontext der Abgeordnetenkorruption\"",
          "Kontrollbericht zu McDonald's, Bochum",
          "Verkehrskontrolle Kreuzung Arnold-/Rothe-/Keplerstraße in Altona",
          "Kontrollbericht zu Cafe Milchhäuschen, Chemnitz",
          "Übersicht über die durchgeführten Beratungs- und Kontrollbesuche der BfDI im Jahr 2017 (möglichst auch nach nach Einstufung als VS bzw. ohne Einstufung)",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Kontrollbericht zu Nahkauf, Frankfurt am Main",
          "Ermittlungsverfahren wegen Veröffentlichungen des \"Chemnitzer Haftbefehls\"",
          "Studie \"Politisch Netzaktive und Politik in Deutschland\" von TNS Infratest",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Nach dem G20-Gipfel: PIRATEN fordern Aufklärung vom Presse- und Informationsamt der Bundesregierung (Bundespresseamt)",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Kosten für die Stadt von 32. Deutscher Evangelischer Kirchentag",
          "Kontrollbericht zu Backhaus Markus, Kassel",
          "\"Rechtsfragen im Kontext der Abgeordnetenkorruption\"",
          "Missbrauch von Ein-Euro-Jobs - von Jobcentern legalisierte Schwarzarbeit",
          "Coding-Guidelines",
          "Kosten für Olympiabewerbung",
          "Abitur-Aufgaben im Fach Englisch im Jahr 2018 in Nordrhein-Westfalen",
          "PE 6 - 074/13 – Fragen zur Anwendung der Safe Harbor Grundsätze zwischen der EU und den USA",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Belegung und Auslastung von Schwimmbädern durch Schulen",
          "Bundesanzeiger Verlag GmbH",
          "Begründung zu IFGGebV",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Weisung des Jobcenters - ESG / Einstiegsgeld Beschäftigung",
          "Übersicht Umweltinformationen über den Verbrauch der natürlichen Ressourcen Wasser, Luft oder Boden",
          "Kontrollbericht zu Rewe Markt, Nuremberg",
          "Kontrollbericht zu Rocca, Düsseldorf",
          "Kontrollbericht zu McDonald's Restaurant, Holzminden",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\""
         ],
         "type": "scatter3d",
         "uid": "50cf70a0-0e83-48df-a760-79f8845e12ed",
         "x": [
          2.0496175289154053,
          -5.977837085723877,
          -12.711712837219238,
          -12.054862976074219,
          7.60654878616333,
          8.787161827087402,
          -10.0324068069458,
          -5.113154888153076,
          2.8910017013549805,
          -5.0979719161987305,
          -5.9908599853515625,
          -10.66723346710205,
          3.938897132873535,
          4.1087446212768555,
          -7.548727512359619,
          6.49463415145874,
          -8.161949157714844,
          5.629408359527588,
          3.950871706008911,
          -6.573735237121582,
          2.255570411682129,
          2.573601484298706,
          -5.0979719161987305,
          2.4168429374694824,
          0.7774446606636047,
          6.755669116973877,
          -10.508511543273926,
          2.575693130493164,
          8.146732330322266,
          8.744124412536621,
          4.808902263641357,
          3.5429773330688477,
          -10.329071998596191,
          -9.09121322631836,
          8.295862197875977,
          -10.489307403564453,
          -9.001729011535645,
          2.279770612716675,
          -8.182740211486816,
          6.898396015167236,
          4.581606388092041,
          -8.566640853881836,
          7.919209003448486,
          -11.706750869750977,
          -7.6399993896484375,
          8.867901802062988,
          -5.0979719161987305,
          8.816777229309082,
          9.545597076416016,
          -0.26873868703842163,
          4.89630126953125,
          8.12537956237793,
          5.525572299957275,
          5.723082542419434,
          0.1868811845779419,
          3.0366859436035156,
          4.164027214050293,
          -8.896017074584961,
          -6.543595790863037,
          5.343923568725586,
          -8.5708589553833,
          -7.014779090881348,
          2.8536081314086914,
          0.7774446606636047,
          2.901885747909546,
          -9.873136520385742,
          7.583010673522949,
          8.141146659851074,
          -9.979365348815918,
          2.79323673248291,
          -11.776721000671387,
          5.334061145782471,
          1.992885708808899,
          6.277792453765869,
          -5.362245559692383,
          5.134640693664551,
          -5.015475749969482,
          8.630755424499512,
          -6.817136764526367,
          8.51134204864502,
          -8.681212425231934,
          -11.329544067382812,
          0.33584532141685486,
          4.746885299682617,
          -5.015475749969482,
          8.378666877746582,
          2.8303825855255127,
          2.7752671241760254,
          6.940781116485596,
          5.250360488891602,
          0.1868811845779419,
          -4.721726417541504,
          2.9814906120300293,
          8.439661979675293,
          6.446554660797119,
          -9.38161849975586,
          9.316628456115723,
          -12.567266464233398,
          4.520877838134766,
          -5.015475749969482,
          -9.183879852294922,
          5.266363620758057,
          2.933032512664795,
          0.1868811845779419,
          -5.522705078125,
          0.14016073942184448,
          3.495696544647217,
          -9.775176048278809,
          6.233816146850586,
          -6.8187127113342285,
          -7.687166213989258,
          -5.0979719161987305,
          -10.037810325622559,
          2.1147520542144775,
          -10.28725528717041,
          -5.013827800750732,
          5.684521198272705,
          -7.707305908203125,
          7.789681434631348,
          9.519491195678711,
          6.34404182434082,
          -12.901342391967773,
          -5.4207963943481445,
          -6.261378288269043,
          -6.584848403930664,
          0.14016073942184448,
          -5.921288967132568,
          6.958526134490967,
          0.33584532141685486,
          -6.478660583496094,
          6.073117256164551,
          3.1927194595336914,
          2.9396426677703857,
          2.8029897212982178,
          8.739713668823242,
          -8.972855567932129,
          7.537847995758057,
          -5.0979719161987305,
          -6.794197082519531,
          -11.375641822814941,
          -6.444124698638916,
          0.14016073942184448,
          7.03246545791626,
          4.111732006072998,
          -5.286664962768555,
          5.703056812286377,
          9.947874069213867,
          5.67094612121582,
          -10.764178276062012,
          2.0981550216674805,
          -4.819921970367432,
          -4.9782490730285645,
          6.760471820831299,
          2.6841976642608643,
          5.648340702056885,
          -10.066603660583496,
          -5.0979719161987305,
          5.445603370666504,
          -8.174461364746094,
          0.33584532141685486,
          -5.816196918487549,
          2.5735058784484863,
          0.33584532141685486,
          -8.024787902832031,
          1.3225784301757812,
          -10.813678741455078,
          0.33584532141685486,
          7.204666614532471,
          4.559179306030273,
          -0.26873868703842163,
          -10.65316390991211,
          6.32828426361084,
          -6.803390979766846,
          6.630025863647461,
          0.14016073942184448,
          -11.618653297424316,
          7.037143230438232,
          2.5735058784484863,
          -4.19771671295166,
          4.65407657623291,
          0.33584532141685486,
          4.417304515838623,
          -5.673744201660156,
          -0.38647884130477905,
          7.41375207901001,
          7.910918712615967,
          3.884354829788208,
          2.923373222351074,
          2.4550154209136963,
          -5.0979719161987305,
          6.531270503997803,
          5.037452697753906,
          7.360121250152588,
          0.33584532141685486,
          3.1750731468200684,
          8.486339569091797,
          -9.454133033752441,
          -8.513927459716797,
          -10.565679550170898,
          0.14016073942184448
         ],
         "y": [
          -0.7224939465522766,
          -7.765384197235107,
          -6.995283603668213,
          -6.015340328216553,
          5.682014465332031,
          5.248470783233643,
          -5.626842021942139,
          2.2132468223571777,
          1.1897757053375244,
          2.8909764289855957,
          -8.002727508544922,
          -5.921232223510742,
          -1.4772616624832153,
          4.812557697296143,
          -6.63919734954834,
          3.3622336387634277,
          -5.213634967803955,
          2.3537542819976807,
          -1.476379632949829,
          -6.812939167022705,
          4.195209980010986,
          0.08347507566213608,
          2.8909764289855957,
          4.1964826583862305,
          -1.2093485593795776,
          4.830593109130859,
          -4.235326766967773,
          0.6883776783943176,
          4.507946014404297,
          7.1215739250183105,
          4.0177083015441895,
          1.355521321296692,
          -7.2826995849609375,
          -6.807775020599365,
          6.933506011962891,
          -4.213762283325195,
          -5.1476826667785645,
          3.1562843322753906,
          -5.9367265701293945,
          3.86442494392395,
          2.8690319061279297,
          -7.586164474487305,
          5.604818820953369,
          -6.091543197631836,
          -7.181718826293945,
          8.116358757019043,
          2.8909764289855957,
          6.4218220710754395,
          4.880075454711914,
          0.5173670053482056,
          5.024609565734863,
          5.889652252197266,
          0.8395517468452454,
          3.495476722717285,
          2.6992027759552,
          0.17377394437789917,
          3.04080867767334,
          -5.885236740112305,
          -6.1643242835998535,
          3.280919075012207,
          -6.407630920410156,
          -7.570429801940918,
          0.2712068557739258,
          -1.2093485593795776,
          1.2266719341278076,
          -7.4132080078125,
          5.516767978668213,
          7.275270938873291,
          -5.62645959854126,
          1.2346396446228027,
          -5.770196914672852,
          3.5111172199249268,
          3.7676398754119873,
          1.502522349357605,
          -7.342240333557129,
          2.588552236557007,
          2.8830583095550537,
          5.871829986572266,
          -7.507278919219971,
          6.574592113494873,
          -7.048837661743164,
          -6.6548590660095215,
          -0.9023218154907227,
          1.666072964668274,
          2.8830583095550537,
          5.898134708404541,
          1.2783702611923218,
          -0.18196170032024384,
          2.6481566429138184,
          2.8571012020111084,
          2.6992027759552,
          -8.044676780700684,
          0.6016415357589722,
          3.534564733505249,
          4.561144828796387,
          -7.303203105926514,
          5.950961589813232,
          -7.49461555480957,
          3.5792741775512695,
          2.8830583095550537,
          -8.309487342834473,
          3.481027841567993,
          0.685128390789032,
          2.6992027759552,
          -6.396143436431885,
          2.8973429203033447,
          1.0084422826766968,
          -5.169563293457031,
          4.335413455963135,
          -5.027449131011963,
          -6.110832214355469,
          2.8909764289855957,
          -7.672587871551514,
          1.6177901029586792,
          -7.026039123535156,
          -8.4541654586792,
          6.426634788513184,
          -6.219512939453125,
          6.546996116638184,
          7.524615287780762,
          2.232236385345459,
          -7.087281227111816,
          -8.619607925415039,
          -6.741166114807129,
          -7.51521635055542,
          2.8973429203033447,
          -6.994996547698975,
          7.056051731109619,
          -0.9023218154907227,
          -7.710877418518066,
          1.8841884136199951,
          1.0007550716400146,
          1.1752618551254272,
          0.09856270998716354,
          7.300311088562012,
          -7.111236095428467,
          5.178408145904541,
          2.8909764289855957,
          -6.434704780578613,
          -7.45441198348999,
          -7.329197406768799,
          2.8973429203033447,
          5.693030834197998,
          1.2258495092391968,
          -7.736440658569336,
          2.5507915019989014,
          6.847551345825195,
          4.058282375335693,
          -7.617099285125732,
          3.756077289581299,
          -8.771750450134277,
          -6.267053604125977,
          6.441490650177002,
          3.205388069152832,
          4.398468971252441,
          -4.908642768859863,
          2.8909764289855957,
          5.494192123413086,
          -5.961627960205078,
          -0.9023218154907227,
          -8.005725860595703,
          0.6816319823265076,
          -0.9023218154907227,
          -7.265903949737549,
          0.8831027150154114,
          -5.880349636077881,
          -0.9023218154907227,
          6.235750675201416,
          0.3115219473838806,
          0.5173670053482056,
          -7.722620487213135,
          4.808612823486328,
          -5.297621250152588,
          4.442326545715332,
          2.8973429203033447,
          -6.35603666305542,
          2.579110860824585,
          0.6816319823265076,
          2.5901267528533936,
          2.473360538482666,
          -0.9023218154907227,
          1.493632197380066,
          -7.4601969718933105,
          0.5117210745811462,
          4.627078056335449,
          7.749229431152344,
          1.7516403198242188,
          -0.8992417454719543,
          2.928863525390625,
          2.8909764289855957,
          4.3100433349609375,
          2.9319088459014893,
          5.992353439331055,
          -0.9023218154907227,
          3.3996388912200928,
          4.26093053817749,
          -6.02252721786499,
          -5.569688320159912,
          -7.523761749267578,
          2.8973429203033447
         ],
         "z": [
          2.5795583724975586,
          -1.5687669515609741,
          2.1083457469940186,
          2.1354286670684814,
          -1.6515716314315796,
          -2.064392566680908,
          -0.23784342408180237,
          -0.7421150207519531,
          4.532965183258057,
          -1.1293078660964966,
          -2.465883493423462,
          2.38620924949646,
          3.1960978507995605,
          -0.8306865692138672,
          0.1659506857395172,
          -1.5524617433547974,
          0.2540983259677887,
          1.2178560495376587,
          3.200843572616577,
          -1.420032024383545,
          1.701882004737854,
          2.130821943283081,
          -1.1293078660964966,
          1.594612717628479,
          -0.7632833123207092,
          -0.33173322677612305,
          -0.28552109003067017,
          -3.8464162349700928,
          -3.348540782928467,
          -2.5776960849761963,
          -0.7539721727371216,
          1.128782868385315,
          2.8380253314971924,
          0.3967597782611847,
          -2.557199478149414,
          -0.35674649477005005,
          0.5824238657951355,
          -2.094285249710083,
          -1.4502674341201782,
          -0.3505263328552246,
          0.008555743843317032,
          2.022860288619995,
          -2.291990041732788,
          0.8818351626396179,
          1.610668420791626,
          -2.415998935699463,
          -1.1293078660964966,
          -1.9592995643615723,
          -1.948509693145752,
          2.0481679439544678,
          0.6642979383468628,
          -2.2225701808929443,
          -0.5780377388000488,
          -0.6695176362991333,
          -2.2199723720550537,
          1.5334478616714478,
          -1.3842523097991943,
          0.2514631152153015,
          0.6721741557121277,
          -2.360804319381714,
          1.6807416677474976,
          0.035157460719347,
          1.812088966369629,
          -0.7632833123207092,
          4.523426532745361,
          1.7323299646377563,
          -1.595141053199768,
          -1.050831913948059,
          -0.13038185238838196,
          4.682575225830078,
          1.4923145771026611,
          -0.4618721604347229,
          1.9764982461929321,
          0.4585879445075989,
          -1.2785744667053223,
          -0.5680411458015442,
          -0.35223159193992615,
          -0.5875179767608643,
          1.2156401872634888,
          -2.6858506202697754,
          -0.39968863129615784,
          0.9361069798469543,
          -0.6303673982620239,
          0.977859377861023,
          -0.35223159193992615,
          -2.1665492057800293,
          4.566050052642822,
          2.09784197807312,
          1.101356863975525,
          -0.21337810158729553,
          -2.2199723720550537,
          -1.3279764652252197,
          1.6474111080169678,
          -1.8832086324691772,
          2.1453166007995605,
          1.1534923315048218,
          -3.352851152420044,
          2.002474308013916,
          1.1702289581298828,
          -0.35223159193992615,
          0.5495179891586304,
          0.2175617516040802,
          1.6083543300628662,
          -2.2199723720550537,
          1.0376064777374268,
          -1.8965415954589844,
          1.2540202140808105,
          1.093658208847046,
          2.082233428955078,
          1.5775407552719116,
          1.1511719226837158,
          -1.1293078660964966,
          1.9013307094573975,
          1.9690555334091187,
          0.9673426151275635,
          -1.6654318571090698,
          -1.6250033378601074,
          -0.18220077455043793,
          -3.6026573181152344,
          -3.0483179092407227,
          1.819309949874878,
          1.9970813989639282,
          -0.643523633480072,
          -0.02730434574186802,
          0.8781163096427917,
          -1.8965415954589844,
          -0.5935953259468079,
          -2.1477434635162354,
          -0.6303673982620239,
          -0.500562846660614,
          -1.7038707733154297,
          -0.06076213717460632,
          4.4280009269714355,
          1.9629859924316406,
          -4.061894416809082,
          -0.1633749008178711,
          -1.3820085525512695,
          -1.1293078660964966,
          -1.5821350812911987,
          1.6025481224060059,
          -0.9177471995353699,
          -1.8965415954589844,
          -2.432953357696533,
          2.578202486038208,
          -0.7607769966125488,
          -0.41780081391334534,
          -1.8104580640792847,
          0.2762056589126587,
          1.463840365409851,
          1.8682150840759277,
          -1.2400975227355957,
          -0.6192284822463989,
          -0.9131049513816833,
          1.5437922477722168,
          -1.0590237379074097,
          1.7014617919921875,
          -1.1293078660964966,
          -2.783799886703491,
          -0.748837411403656,
          -0.6303673982620239,
          -1.2422313690185547,
          -3.8495614528656006,
          -0.6303673982620239,
          -0.9684569239616394,
          1.4399527311325073,
          2.3448548316955566,
          -0.6303673982620239,
          -1.8057807683944702,
          1.0555800199508667,
          2.0481679439544678,
          1.911779522895813,
          -1.4498475790023804,
          -0.22594106197357178,
          -3.2011232376098633,
          -1.8965415954589844,
          2.7967209815979004,
          -0.7160580158233643,
          -3.8495614528656006,
          -0.837561309337616,
          0.12596452236175537,
          -0.6303673982620239,
          -1.3677338361740112,
          0.7582213878631592,
          2.070333480834961,
          -1.7688521146774292,
          -3.1056277751922607,
          -0.2730365991592407,
          0.8953425288200378,
          1.5726662874221802,
          -1.1293078660964966,
          -1.220510482788086,
          -0.16084033250808716,
          0.2943280041217804,
          -0.6303673982620239,
          0.2668796479701996,
          -0.3016704022884369,
          1.9371384382247925,
          0.9880262613296509,
          1.2545613050460815,
          -1.8965415954589844
         ]
        }
       ],
       "layout": {
        "height": 800,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "width": 1000,
        "xaxis": {
         "zeroline": false
        },
        "yaxis": {
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"ef6554a8-d4a6-4452-971f-1e85c6192d93\" class=\"plotly-graph-div\" style=\"height:800px; width:1000px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"ef6554a8-d4a6-4452-971f-1e85c6192d93\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'ef6554a8-d4a6-4452-971f-1e85c6192d93',\n",
       "                        [{\"hoverinfo\": \"text\", \"marker\": {\"line\": {\"color\": \"rgb(225, 225, 225)\", \"width\": 0.5}, \"opacity\": 1, \"size\": 6}, \"mode\": \"markers\", \"text\": [\"Interne Anwendungshinweise zum IFG\", \"Kontrollbericht zu A la Turka, Wilhelmshaven\", \"Kontrollbericht zu Berlin D\\u00f6ner, Hannover\", \"Kontrollbericht zu Haibacher D\\u00f6ner & Pizza, Haibach\", \"Aufstellung \\u00fcber die Verteilung der sog. Selbstbewirtschaftungsmittel auf die Ortsverb\\u00e4nde innerhalb Ihres LV mit Auflistung der OV und der jeweils zugewiesenen Betr\\u00e4ge sowie des zugeh\\u00f6rigen Verteilungsschl\\u00fcssels\", \"\\u00a7268AO Antrag auf Beschr\\u00e4nkung der Vollstreckung auf den eigenen Rundfunkbeitragsanteil\", \"Kontrollbericht zu Nomiya, M\\u00fcnchen\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Stellungnahme von Bundesfachverband unbegleitete minderj\\u00e4hrige Fl\\u00fcchtlinge e.V. zu Entwurf eines Gesetzes zur besseren Durchsetzung der Ausreisepflicht\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Kontrollbericht zu Klosterhof, S\\u00f6flingen\", \"Kontrollbericht zu La Perla, Bielefeld\", \"Weisungen des Jobcenters - Jobcenter im Landkreis Rh\\u00f6n Grabfeld\", \"Gutachten Dietenbach\", \"Kontrollbericht zu Sriphen's Thai K\\u00fcche, Emmendingen\", \"Gespr\\u00e4chsnotizen vom Staatsbesuch aus China\", \"Kontrollbericht zu Kecha, Dresden\", \"Liste zu Ablehnungsentscheiden von Tierversuchsantr\\u00e4gen\", \"Zielvereinbarung mit der Bundesagentur f\\u00fcr Arbeit - Jobcenter Bayreuth Stadt\", \"Kontrollbericht zu Sternenb\\u00e4ck, Plauen\", \"WD 5 - 124/10 \\u2013 Arbeitsplatzeffekte der \\u201eGr\\u00fcnen Gentechnik\\u201c\", \"Deutscher Bundestag: WD Ausarbeitung \\u201eInformationszugangsfreiheit als Grundrecht\\u201c (WD 3 \\u2013 322/11)\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"WD 4 - 156/10 \\u2013 Besonderes Kirchgeld und Vorschl\\u00e4ge zur Reform der Kirchensteuer\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Datencodes in den Brieffenstern des Beitragsservice\", \"Kontrollbericht zu Alte Liebe, Berlin\", \"Studie \\\"Politisch Netzaktive und Politik in Deutschland\\\" von TNS Infratest\", \"Baupl\\u00e4ne Versorgungstunnel Uni Stuttgart\", \"Masterstudiengang \\\"Intelligence and Security Studies\\\" (MISS)\", \"Asphaltierung Malm\\u00f6er Stra\\u00dfe/Sperrung Boesebr\\u00fccke\", \"Bundesministerium f\\u00fcr Arbeit und Soziales (BMAS): Von Deutschland umzusetzende EU-Gesetze im Sozialbereich gem\\u00e4\\u00df Art. 4 Abs. 2 und Art. 153 AEUV\", \"Kontrollbericht zu Sushi Park, Karlsruhe\", \"Kontrollbericht zu Caf\\u00e9 - Restaurant Michaelsberg, Bruchsal\", \"Zertifizierungsrichtlinie (CPS) der Bundesagentur f\\u00fcr Arbeit\", \"Kontrollbericht zu Hasina Eatery, Berlin\", \"Kontrollbericht zu Diego, Leipzig\", \"Studie \\\"zu den Political Net Activists\\\" des Instituts f\\u00fcr Demoskopie in Allensbach\", \"Kontrollbericht zu Futterkrippe, Moringen\", \"Feststellung des Hauptwohnsitzes\", \"Einsatz von Arbeitsgelegenheiten 2010\", \"Kontrollbericht zu Ristorante da Gerardo Bad Furth\", \"Liste/n Grundstoffe f\\u00fcr die Herstellung von Chemiewaffen in maschinenlesbarer Form\", \"Kontrollbericht zu Aras Kebap Haus, Hamburg\", \"Kontrollbericht zu Ristorante & Pizzeria Bacco, M\\u00f6nchweiler\", \"funk Mustervertr\\u00e4ge und aktive Vetr\\u00e4ge mit Influencern\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Fahrradweg beim Ausbau der St 2027 bei Forsthofen (Projekt KE500-07)\", \"Gesch\\u00e4ftsordnung der BGE\", \"Gutachten \\\"Rechtsfragen im Kontext der Abgeordnetenkorruption\\\"\", \"LDA - Brandenburg - Themengebiet interne Verwaltung - Akte 089/12/133\", \"Detaillierte Rohdaten angezeigter Straftaten\", \"Dokumente zur Umbenennung des \\u201eBundesministerium f\\u00fcr Umwelt, Naturschutz und Reaktorsicherheit\\u201c in  \\u201eBundesministerium f\\u00fcr Umwelt, Naturschutz und nukleare Sicherheit\\u201c\", \"elektronische Patientenakte (EPA) SGB5 \\u00a7291a - aktueller Stand des gematik-Auftrages zur Schaffung der Voraussetzungen f\\u00fcr die EPA (Fristablauf 31.12.2018)\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Datenverarbeitung beim Verfassungsschutz / Innenministerium\", \"Abiturklausuren 2011\", \"Kontrollbericht zu Efsane Bistro, Laupheim\", \"Kontrollbericht zu New Ceylon Imbiss, Dortmund\", \"Gr\\u00fcndung eines \\\"Sicherheitsclubs\\\"\", \"Kontrollbericht zu Pizzeria B30, Ravensburg\", \"Kontrollbericht zu Nostalgia Zur Delle, D\\u00fcsseldorf\", \"BNetzA-Vortrag \\\"Regulierung der Netze\\\" auf der Handelsblatt-Tagung am 21.1.2016\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Stellungnahme von Deutscher Genossenschafts- und Raiffeisenverband e.V. zu Entwurf eines Gesetzes zur Weiterentwicklung des Strommarktes (StrommarktG)\", \"Kontrollbericht zu Domino's, Mannheim\", \"Aufschl\\u00fcsselung der Kosten f\\u00fcr \\\"Der Bastard\\\"-Mitschnitt beim WDR Mitschnitt-Service\", \"Lizenzbedingungen f\\u00fcr die Inhalte der \\\"Ankommen\\\"-App \", \"Kontrollbericht zu Catwalk, M\\u00fcnchen\", \"Stellungnahme von Deutscher Weinfonds zu Neuntes Gesetz zur \\u00c4nderung des Weingesetzes\", \"Kontrollbericht zu Pizza Hut, K\\u00f6ln\", \"Vertr\\u00e4ge und Zul\\u00e4ssigkeitspr\\u00fcfung zu Au\\u00dfenwerbungsanlagen auf \\u00f6ffentlichem Grund\", \"WD 4 - 128/12 \\u2013 Situation der Sparkassen in Europa\", \"Haushaltspl\\u00e4ne maschinenlesbare Form\", \"Kontrollbericht zu Tegut, Langenselbold\", \"Aufsichtsratst\\u00e4tigkeit der B\\u00fcrgermeisterin bei den DEW\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Strasse Namibia Sossusvlei\", \"Kontrollbericht zu Ristorante \\\"Alte M\\u00fcnze\\\", Hildesheim\", \"Baumf\\u00e4llung im Alten Elbpark Fr\\u00fchjahr 2015\", \"Kontrollbericht zu Restaurant Aquila, F\\u00fcssen\", \"Kontrollbericht zu Hellas Restaurant, Hamburg\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Antrag IFG Papier-und Druckerkosten 2017\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Bauma\\u00dfnahmen auf dem Tempelhofer Feld\", \"Stellungnahme von IG Metall Vorstand zu 15. Gesetz zur \\u00c4nderung des Atomgesetzes\", \"Externe Berater*innen Digitalpakt\", \"Pr\\u00fcfungsaufgaben Jahrgangsstufe 10 des Jahres 2018 f\\u00fcr Gymnasien\", \"Angaben zu ausgefallenen Unterrichtsstunden und Sch\\u00fclerzahlen Essener Schulen 2015/2016\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Kontrollbericht zu Brauereigasthof Hirsch, Sonthofen\", \"Verbleib des Herrenduftes\", \"Beitragsschuldner\", \"Verwaltungsvereinbarung \\\"ARD ZDF DR Beitragsservice\\\"\", \"Kontrollbericht zu Senats's, L\\u00fcbeck\", \"Brandschutzbedarfsplan und aktuelle Brandschutzsatzung!\", \"Kontrollbericht zu Grill Royal, Berlin\", \"Stellungnahme von Bundesvereinigung der Deutschen Arbeitgeberverb\\u00e4nde zu Gesetz zur Reform der Strukturen der Krankenhausversorgung  (Krankenhausstrukturgesetz \\u2013 KHSG)\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Kontrollbericht zu McDonald's Pfungstadt, Pfungstadt\", \"Bericht Unterhaltsvorschuss - wurde in die Ressortabstimmung gegeben\", \"Bitte um \\u00dcbermittelung der Rechercheergebnisse im Zuge des Pr\\u00fcfvorgangs bzgl. Paragraph 99 des Strafgesetzbuchs \", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Kontrollbericht zu Minh Minh Asia Bistro, Lengerich\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Subskriptionskosten f\\u00fcr wissenschaftliche Verlage\", \"Kontrollbericht zu Renoir, Bremen\", \"Deutschlandradio / ZDF und Beitragsservice\", \"Kontrollbericht zu Karstadt Bamberg, Bamberg\", \"Kontrollbericht zu B\\u00e4ckerei Grimm, Sittensen\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Kontrollbericht zu McDonald's, Bad Pyrmont\", \"\\u00dcbersicht der Ausarbeitungen des Wissenschaftlichen Dienstes des Landtages SA\", \"Kontrollbericht zu King's Garden Restaurant, Olching\", \"Kontrollbericht zu Wolf Genie\\u00dferwelt, Otzberg\", \"Anzahl der verkauften Wahlergebnis CDs\", \"Kontrollbericht zu Curry-Palast, Aachen\", \"Schreiben von Lorenz Caffier an den Generalbundesanwalt bzgl. des Todeslisten-Vorfalls\", \"Den Abschlussbericht des Expertengremiums \\u00fcber die Sicherheitsgesetze\", \"Sponsorings\", \"Kontrollbericht zu da remo, Berlin\", \"Kontrollbericht zu Mongols Garden, Wunstorf\", \"Kontrollbericht zu Tapas Factory, Dortmund\", \"Kontrollbericht zu Ristorante Il Sogno, Eggst\\u00e4tt\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Kontrollbericht zu Netto, Schwielowsee\", \"P\\u00fcnktlichkeit der Stra\\u00dfenbahn-Linie M17\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Kontrollbericht zu Efsane Deluxe, Duisburg\", \"Adressen aller B\\u00fcrgermeister\", \"Kosten f\\u00fcr die Bewachung von ausl\\u00e4ndischen milit\\u00e4rischen Einrichtungen\", \"Stellungnahme von Verband der Deutschen Automaten-Industrie e. V. zu Entwurf eines Gesetzes zur Aktualisierung der Strukturreform des Geb\\u00fchrenrechts des Bundes\", \"Presse- und Informationsamt der Bundesregierung (BPA): Umfragen im Auftrag des BPAs 2009-2013\", \"Einfuhrmenge Zigaretten aus Polen\", \"Kontrollbericht zu Indisches Restaurant Tandoori, Marburg\", \"FeV Anlage 4, Punkte 9.2.1.und 9.2.2.: Regelm\\u00e4\\u00dfige und gelegentliche Einnahme von Cannabis\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Kontrollbericht zu Sternenb\\u00e4ck, Sigmaringen\", \"Kontrollbericht zu McDonald's Restaurant, Berlin\", \"Kontrollbericht zu zur Platane, M\\u00f6rfelden-Walldorf\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"[Kita-Satzungen] Anzahl der anh\\u00e4ngigen Normenkontrollverfahren\", \"F\\u00f6rderung des Internationalen Maritimen Museums\", \"Kontrollbericht zu House Journal, Gro\\u00df-Umstadt\", \"Neues Konzept zu Unterkunftskosten im M\\u00e4rkischen Kreis\", \"Pestizideinsatz im Wald\", \"Informationen zum \\\"Gemeinsamen Kompetenz- und Dienstleistungszentrum\\u201c (GKDZ) zur Telekommunikations\\u00fcberwachung\", \"Kontrollbericht zu McDonald's Restaurant, M\\u00f6nchengladbach\", \"WD 1 - 043/06 \\u2013 Politische Dimension der Fu\\u00dfball-Weltmeisterschaft 2006 in Deutschland\", \"Kontrollbericht zu Gourmet Tempel, Porta Westfalica\", \"Kontrollbericht zu Hotel NH Ingolstadt, Ingolstadt\", \"Verschl\\u00fcsselung\", \"WD 3 - 353/11 \\u2013 Zul\\u00e4ssigkeit des Auslesens von Daten aus mobilen Datentr\\u00e4gern aufgrund \\u00a7 48 Abs. 3 AufenthG\", \"Anzahl und Ergebnisse der Verkehrskontrollen in Rheine H\\u00f6he Emsland Gymnasiums\", \"Kontrollbericht zu Alte Post, Kreuzau\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Liste - Wirtschaftlichkeitsbetrachtungsdokumente\", \"Kontrollbericht zu Ebl, W\\u00fcrzburg\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Kontrollbericht zu Steinhoff, Beckum\", \"Studie \\\"Politisch Netzaktive und Politik in Deutschland\\\" von TNS Infratest\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Kontrollbericht zu CQ Flavour, Stuttgart\", \"Finanzverfassungsrechtliche Fragen zur Ausgestaltung des Europ\\u00e4ischen Stabilit\\u00e4tsmechanismus (ESM) \", \"Kontrollbericht zu meiwei, Bielefeld\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Zust\\u00e4ndigkeitsstreiten Deutsche Rentenversicherung - Jobcenter\", \"Speicherung der Akten\", \"Gutachten \\\"Rechtsfragen im Kontext der Abgeordnetenkorruption\\\"\", \"Kontrollbericht zu McDonald's, Bochum\", \"Verkehrskontrolle Kreuzung Arnold-/Rothe-/Keplerstra\\u00dfe in Altona\", \"Kontrollbericht zu Cafe Milchh\\u00e4uschen, Chemnitz\", \"\\u00dcbersicht \\u00fcber die durchgef\\u00fchrten Beratungs- und Kontrollbesuche der BfDI im Jahr 2017 (m\\u00f6glichst auch nach nach Einstufung als VS bzw. ohne Einstufung)\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Kontrollbericht zu Nahkauf, Frankfurt am Main\", \"Ermittlungsverfahren wegen Ver\\u00f6ffentlichungen des \\\"Chemnitzer Haftbefehls\\\"\", \"Studie \\\"Politisch Netzaktive und Politik in Deutschland\\\" von TNS Infratest\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Nach dem G20-Gipfel: PIRATEN fordern Aufkl\\u00e4rung vom Presse- und Informationsamt der Bundesregierung (Bundespresseamt)\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Kosten f\\u00fcr die Stadt von 32. Deutscher Evangelischer Kirchentag\", \"Kontrollbericht zu Backhaus Markus, Kassel\", \"\\\"Rechtsfragen im Kontext der Abgeordnetenkorruption\\\"\", \"Missbrauch von Ein-Euro-Jobs - von Jobcentern legalisierte Schwarzarbeit\", \"Coding-Guidelines\", \"Kosten f\\u00fcr Olympiabewerbung\", \"Abitur-Aufgaben im Fach Englisch im Jahr 2018 in Nordrhein-Westfalen\", \"PE 6 - 074/13 \\u2013 Fragen zur Anwendung der Safe Harbor Grunds\\u00e4tze zwischen der EU und den USA\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Belegung und Auslastung von Schwimmb\\u00e4dern durch Schulen\", \"Bundesanzeiger Verlag GmbH\", \"Begr\\u00fcndung zu IFGGebV\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Weisung des Jobcenters - ESG / Einstiegsgeld Besch\\u00e4ftigung\", \"\\u00dcbersicht Umweltinformationen \\u00fcber den Verbrauch der nat\\u00fcrlichen Ressourcen Wasser, Luft oder Boden\", \"Kontrollbericht zu Rewe Markt, Nuremberg\", \"Kontrollbericht zu Rocca, D\\u00fcsseldorf\", \"Kontrollbericht zu McDonald's Restaurant, Holzminden\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\"], \"type\": \"scatter3d\", \"uid\": \"50cf70a0-0e83-48df-a760-79f8845e12ed\", \"x\": [2.0496175289154053, -5.977837085723877, -12.711712837219238, -12.054862976074219, 7.60654878616333, 8.787161827087402, -10.0324068069458, -5.113154888153076, 2.8910017013549805, -5.0979719161987305, -5.9908599853515625, -10.66723346710205, 3.938897132873535, 4.1087446212768555, -7.548727512359619, 6.49463415145874, -8.161949157714844, 5.629408359527588, 3.950871706008911, -6.573735237121582, 2.255570411682129, 2.573601484298706, -5.0979719161987305, 2.4168429374694824, 0.7774446606636047, 6.755669116973877, -10.508511543273926, 2.575693130493164, 8.146732330322266, 8.744124412536621, 4.808902263641357, 3.5429773330688477, -10.329071998596191, -9.09121322631836, 8.295862197875977, -10.489307403564453, -9.001729011535645, 2.279770612716675, -8.182740211486816, 6.898396015167236, 4.581606388092041, -8.566640853881836, 7.919209003448486, -11.706750869750977, -7.6399993896484375, 8.867901802062988, -5.0979719161987305, 8.816777229309082, 9.545597076416016, -0.26873868703842163, 4.89630126953125, 8.12537956237793, 5.525572299957275, 5.723082542419434, 0.1868811845779419, 3.0366859436035156, 4.164027214050293, -8.896017074584961, -6.543595790863037, 5.343923568725586, -8.5708589553833, -7.014779090881348, 2.8536081314086914, 0.7774446606636047, 2.901885747909546, -9.873136520385742, 7.583010673522949, 8.141146659851074, -9.979365348815918, 2.79323673248291, -11.776721000671387, 5.334061145782471, 1.992885708808899, 6.277792453765869, -5.362245559692383, 5.134640693664551, -5.015475749969482, 8.630755424499512, -6.817136764526367, 8.51134204864502, -8.681212425231934, -11.329544067382812, 0.33584532141685486, 4.746885299682617, -5.015475749969482, 8.378666877746582, 2.8303825855255127, 2.7752671241760254, 6.940781116485596, 5.250360488891602, 0.1868811845779419, -4.721726417541504, 2.9814906120300293, 8.439661979675293, 6.446554660797119, -9.38161849975586, 9.316628456115723, -12.567266464233398, 4.520877838134766, -5.015475749969482, -9.183879852294922, 5.266363620758057, 2.933032512664795, 0.1868811845779419, -5.522705078125, 0.14016073942184448, 3.495696544647217, -9.775176048278809, 6.233816146850586, -6.8187127113342285, -7.687166213989258, -5.0979719161987305, -10.037810325622559, 2.1147520542144775, -10.28725528717041, -5.013827800750732, 5.684521198272705, -7.707305908203125, 7.789681434631348, 9.519491195678711, 6.34404182434082, -12.901342391967773, -5.4207963943481445, -6.261378288269043, -6.584848403930664, 0.14016073942184448, -5.921288967132568, 6.958526134490967, 0.33584532141685486, -6.478660583496094, 6.073117256164551, 3.1927194595336914, 2.9396426677703857, 2.8029897212982178, 8.739713668823242, -8.972855567932129, 7.537847995758057, -5.0979719161987305, -6.794197082519531, -11.375641822814941, -6.444124698638916, 0.14016073942184448, 7.03246545791626, 4.111732006072998, -5.286664962768555, 5.703056812286377, 9.947874069213867, 5.67094612121582, -10.764178276062012, 2.0981550216674805, -4.819921970367432, -4.9782490730285645, 6.760471820831299, 2.6841976642608643, 5.648340702056885, -10.066603660583496, -5.0979719161987305, 5.445603370666504, -8.174461364746094, 0.33584532141685486, -5.816196918487549, 2.5735058784484863, 0.33584532141685486, -8.024787902832031, 1.3225784301757812, -10.813678741455078, 0.33584532141685486, 7.204666614532471, 4.559179306030273, -0.26873868703842163, -10.65316390991211, 6.32828426361084, -6.803390979766846, 6.630025863647461, 0.14016073942184448, -11.618653297424316, 7.037143230438232, 2.5735058784484863, -4.19771671295166, 4.65407657623291, 0.33584532141685486, 4.417304515838623, -5.673744201660156, -0.38647884130477905, 7.41375207901001, 7.910918712615967, 3.884354829788208, 2.923373222351074, 2.4550154209136963, -5.0979719161987305, 6.531270503997803, 5.037452697753906, 7.360121250152588, 0.33584532141685486, 3.1750731468200684, 8.486339569091797, -9.454133033752441, -8.513927459716797, -10.565679550170898, 0.14016073942184448], \"y\": [-0.7224939465522766, -7.765384197235107, -6.995283603668213, -6.015340328216553, 5.682014465332031, 5.248470783233643, -5.626842021942139, 2.2132468223571777, 1.1897757053375244, 2.8909764289855957, -8.002727508544922, -5.921232223510742, -1.4772616624832153, 4.812557697296143, -6.63919734954834, 3.3622336387634277, -5.213634967803955, 2.3537542819976807, -1.476379632949829, -6.812939167022705, 4.195209980010986, 0.08347507566213608, 2.8909764289855957, 4.1964826583862305, -1.2093485593795776, 4.830593109130859, -4.235326766967773, 0.6883776783943176, 4.507946014404297, 7.1215739250183105, 4.0177083015441895, 1.355521321296692, -7.2826995849609375, -6.807775020599365, 6.933506011962891, -4.213762283325195, -5.1476826667785645, 3.1562843322753906, -5.9367265701293945, 3.86442494392395, 2.8690319061279297, -7.586164474487305, 5.604818820953369, -6.091543197631836, -7.181718826293945, 8.116358757019043, 2.8909764289855957, 6.4218220710754395, 4.880075454711914, 0.5173670053482056, 5.024609565734863, 5.889652252197266, 0.8395517468452454, 3.495476722717285, 2.6992027759552, 0.17377394437789917, 3.04080867767334, -5.885236740112305, -6.1643242835998535, 3.280919075012207, -6.407630920410156, -7.570429801940918, 0.2712068557739258, -1.2093485593795776, 1.2266719341278076, -7.4132080078125, 5.516767978668213, 7.275270938873291, -5.62645959854126, 1.2346396446228027, -5.770196914672852, 3.5111172199249268, 3.7676398754119873, 1.502522349357605, -7.342240333557129, 2.588552236557007, 2.8830583095550537, 5.871829986572266, -7.507278919219971, 6.574592113494873, -7.048837661743164, -6.6548590660095215, -0.9023218154907227, 1.666072964668274, 2.8830583095550537, 5.898134708404541, 1.2783702611923218, -0.18196170032024384, 2.6481566429138184, 2.8571012020111084, 2.6992027759552, -8.044676780700684, 0.6016415357589722, 3.534564733505249, 4.561144828796387, -7.303203105926514, 5.950961589813232, -7.49461555480957, 3.5792741775512695, 2.8830583095550537, -8.309487342834473, 3.481027841567993, 0.685128390789032, 2.6992027759552, -6.396143436431885, 2.8973429203033447, 1.0084422826766968, -5.169563293457031, 4.335413455963135, -5.027449131011963, -6.110832214355469, 2.8909764289855957, -7.672587871551514, 1.6177901029586792, -7.026039123535156, -8.4541654586792, 6.426634788513184, -6.219512939453125, 6.546996116638184, 7.524615287780762, 2.232236385345459, -7.087281227111816, -8.619607925415039, -6.741166114807129, -7.51521635055542, 2.8973429203033447, -6.994996547698975, 7.056051731109619, -0.9023218154907227, -7.710877418518066, 1.8841884136199951, 1.0007550716400146, 1.1752618551254272, 0.09856270998716354, 7.300311088562012, -7.111236095428467, 5.178408145904541, 2.8909764289855957, -6.434704780578613, -7.45441198348999, -7.329197406768799, 2.8973429203033447, 5.693030834197998, 1.2258495092391968, -7.736440658569336, 2.5507915019989014, 6.847551345825195, 4.058282375335693, -7.617099285125732, 3.756077289581299, -8.771750450134277, -6.267053604125977, 6.441490650177002, 3.205388069152832, 4.398468971252441, -4.908642768859863, 2.8909764289855957, 5.494192123413086, -5.961627960205078, -0.9023218154907227, -8.005725860595703, 0.6816319823265076, -0.9023218154907227, -7.265903949737549, 0.8831027150154114, -5.880349636077881, -0.9023218154907227, 6.235750675201416, 0.3115219473838806, 0.5173670053482056, -7.722620487213135, 4.808612823486328, -5.297621250152588, 4.442326545715332, 2.8973429203033447, -6.35603666305542, 2.579110860824585, 0.6816319823265076, 2.5901267528533936, 2.473360538482666, -0.9023218154907227, 1.493632197380066, -7.4601969718933105, 0.5117210745811462, 4.627078056335449, 7.749229431152344, 1.7516403198242188, -0.8992417454719543, 2.928863525390625, 2.8909764289855957, 4.3100433349609375, 2.9319088459014893, 5.992353439331055, -0.9023218154907227, 3.3996388912200928, 4.26093053817749, -6.02252721786499, -5.569688320159912, -7.523761749267578, 2.8973429203033447], \"z\": [2.5795583724975586, -1.5687669515609741, 2.1083457469940186, 2.1354286670684814, -1.6515716314315796, -2.064392566680908, -0.23784342408180237, -0.7421150207519531, 4.532965183258057, -1.1293078660964966, -2.465883493423462, 2.38620924949646, 3.1960978507995605, -0.8306865692138672, 0.1659506857395172, -1.5524617433547974, 0.2540983259677887, 1.2178560495376587, 3.200843572616577, -1.420032024383545, 1.701882004737854, 2.130821943283081, -1.1293078660964966, 1.594612717628479, -0.7632833123207092, -0.33173322677612305, -0.28552109003067017, -3.8464162349700928, -3.348540782928467, -2.5776960849761963, -0.7539721727371216, 1.128782868385315, 2.8380253314971924, 0.3967597782611847, -2.557199478149414, -0.35674649477005005, 0.5824238657951355, -2.094285249710083, -1.4502674341201782, -0.3505263328552246, 0.008555743843317032, 2.022860288619995, -2.291990041732788, 0.8818351626396179, 1.610668420791626, -2.415998935699463, -1.1293078660964966, -1.9592995643615723, -1.948509693145752, 2.0481679439544678, 0.6642979383468628, -2.2225701808929443, -0.5780377388000488, -0.6695176362991333, -2.2199723720550537, 1.5334478616714478, -1.3842523097991943, 0.2514631152153015, 0.6721741557121277, -2.360804319381714, 1.6807416677474976, 0.035157460719347, 1.812088966369629, -0.7632833123207092, 4.523426532745361, 1.7323299646377563, -1.595141053199768, -1.050831913948059, -0.13038185238838196, 4.682575225830078, 1.4923145771026611, -0.4618721604347229, 1.9764982461929321, 0.4585879445075989, -1.2785744667053223, -0.5680411458015442, -0.35223159193992615, -0.5875179767608643, 1.2156401872634888, -2.6858506202697754, -0.39968863129615784, 0.9361069798469543, -0.6303673982620239, 0.977859377861023, -0.35223159193992615, -2.1665492057800293, 4.566050052642822, 2.09784197807312, 1.101356863975525, -0.21337810158729553, -2.2199723720550537, -1.3279764652252197, 1.6474111080169678, -1.8832086324691772, 2.1453166007995605, 1.1534923315048218, -3.352851152420044, 2.002474308013916, 1.1702289581298828, -0.35223159193992615, 0.5495179891586304, 0.2175617516040802, 1.6083543300628662, -2.2199723720550537, 1.0376064777374268, -1.8965415954589844, 1.2540202140808105, 1.093658208847046, 2.082233428955078, 1.5775407552719116, 1.1511719226837158, -1.1293078660964966, 1.9013307094573975, 1.9690555334091187, 0.9673426151275635, -1.6654318571090698, -1.6250033378601074, -0.18220077455043793, -3.6026573181152344, -3.0483179092407227, 1.819309949874878, 1.9970813989639282, -0.643523633480072, -0.02730434574186802, 0.8781163096427917, -1.8965415954589844, -0.5935953259468079, -2.1477434635162354, -0.6303673982620239, -0.500562846660614, -1.7038707733154297, -0.06076213717460632, 4.4280009269714355, 1.9629859924316406, -4.061894416809082, -0.1633749008178711, -1.3820085525512695, -1.1293078660964966, -1.5821350812911987, 1.6025481224060059, -0.9177471995353699, -1.8965415954589844, -2.432953357696533, 2.578202486038208, -0.7607769966125488, -0.41780081391334534, -1.8104580640792847, 0.2762056589126587, 1.463840365409851, 1.8682150840759277, -1.2400975227355957, -0.6192284822463989, -0.9131049513816833, 1.5437922477722168, -1.0590237379074097, 1.7014617919921875, -1.1293078660964966, -2.783799886703491, -0.748837411403656, -0.6303673982620239, -1.2422313690185547, -3.8495614528656006, -0.6303673982620239, -0.9684569239616394, 1.4399527311325073, 2.3448548316955566, -0.6303673982620239, -1.8057807683944702, 1.0555800199508667, 2.0481679439544678, 1.911779522895813, -1.4498475790023804, -0.22594106197357178, -3.2011232376098633, -1.8965415954589844, 2.7967209815979004, -0.7160580158233643, -3.8495614528656006, -0.837561309337616, 0.12596452236175537, -0.6303673982620239, -1.3677338361740112, 0.7582213878631592, 2.070333480834961, -1.7688521146774292, -3.1056277751922607, -0.2730365991592407, 0.8953425288200378, 1.5726662874221802, -1.1293078660964966, -1.220510482788086, -0.16084033250808716, 0.2943280041217804, -0.6303673982620239, 0.2668796479701996, -0.3016704022884369, 1.9371384382247925, 0.9880262613296509, 1.2545613050460815, -1.8965415954589844]}],\n",
       "                        {\"height\": 800, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"width\": 1000, \"xaxis\": {\"zeroline\": false}, \"yaxis\": {\"zeroline\": false}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ef6554a8-d4a6-4452-971f-1e85c6192d93');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotly_plot_tsne(tsne_embeddings_3d, labels_3d, dimension=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der generierte Plot sollte ungefähr folgendermaßen aussehen (statisches Bild des interaktiven Plots zur Darstellung in GitHub):\n",
    "<img src=\"Images/plotly_tsne.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"WED\"></a>[WED]\n",
    "        </td>\n",
    "        <td>\n",
    "The Illustrated Word2vec – Jay Alammar – Visualizing machine ....\" 27 März. 2019, http://jalammar.github.io/illustrated-word2vec/. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"SAM\"></a>[SAM]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Word2Vec Tutorial - The Skip-Gram Model · Chris McCormick.\" 19 Apr.. 2016, http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"SWS\"></a>[SWS]\n",
    "        </td>\n",
    "        <td>\n",
    "\"The Illustrated Word2vec – Jay Alammar – Visualizing machine ....\" 27 März. 2019, http://jalammar.github.io/illustrated-word2vec/. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"NCE\"></a>[NCE]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Notes on Noise Contrastive Estimation and Negative Sampling.\" http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"CSM\"></a>[CSM]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Cosine similarity - Wikipedia.\" https://en.wikipedia.org/wiki/Cosine_similarity. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"TSN\"></a>[TSN]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Visualizing data using t-SNE - SlideShare.\" https://www.slideshare.net/KyeongUkJang/visualizing-data-using-tsne-149111155. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"TDS\"></a>[TDS]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Visualizing Data using t-SNE - Journal of Machine Learning Research.\" http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"HYP\"></a>[HYP]\n",
    "        </td>\n",
    "        <td>\n",
    "\"How to Use t-SNE Effectively - Distill.pub.\" 13 Okt.. 2016, https://distill.pub/2016/misread-tsne/. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FDS_Word2Vec.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "fds_word2vec",
   "language": "python",
   "name": "fds_word2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
