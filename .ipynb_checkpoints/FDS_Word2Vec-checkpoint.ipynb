{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausgewählte Kapitel sozial Webtechnologien - Neuronale Netze\n",
    "## Trainieren eines Word2Vec Modells und Darstellung von Wort- und Dokumentenvektoren anhand von Anfragetexten des FragDenStaat-Projektes\n",
    "\n",
    "Bearbeiten von:\n",
    "* Sebastian Jüngling (558556)\n",
    "* Konstantin Bruckert (558290)\n",
    "\n",
    "Prüfer:\n",
    "* Benjamin Voigt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einleitung\n",
    "Über das FragDenStaat-Portal werden Anfragen an Behörden in Deutschland gesammelt und zur Verfügung gestellt. Durch die stetig wachsende Popularität des Portals liegt diesem Projekt ein umfangreicher Datensatz vor, dessen Informationsgehalt im Laufe dieses Notebooks mithilfe eines Word2Vec Modells möglichst weit ausgeschöpft werden soll.\n",
    "\n",
    "**Grober Ablauf**<br>\n",
    "Zunächst werden die bereits bereinigten Daten für die Weiterverarbeitung aufbereitet und randomisiert. Tatsächliche Input-Daten werden daraufhin durch die Indexierung und Speicherung in Lookup-Tables generiert. Mithilfe von Context-Windows können nun Target-Label Paare aus Daten abgeleitet und für alle Sätze erzeugt werden. Das eigentliche Training innerhalb des Notebooks findet dann mithilfe eines Skip-Gramm Modells statt, welches in sequenziellen Batches über mehrere Epochen hinweg die Word-Emebddings trainiert. Die daraus resultierenden Word-Embeddings können nun genutzt werden, um Dokumenten-Vektoren aufzubauen und diese oder auch einfache Wort-Vektoren dann mithilfe der Cosine-Similarity zu verglichen. Abschließend wird versucht, die Word-Embeddings in verschieden Arten und unter Zuhilfenahme des t-SNE Dimensionsreduktionsverfahrens zu visualisieren bzw. Ähnlichkeiten zu clustern.\n",
    "\n",
    "**Grundlage/Inspiration**<br>\n",
    "Als Grundlage und grober Leitfaden für das Projekt diente das TensoFlow-Tutorial [Vector Representations of Words](https://www.tensorflow.org/tutorials/representation/word2vec). Ein Großteil der Architekturideen und Implementationsbausteine musste jedoch umgebaut werden und auf die speziellen Bedürfnisse unseres Datensatzes als auch die Ziele der Projektarbeit angepasst werden.\n",
    "\n",
    "**Hintergrundinformationen**<br>\n",
    "Für allgemeine Hintergrundinformationen zu den einzelnen hier im Modul angewandte Techniken und auch Details zur Entscheidungsfindung für bestimmte Ansätze, lohnt sich zudem ein Blick in das [Exposé](Documents/NN-Projekt-Expose.pdf).\n",
    "\n",
    "**Quellen**<br>\n",
    "Quellengestützte Aussagen und direkt/indirekt übernommene Inhalte sind mit einem dreistelligen Tag [XXX] versehen und können anhand diesem im Literaturverzeichnis am Ende des Notebooks eingesehen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "us2jJuCTNzou"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from tempfile import gettempdir\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten:\n",
    "Hier findet das Einladen des Anfragen-Katalogs des FragDenStaat-Projektes statt.  \n",
    "Die Daten wurden schon im Zuge der Werkstudententätigkeit von S. Jüngling im Vorfeld bezogen und weitestgehend aufbereitet.\n",
    "Dabei wurden die Texte auf ihre bedeutungstragenden Begriffe reduziert und die Wörter lemmatisiert.\n",
    "\n",
    "Beim Ausführen dieses Notebooks bitte darauf achten, die Daten gemäß der Anleitung in der README.md Datei herunterzuladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "id": "6jy-dki-Sbxc",
    "outputId": "19e9db64-9618-4bad-bf42-fee7bb83b4dd"
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('fds_requests_preprocessed.json', orient='records', encoding='utf-8')\n",
    "data = data.set_index('id') #set column 'id' as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "3VhuI9WkXbeH",
    "outputId": "5128ec4d-42eb-4cc7-fbab-7ed22836cf73",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>textrank</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47033</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, parkstern, berlin], [betrie...</td>\n",
       "      <td>[[parkstern, Parkstern, 1.1227777778], [berlin...</td>\n",
       "      <td>Kontrollbericht zu Parkstern, Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131943</th>\n",
       "      <td>Die Stellungnahme des BfR zur IARC- Monographi...</td>\n",
       "      <td>[[stellungnahme, bfr], [iarc, monographie, gly...</td>\n",
       "      <td>[[stellungnahme, Stellungnahme, 1.0], [bfr, Bf...</td>\n",
       "      <td>Stellungnahme des BfR zur IARC- Monographie üb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47827</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, aroma, berlin], [betriebsüb...</td>\n",
       "      <td>[[aroma, Aroma, 1.1227777778], [berlin, Berlin...</td>\n",
       "      <td>Kontrollbericht zu Aroma, Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131938</th>\n",
       "      <td>Die Stellungnahme des BfR zur IARC- Monographi...</td>\n",
       "      <td>[[stellungnahme, bfr], [iarc, monographie, gly...</td>\n",
       "      <td>[[stellungnahme, Stellungnahme, 1.0], [bfr, Bf...</td>\n",
       "      <td>Stellungnahme des BfR zur IARC- Monographie üb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48091</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht], [hans, glück, bonn], [betr...</td>\n",
       "      <td>[[bonn, Bonn, 1.2479166667000001], [hans, Hans...</td>\n",
       "      <td>Kontrollbericht zu \"Hans im Glück\", Bonn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  \\\n",
       "id                                                          \n",
       "47033   1. Wann haben die beiden letzten lebensmittelr...   \n",
       "131943  Die Stellungnahme des BfR zur IARC- Monographi...   \n",
       "47827   1. Wann haben die beiden letzten lebensmittelr...   \n",
       "131938  Die Stellungnahme des BfR zur IARC- Monographi...   \n",
       "48091   1. Wann haben die beiden letzten lebensmittelr...   \n",
       "\n",
       "                                             preprocessed  \\\n",
       "id                                                          \n",
       "47033   [[kontrollbericht, parkstern, berlin], [betrie...   \n",
       "131943  [[stellungnahme, bfr], [iarc, monographie, gly...   \n",
       "47827   [[kontrollbericht, aroma, berlin], [betriebsüb...   \n",
       "131938  [[stellungnahme, bfr], [iarc, monographie, gly...   \n",
       "48091   [[kontrollbericht], [hans, glück, bonn], [betr...   \n",
       "\n",
       "                                                 textrank  \\\n",
       "id                                                          \n",
       "47033   [[parkstern, Parkstern, 1.1227777778], [berlin...   \n",
       "131943  [[stellungnahme, Stellungnahme, 1.0], [bfr, Bf...   \n",
       "47827   [[aroma, Aroma, 1.1227777778], [berlin, Berlin...   \n",
       "131938  [[stellungnahme, Stellungnahme, 1.0], [bfr, Bf...   \n",
       "48091   [[bonn, Bonn, 1.2479166667000001], [hans, Hans...   \n",
       "\n",
       "                                                    title  \n",
       "id                                                         \n",
       "47033                Kontrollbericht zu Parkstern, Berlin  \n",
       "131943  Stellungnahme des BfR zur IARC- Monographie üb...  \n",
       "47827                    Kontrollbericht zu Aroma, Berlin  \n",
       "131938  Stellungnahme des BfR zur IARC- Monographie üb...  \n",
       "48091            Kontrollbericht zu \"Hans im Glück\", Bonn  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel für Preprocessing des Anfragetextes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titel und Description für Beispielanfrage:\n",
      "\n",
      "Kontrollbericht zu Aroma, Berlin\n",
      "1. Wann haben die beiden letzten lebensmittelrechtlichen Betriebsüberprüfungen im folgenden Betrieb stattgefunden:\r\n",
      "Aroma\r\n",
      "Kantstraße\r\n",
      "10625 Berlin\r\n",
      "\r\n",
      "2. Kam es hierbei zu Beanstandungen? Falls ja, beantrage ich hiermit die Herausgabe des entsprechenden Kontrollberichts an mich.\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Preprocessed Anfragetext für Titel und Anfragetext:\n",
      "\n",
      "[['kontrollbericht', 'aroma', 'berlin'], ['betriebsüberprüfungen', 'betrieb'], ['aroma', 'kantstraße', 'berlin'], ['beanstandung'], ['herausgabe', 'kontrollberichts']]\n"
     ]
    }
   ],
   "source": [
    "print('Titel und Description für Beispielanfrage:\\n')\n",
    "print(data.loc[47827]['title'])\n",
    "print(data.loc[47827]['description'])\n",
    "\n",
    "print('-------------------------------------------------------------------------')\n",
    "\n",
    "print('\\nPreprocessed Anfragetext für Titel und Anfragetext:\\n')\n",
    "print(data.loc[47827]['preprocessed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduzierung der Anzahl der Anfragen zu Glyphosat\n",
    "Immer wieder kommt es bei FragDenStaat zu einer Häufung tagespolitischer Themen, wie z.B. die Fragen rund um das Thema Glyphosat. Seit März 2019 sind hierzu bereits mehr als 30.000 Anfragen eingegangen, welche anhand eines immer gleichen Musters ausformuliert werden und somit das Training der globalen Datenmenge zu stark beeinflussen. Zur Reduzierung dieses Einflusses werden die Anfragen zu diesem Thema bei 3000 gedeckelt.\n",
    "Um auch in Zukunft und ggf. bei der Nutzung andersartiger Datensätze einwandfreie Ergebnisse zu erzielen, sollte regelmäßig geprüft werden, ob die Daten von einem bestimmten Thema dominiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Anfragen zu Glyphosat: 36199 von insgesamt: 92374 Anfragen\n",
      "Anzahl der Anfragen zu Glyphosat nach Bereinigung: 3000 von insgesamt: 59175 Anfragen\n"
     ]
    }
   ],
   "source": [
    "glyphosat_title = 'Stellungnahme des BfR zur IARC- Monographie über Glyphosat'\n",
    "glyphosat_ids = data[data['title'] == glyphosat_title].index\n",
    "\n",
    "print('Anzahl der Anfragen zu Glyphosat:', len(glyphosat_ids), 'von insgesamt:', len(data), 'Anfragen')\n",
    "\n",
    "# Da dies alle gleiche Anfragen sind und diese hohe Anzahl den Trainingsprozess verfälschen würde, \n",
    "# wird die Anzahl der Anfragen zu Glyphosat auf 3000 beschränkt\n",
    "remain_glyphosat_requests = 3000\n",
    "data.drop(glyphosat_ids[remain_glyphosat_requests:], inplace=True) # drop by id\n",
    "\n",
    "print('Anzahl der Anfragen zu Glyphosat nach Bereinigung:', len(data[data['title'] == glyphosat_title]), 'von insgesamt:', len(data), 'Anfragen')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Data:\n",
    "Während des Trainings mit den Daten konnte trotz der sorgfältigen Beseitigung dominanter Themen immer noch eine überproportionale Gewichtung der Glyphosat-Themen festgestellt werden. Das Problem lag hierbei im chronologisch vorliegenden Datensatz, welcher eine natürliche, große Abfolge von gleichen Themen nacheinander besitzt. Um die Word-Embeddings dadurch nicht zu stark in eine Richtung zu trainieren, werden die Anfragen randomisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>textrank</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85996</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, wirtshaus], [hof, starnberg...</td>\n",
       "      <td>[[hof, Hof, 1.2479166667000001], [tutzinger, T...</td>\n",
       "      <td>Kontrollbericht zu Wirtshaus Tutzinger Hof, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34119</th>\n",
       "      <td>Die Mitteilung der Firma Atos an die BRAK in d...</td>\n",
       "      <td>[[mitteilung, firma, atos, brak], [mitteilung,...</td>\n",
       "      <td>[[ifg-anfrage, IFG-Anfrage, 1.2137986111], [18...</td>\n",
       "      <td>Mitteilung der Firma Atos an die BRAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Abschrift des Telefonates von Bundespräsident ...</td>\n",
       "      <td>[[abschrift, telefonanruf], [abschrift, telefo...</td>\n",
       "      <td>[[abschrift, Abschrift, 1.647328125], [christi...</td>\n",
       "      <td>„Abschrift eines Telefonanrufes“</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Ich bitte um Übersendung des Gutachtens \"Recht...</td>\n",
       "      <td>[[gutachten], [rechtsfrage, kontext, abgeordne...</td>\n",
       "      <td>[[rechtsfrage, Rechtsfragen, 1.26435], [kontex...</td>\n",
       "      <td>Gutachten \"Rechtsfragen im Kontext der Abgeord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39396</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, regenbogen], [arbeit, gmbh]...</td>\n",
       "      <td>[[arbeit, Arbeit, 1.1761979167], [gmbh, GmbH, ...</td>\n",
       "      <td>Kontrollbericht zu Regenbogen Arbeit gemeinnüt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "id                                                         \n",
       "85996  1. Wann haben die beiden letzten lebensmittelr...   \n",
       "34119  Die Mitteilung der Firma Atos an die BRAK in d...   \n",
       "400    Abschrift des Telefonates von Bundespräsident ...   \n",
       "495    Ich bitte um Übersendung des Gutachtens \"Recht...   \n",
       "39396  1. Wann haben die beiden letzten lebensmittelr...   \n",
       "\n",
       "                                            preprocessed  \\\n",
       "id                                                         \n",
       "85996  [[kontrollbericht, wirtshaus], [hof, starnberg...   \n",
       "34119  [[mitteilung, firma, atos, brak], [mitteilung,...   \n",
       "400    [[abschrift, telefonanruf], [abschrift, telefo...   \n",
       "495    [[gutachten], [rechtsfrage, kontext, abgeordne...   \n",
       "39396  [[kontrollbericht, regenbogen], [arbeit, gmbh]...   \n",
       "\n",
       "                                                textrank  \\\n",
       "id                                                         \n",
       "85996  [[hof, Hof, 1.2479166667000001], [tutzinger, T...   \n",
       "34119  [[ifg-anfrage, IFG-Anfrage, 1.2137986111], [18...   \n",
       "400    [[abschrift, Abschrift, 1.647328125], [christi...   \n",
       "495    [[rechtsfrage, Rechtsfragen, 1.26435], [kontex...   \n",
       "39396  [[arbeit, Arbeit, 1.1761979167], [gmbh, GmbH, ...   \n",
       "\n",
       "                                                   title  \n",
       "id                                                        \n",
       "85996  Kontrollbericht zu Wirtshaus Tutzinger Hof, St...  \n",
       "34119              Mitteilung der Firma Atos an die BRAK  \n",
       "400                     „Abschrift eines Telefonanrufes“  \n",
       "495    Gutachten \"Rechtsfragen im Kontext der Abgeord...  \n",
       "39396  Kontrollbericht zu Regenbogen Arbeit gemeinnüt...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input-Daten generieren:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten aufbereiten\n",
    "Für die späteren Bearbeitungsschritte müssen die vorliegenden Anfragen aufbereitet und um Metainformationen erweitert werden.  \n",
    "Besonders die Indizierung der benutzten Wörter und das Erstellen entsprechender Lookup-Tables spielt im weiteren Verlauf des Notebooks eine vitale Rolle. \n",
    "Mit den daraus gewonnenen Wort-Indizes werden die Sätze der Anfragetexte nachgebaut. Für das Training wird außerdem die Gesamtanzahl der einzigartigen Wörter in allen Anfragetexten benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nxCqoQSTYBn"
   },
   "outputs": [],
   "source": [
    "def build_lookup_tables(docs, vocabulary_size=None):\n",
    "    '''\n",
    "    :param docs: Spalte eines pandas-DF: data['preprocessed'].values\n",
    "    :return sentences: Alle Sätze aller Dokumente in einer Liste\n",
    "    :return words: Alle Wörter aller Dokumente in einer Liste\n",
    "    :return word_count: Häufigkeiten der jeweiligen Wörter in allen Dokumenten\n",
    "    :return word_2_index_dict: \n",
    "    :return index_2_word_dict:\n",
    "    :return sentences_as_index: Alle Sätze aller Dokumente mit Wortindex, anstatt des Wortes\n",
    "    :return sentences_as_index_flattened: wie sentences_as_index, aber ohne subarrays\n",
    "    :return vocabulary_size: Anzahl der unique Wörter\n",
    "    '''\n",
    "    sentences = [sent for pd_list in docs for sent in pd_list]\n",
    "    words = [word for sent in sentences for word in sent]\n",
    "  \n",
    "    if not vocabulary_size:\n",
    "        # unique word count\n",
    "        vocabulary_size = len(set(words)) # because of unknown word\n",
    " \n",
    "    # count words\n",
    "    word_count = collections.Counter(words).most_common(vocabulary_size)\n",
    "    word_count.append(['UNK', -1]) # flag for words which are not common enqough\n",
    "  \n",
    "    # lookup-tables\n",
    "    word_2_index_dict = {}\n",
    "    for index, word in enumerate(word_count):\n",
    "        word_2_index_dict[word[0]] = index\n",
    "  \n",
    "    index_2_word_dict = dict(zip(word_2_index_dict.values(), word_2_index_dict.keys()))\n",
    "  \n",
    "    # Wörter der Anfragetexte durch Indizes austauschen:\n",
    "    sentences_as_index = []\n",
    "    unknown_word_count = 0\n",
    "    for sent in sentences:\n",
    "        sent_index = []\n",
    "        for word in sent:\n",
    "            if word in word_2_index_dict:\n",
    "                sent_index.append(word_2_index_dict[word])\n",
    "            else:\n",
    "                unknown_word_count += 1\n",
    "        if sent_index:\n",
    "            sentences_as_index.append(sent_index)\n",
    "    word_count[-1][1] = unknown_word_count\n",
    "\n",
    "    sentences_as_index_flattened = [word for sent in sentences_as_index for word in sent]\n",
    "  \n",
    "    return sentences, words, word_count, word_2_index_dict, index_2_word_dict, sentences_as_index, sentences_as_index_flattened, vocabulary_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2axsWl9ii25H"
   },
   "outputs": [],
   "source": [
    "sentences, words, word_count, word_2_index_dict, index_2_word_dict, sentences_as_index, sentences_as_index_flattened, vocabulary_size = build_lookup_tables(data['preprocessed'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiele:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Sätze der Anfragetexte in einer Liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "htJa8Opejkgl",
    "outputId": "592c135e-96e3-4ae4-c706-0b372efaee26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['kontrollbericht', 'parkstern', 'berlin'],\n",
       " ['betriebsüberprüfungen', 'betrieb'],\n",
       " ['parkstern', 'parkstraße', 'berlin'],\n",
       " ['beanstandung'],\n",
       " ['herausgabe', 'kontrollberichts']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattened data: only sentences\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Wörter aller Anfragetexte chronologisch in einer Liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CC0x0bS2jk93",
    "outputId": "7658adac-e306-4c36-c37b-73b83cd2fa77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kontrollbericht', 'parkstern', 'berlin', 'betriebsüberprüfungen', 'betrieb']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all words in docs\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzahl der Worthäufigkeiten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "o7AXFIVPjlPc",
    "outputId": "40571fd8-1d1a-4008-c7a3-2bc918fe47dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stellungnahme', 76768),\n",
       " ('glyphosat', 72480),\n",
       " ('bfr', 72432),\n",
       " ('iarc', 72419),\n",
       " ('monographie', 72415)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of words\n",
    "word_count[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wort zu Wortindex Lookuptable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "uYVuDGdRjlin",
    "outputId": "a2c897db-6785-478f-8d9f-fcaa4f980c49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stellungnahme': 0,\n",
       " 'glyphosat': 1,\n",
       " 'bfr': 2,\n",
       " 'iarc': 3,\n",
       " 'monographie': 4,\n",
       " 'dokument': 5,\n",
       " 'september': 6,\n",
       " 'arne': 7,\n",
       " 'semsrott': 8,\n",
       " 'betrieb': 9}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_2_index_dict\n",
    "# nur für Anschauungszwecke:\n",
    "{k: word_2_index_dict[k] for k in list(word_2_index_dict)[:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wortindex zu Wort Lookuptable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "2ZhDExldjlzf",
    "outputId": "f71b8bb2-bbbd-477c-b86e-5c9b8c4f4316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'stellungnahme',\n",
       " 1: 'glyphosat',\n",
       " 2: 'bfr',\n",
       " 3: 'iarc',\n",
       " 4: 'monographie',\n",
       " 5: 'dokument',\n",
       " 6: 'september',\n",
       " 7: 'arne',\n",
       " 8: 'semsrott',\n",
       " 9: 'betrieb'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index_2_word_dict\n",
    "# nur für Anschauungszwecke:\n",
    "{k: index_2_word_dict[k] for k in list(index_2_word_dict)[:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Wörter in allen Anfragesätzen ausgetauscht durch den jeweiligen Wortindex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "xjRpEGCGkHud",
    "outputId": "023dd201-62d0-4556-b4f9-c903648f7778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 29980, 22], [13, 9], [29980, 4020, 22], [12], [10, 14]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_as_index[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Wörter aller Anfragetexte chronologisch in einer Liste, ausgetauscht durch den Wortindex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pnrYmbeJMVpm",
    "outputId": "825ce233-a7f8-4b29-b506-e1b878de3bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 29980, 22, 13, 9, 29980, 4020, 22, 12, 10]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_as_index_flattened[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzahl aller einzigartigen Wörter aus allen Anfragetexten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mDjh9g9Tk5WS",
    "outputId": "36a24c11-c75f-4bfc-a283-b5fd71bbf659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95616"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input-Target-Wörter mit entsprechenden Labels aus Daten ableiten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "Essenziell für die folgenden Schritte ist ein generelles Verständnis von Word Embeddings. Ein Wort kann als ein Vektor mit einer beliebigen Anzahl von Features dargestellt werden. Die voreingestellten Parameter dieses Notebooks arbeiten mit 300 Features.\n",
    "Vergleichen wir beispielsweise die Word Embeddings der Wörter \"Hund\" und \"Katze\", so werden bestimmte Features innerhalb der beiden Vektoren eine Ähnlichkeit haben, u.a. an der Stelle wo das Modell die Kategorie \"Tier\" trainiert hat. Anhand eines Beispiels, in dem die Word Embedding Values mit Farben je nach Wert ersetzt wurden, lässt sich dieses Prinzip gut veranschaulichen:\n",
    "\n",
    "<img src=\"Images/king-man-woman-embedding.png\" alt=\"drawing\" width=\"500\"/>\n",
    "Quelle: [WED]\n",
    "\n",
    "\n",
    "### Language Modelling\n",
    "Je nach Ansatz ist es das Ziel eines Language Modells, für ein gegebenes Wort möglichst Präzise vorhersagen zu treffen, welches Wort darauf folgen könnte (CBOW) oder anhand eines Wortes die umgebenden Wörter vorherzusagen (Skipgram). Anhand der im vorherigen Abschnitt erstellten Word Embeddings können wir einzelne Wörter oder ganze Sätze leicht vergleichen und prüfen, ob Sie in einem kontextuellen Zusammenhang stehen. \n",
    "\n",
    "### Skip-Gram Model und Context Windows\n",
    "Folgende Abbildung skizziert die generelle Architektur eines Skip-Gram Modells:\n",
    "\n",
    "<img src=\"Images/skip_gram_net_architecuture.png\" alt=\"drawing\" width=\"600\"/>\n",
    "Quelle: [SAM]\n",
    "\n",
    "Im Notebook kommt es jedoch zu einigen Abweichungen von der Standard-Architektur, insbesondere bei der Klassifikation (siehe folgende Kapitel). <br>\n",
    "\n",
    "Natürlich muss ein solches Language-Modell zunächst ausgiebig trainiert werden. Mittels Context-Windows, also ein Ausschnitt von umgebenden Wörtern, versuchen wir Wort-Paare aus Target- und Label-Wörtern zu erstellen, die häufig zusammen auftreten. Angenommen wir nutzen Window-Size=2, dann betrachten wir in jedem Wort eines Satzes die zwei Wörter (\"labels\") vor und nach dem fokussierten Wort (\"target\") und notieren dieses gemeinsame Auftreten. In folgendem Beispiel wird die Context-Window Methode an einem Skip-Gram Modell dargestellt. Das Wort \"red\" ist ein target (=input) und die jeweils umgebenden Wörter sind die labels (=output):\n",
    "\n",
    "<img src=\"Images/skipgram-sliding-window-samples.png\" alt=\"drawing\" width=\"400\"/>\n",
    "Quelle: [SWS]\n",
    "\n",
    "Context-Windows arbeiten mit einzelnen Sätzen und beim Beginn und Ende eines jeden Satzes muss zudem darauf geachtet werden, dass mit dem Window nicht vor oder nach dem Satz (Nan) geslided wird. Die folgende Implementierung erzeugt nun die target-label paare, wobei anstelle realer Wörter im weiteren Verlauf die Wort-Indizes verwendet werden (siehe Beispiel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-0DEefWVVgF"
   },
   "outputs": [],
   "source": [
    "def get_context_window(input_data, target_index, window_size):\n",
    "    '''\n",
    "    Ermittelt umgebene Wörter abhängig von window_size und target_index des Wortes\n",
    "    :param input_data: Liste mit Wortindizes\n",
    "    :param: target_index: Listenindex des jeweiligen Wortes\n",
    "    :param window_size: Anzahl der Wörter links und rechts des target wortes\n",
    "    :return target value und liste der umgebenen Wörter\n",
    "    '''\n",
    "  \n",
    "    left_start_index = target_index - window_size if (target_index - window_size) >= 0 else 0\n",
    "  \n",
    "    right_start_index = target_index + 1\n",
    "    right_stop_index = target_index + window_size + 1\n",
    "  \n",
    "    target = input_data[target_index]\n",
    "    left_window = input_data[left_start_index:target_index]\n",
    "    right_window = input_data[right_start_index:right_stop_index]\n",
    "  \n",
    "    return target, left_window + right_window\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "tL2BjvxTXoHm",
    "outputId": "8209c344-3151-4a41-dea8-5b03b38096e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispielsatz aus Indizes: [0, 1, 2, 3, 4, 5]\n",
      "\n",
      "target word index: 0\n",
      "context words für window_size 2: [1, 2]\n",
      "\n",
      "target word index: 2\n",
      "context words für window_size 2: [0, 1, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "#example:\n",
    "input_data = list(range(6))\n",
    "print('Beispielsatz aus Indizes:', input_data)\n",
    "print()\n",
    "\n",
    "target_word_index, context_words = get_context_window(input_data, 0, 2)\n",
    "print('target word index:', target_word_index)\n",
    "print('context words für window_size 2:', context_words)\n",
    "\n",
    "target_word_index, context_words = get_context_window(input_data, 2, 2)\n",
    "print('\\ntarget word index:', target_word_index)\n",
    "print('context words für window_size 2:', context_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generiert Target-Wortliste mit entsprechenden Wortkontexten für alle Sätze der Anfragetexte:\n",
    "Nach den Beispielen kann die Context-Window Funktion nun auf alle Sätze in den Input-Daten angewandt werden. Weitere Beispiele mit Ausschnitten aus dem Gesamtdatenbestand bieten zudem zur besseren Veranschaulichung ein Re-Mapping der Word-Indexe auf die realen Wörter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-3OJiQbbPw1"
   },
   "outputs": [],
   "source": [
    "def build_targets_and_labels(input_data, window_size):\n",
    "    '''\n",
    "    Ermittelt alle targets und labels abhängig von der window_size\n",
    "    :param input_data: Liste mit Sublisten (Sätze)\n",
    "    :param window_size: Anzahl der Wörter links und rechts des target wortes\n",
    "    :return targets: Liste aller Targetwörter\n",
    "    :return labels: Liste aller Labels zu jeweiligem Targetwort\n",
    "    '''\n",
    "    targets = []\n",
    "    labels = []\n",
    "    for sent in input_data:\n",
    "        for index, word in enumerate(sent):\n",
    "            target_word_index, context_words = get_context_window(sent, index, window_size)\n",
    "            for context_word in context_words:\n",
    "                targets.append(target_word_index)\n",
    "                labels.append(context_word)\n",
    "    return targets, labels\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "t6nlmt7jgwj3",
    "outputId": "3b343462-481e-42c3-c52b-4dfb6d457db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erste zwei Beispielsätze mit Wortinidizes:\n",
      " [[11, 29980, 22], [13, 9]] \n",
      "\n",
      "Target Wortindizes: \n",
      " [11, 11, 29980, 29980, 22, 22, 13, 9]\n",
      "Lable Wortindizes: \n",
      " [29980, 22, 11, 22, 11, 29980, 9, 13]\n",
      "\n",
      "Beispiel für Mapping der Wortinindizes der Target und Label-liste:\n",
      "11 kontrollbericht -> 29980 parkstern\n",
      "11 kontrollbericht -> 22 berlin\n",
      "29980 parkstern -> 11 kontrollbericht\n",
      "29980 parkstern -> 22 berlin\n",
      "22 berlin -> 11 kontrollbericht\n",
      "22 berlin -> 29980 parkstern\n",
      "13 betriebsüberprüfungen -> 9 betrieb\n",
      "9 betrieb -> 13 betriebsüberprüfungen\n"
     ]
    }
   ],
   "source": [
    "input_data = sentences_as_index[:2]\n",
    "#input_data = [sentences_as_index_flattened]\n",
    "print('Erste zwei Beispielsätze mit Wortinidizes:\\n', input_data, '\\n')\n",
    "\n",
    "targets_list, labels_list = build_targets_and_labels(input_data, window_size=2)\n",
    "print('Target Wortindizes: \\n', targets_list)\n",
    "print('Lable Wortindizes: \\n', labels_list)\n",
    "\n",
    "print('\\nBeispiel für Mapping der Wortinindizes der Target und Label-liste:')\n",
    "for i in range(len(targets_list)):\n",
    "    print(targets_list[i], index_2_word_dict[targets_list[i]], '->', labels_list[i], index_2_word_dict[labels_list[i]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Trainings-Batch:\n",
    "Folgende Hilfsfunktion generiert iterativ Teilsequenzen (Batches) aus den target-label Paaren. Im Return der Funktion ist ein einzelner Batch und mithilfe der Variable `data_index` wird die aktuelle Iterationsposition im Gesamtdatensatz zwischengespeichert und resetted, sobald das Ende des Gesamtdatensatzes erreicht wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yiUq2UkhBtA"
   },
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "def generate_batch(batch_size, targets_list, labels_list):\n",
    "    '''\n",
    "    Generiert den Trainigs-Batch\n",
    "    #:param window_size: Anzahl der Wörter links und rechts des target wortes [TODO] KANN DAS RAUS???\n",
    "    :return batch: targets\n",
    "    :return labels\n",
    "    '''\n",
    "    global data_index\n",
    "    if data_index + batch_size > len(targets_list):\n",
    "        data_index = 0\n",
    "    batch = np.array(targets_list[data_index:data_index + batch_size], dtype=np.int32)\n",
    "    labels = np.array(labels_list[data_index:data_index + batch_size], dtype=np.int32)[:, np.newaxis]\n",
    "    #labels = np.array(labels_list[data_index:data_index + batch_size], dtype=np.int32).reshape((batch_size,1))\n",
    "    data_index += batch_size\n",
    "  \n",
    "    return batch, labels\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel für batch_size = 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "iUXnETiMiERm",
    "outputId": "e2299c78-fe77-423f-da90-a9691a4bd611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Indizes:\n",
      "[   11    11 29980 29980    22    22    13     9]\n",
      "\n",
      "Label Indizes\n",
      "[[29980]\n",
      " [   22]\n",
      " [   11]\n",
      " [   22]\n",
      " [   11]\n",
      " [29980]\n",
      " [    9]\n",
      " [   13]]\n",
      "\n",
      "Beispiel für Mapping der Wortinindizes der Target und Label-liste:\n",
      "11 kontrollbericht -> 29980 parkstern\n",
      "11 kontrollbericht -> 22 berlin\n",
      "29980 parkstern -> 11 kontrollbericht\n",
      "29980 parkstern -> 22 berlin\n",
      "22 berlin -> 11 kontrollbericht\n",
      "22 berlin -> 29980 parkstern\n",
      "13 betriebsüberprüfungen -> 9 betrieb\n",
      "9 betrieb -> 13 betriebsüberprüfungen\n"
     ]
    }
   ],
   "source": [
    "batch, labels = generate_batch(8, targets_list, labels_list)\n",
    "print('Target Indizes:')\n",
    "print(batch)\n",
    "\n",
    "print('\\nLabel Indizes')\n",
    "print(labels)\n",
    "\n",
    "print('\\nBeispiel für Mapping der Wortinindizes der Target und Label-liste:')\n",
    "for i in range(len(batch)):\n",
    "    print(batch[i], index_2_word_dict[batch[i]], '->', labels[i, 0], index_2_word_dict[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baue und Trainiere das Skip-Gram Model\n",
    "Bis hierhin sollte klar sein was die Funktion eines Skip-Gram Models und deren target-label Paaren, eines Context Window und eines Batches ist. Mit diesem Wissen steht dem eigentlichen Model-Training nichts mehr im Wege! Fast. Vor dem Training bietet sich zunächst die letzte Möglichkeit, mit einstellbaren Parametern Einfluss auf den Verlauf des Trainings zu nehmen. Neben den bereits bekannten Begriffen müssen noch ein paar wenige, neue Parameter verstanden und eingestellt werden, die einen erheblichen Einfluss auf den weiteren Trainingsverlauf ausüben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstellbare Parameter:\n",
    "\n",
    "* `batch_size`: Anzahl der berücksichtigten Target-Label-Paare pro Trainingsiteration\n",
    "* `embedding_size`: Dimensionsgröße der Word-Embeddings \n",
    "    * -> Wert von 300 zeigt sich als guter Kompromiss von Performance und Genauigkeit\n",
    "* `skip_window`: Anzahl der berüchtigten Wörter links und rechts (Nachbarwörter) eines Targetwortes für Bildung der Target-Label-Paare\n",
    "* `num_sampled` Anzahl der Negative Samples für NCE Loss (siehe weiter unten)\n",
    "* Anpassung der sich exponentiell verringerten Lernrate (Start-/End-Learning-Rate)\n",
    "* `epochs`: Anzahl der Epochen, also Anzahl der Iterationen die benötigt werden, um einmal alle Target-Label-Paare zu durchlaufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVj4YN6KTK40"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "embedding_size = 300 # Dimension der Word-Embeddings\n",
    "skip_window = 2  # Anzahl der Wörter links und rechts vom Target-Wort\n",
    "num_sampled = 64 #64 # Anzahl der negative samples\n",
    "\n",
    "# Die Lernrate wird je Iteration verringert:\n",
    "starter_learning_rate = 1.0\n",
    "end_learning_rate = 0.1\n",
    "\n",
    "epochs = 1 # Anzahl der Epochen. Eine Epoche ist eine Iteration durch den kompletten Trainingsbestand\n",
    "print_every_x_step = 2000 # alle x Iterationen werden infos geprintet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generieren der Target- und Labelliste für alle Anfragetexte, basierend auf der eingestellten Skip Window Size:\n",
    "\n",
    "Zu Beginn des Trainings werden nun alle Target-Label Paare aller Anfragetexte des Gesamtdatenbestandes aufgrund der im vorherigen Schritt eingestellten Window-Size generiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_list, labels_list = build_targets_and_labels(sentences_as_index, window_size=skip_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es folgen einige Berechnungen für wichtige, fixe Parameter, die aus den einstellbaren Parametern abgeleitet werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Target-Label-Paare: 3099230\n",
      "24213 Iterationen werden benötigt um einmal während des Trainings durch alle Target-Label-Paare zu iterieren\n",
      "Iterationen während des Trainings: 24213\n"
     ]
    }
   ],
   "source": [
    "data_index = 0 # für batch start\n",
    "\n",
    "exp_decay_lr = starter_learning_rate - end_learning_rate\n",
    "\n",
    "input_length = len(targets_list) # Anzahl der Target-Label-Paare\n",
    "print('Anzahl Target-Label-Paare:', input_length)\n",
    "\n",
    "full_iteration_cycle = int(math.ceil(input_length / batch_size))\n",
    "print(full_iteration_cycle, 'Iterationen werden benötigt um einmal während des Trainings durch alle Target-Label-Paare zu iterieren')\n",
    "\n",
    "num_steps = full_iteration_cycle * epochs\n",
    "print('Iterationen während des Trainings:', num_steps)\n",
    "\n",
    "epsilon=1e-12 # dont touch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Graph:\n",
    "\n",
    "Mit eingestellten Parametern und allen generierten Target-Label Paaren der Anfragetexte kann nun die Modellarchitektur festgelegt werden. Zunächst werden Tensorflow Placeholder definiert und dann die Word Embedings (Anzahl uniquer Wörter x Anzahl Features/Dimension) mit einem random Wert zwischen 0 und 1 initialisiert. Auf die gleiche Weiße erhalten auch unsere NCE-Weights (Erklärung folgt) initiale Werte. Der Bias wird mit Nullen initialisiert. Bereits im vorherigen Schritt wurd die Start-Lernrate errechnet (delta aus maximal- und minimal-lernrate), welche nun in der Modell-Architektur in eine exponential-decay Funktion gepackt wird und somit im späteren Training evolutionär angepasst werden kann. Für die komplette Trainingsarchitektur fehlt jetzt nur noch ein Klassifizierungsverfahren und eine Loss-Funktion.\n",
    "\n",
    "## Noise Contrastive estimation (NCE)\n",
    "\n",
    "Remember: Für ein gegebenes Wort (target) soll das Modell die Wahrscheinlichkeit der passenden Kontextwörter (labels) bestimmen. Ein weitverbreitetes und erfahrungsgemäß gutes Klassifizierungsverfahren hierfür ist der Softmax-Classifier. Dieser stellte sich aber während des Trainings als maximal rechenintensiv heraus, da für jedes Wort das ganze Vokabular (mehr als 1 Mio Wörter) mit Wahrscheinlichkeiten belegt werden muss, bzw. die Gewichtsmatrix `[embedding_dim x vocab_dim]` sehr groß ist ([Wiederholung: Softmax-Klassifier](https://www.pyimagesearch.com/2016/09/12/softmax-classifiers-explained/), [Hintergrundwissen: Warum kein Softmax?](https://arxiv.org/pdf/1410.8251.pdf))\n",
    "\n",
    "Um diese Rechenoperation zu vermeiden, aber trotzdem keine spürbaren Einbußen beim Training der Word-Emebdings zu erleiden, kann NCE genutzt werden. Hierbei wird das Gesamtvokabular, also die Menge an Wörtern die auf Ähnlichkeit überprüft werden, auf einen Teil mit dem/den passenden Label/n und einen Teil mit gänzlich unpassenden Wörtern (\"Contrastive Noise\") reduziert. Zudem wird die Vorhersage auf ein Klassifikationsproblem (richtig/falsch) reduziert (vgl. Softmax: Normalverteilt), (korrekte) labels und (gegensätzliche) noise bekommen also die Werte 0 und 1. Das Modell kann somit anhand sehr guter und schlechter Begriffe lernen, ohne dabei jedes Mal das gesamte Vokabular durchforsten zu müssen. Hierin liegt zugleich der entscheidende Punkt bei NCE: Wir können unsere Noise-Verteilung frei bestimmen, z.B. können nur Wörter mit ganz geringer Häufigkeit selektiert, oder alle Wörter mit gleicher Wahrscheinlichkeit oder einfach eine Normalverteilung. Durch diese künstliche Reduzierung der Grunddatenmenge wird jedoch nicht die Genauigkeit des Models in Mitleidenschaft gezogen (QUELLE: [NCE]). \n",
    "Da das Problem bereits auf eine klassische \"Richtig oder Falsch\"-Frage reduziert wurde, kann in NCE die logistische Regression zur Klassifikation herangezogen werden und dann unsere Word-Embeddings mit dem GradientDescentOptimizer optimiert werden. Eine weiterführende Erklärung mit detaillierten Hintergrundinfos zu NCE findet sich [hier](https://towardsdatascience.com/noise-contrastive-estimation-246446ea9aba) und [hier](http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf).\n",
    "\n",
    "In einer früheren Version des Notebooks wurde in diesem Abschnitt auch noch eine Normalisierung der Word-Embeddings auf Werte zwischen 0 und 1 durchgeführt. In zahlreichen Testläufen konnte sich dadurch jedoch keine verbesserte Genauigkeit oder Performance ausmachen und die Ergebnisse der Cosine-Similarity wurden verfälscht, weswegen dieser Part auskommentiert ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.197224577336219\n"
     ]
    }
   ],
   "source": [
    "test = np.log(0.1/0.9)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "vpEXenMKUWkk",
    "outputId": "666d61c9-50f4-4931-c5be-800356a3fa4b"
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input Daten\n",
    "    with tf.name_scope('inputs'):\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "        train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "        iteration = tf.placeholder(tf.int32)\n",
    "  \n",
    "    # Benutze CPU:\n",
    "    with tf.device('/cpu:0'):\n",
    "        with tf.name_scope('embeddings'):\n",
    "            #embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "            # init embeddings:\n",
    "            embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], 0.001, 1.0))\n",
    "            # embeddings lookup table:\n",
    "            embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "     \n",
    "        # TODO\n",
    "        # Construct the variables for the NCE loss\n",
    "        with tf.name_scope('weights'):\n",
    "            nce_weights = tf.Variable(\n",
    "                tf.truncated_normal(\n",
    "                    [vocabulary_size, embedding_size],\n",
    "                    stddev=1.0 / math.sqrt(embedding_size)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Bias:\n",
    "        with tf.name_scope('biases'):\n",
    "            nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # TODO\n",
    "    # Compute the average NCE loss for the batch.\n",
    "    # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "    # time we evaluate the loss.\n",
    "    # Explanation of the meaning of NCE loss:\n",
    "    #   http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(\n",
    "                weights=nce_weights,\n",
    "                biases=nce_biases,\n",
    "                labels=train_labels,\n",
    "                inputs=embed,\n",
    "                num_sampled=num_sampled,\n",
    "                num_classes=vocabulary_size)\n",
    "        )      \n",
    "  \n",
    "    #Lernrate:\n",
    "    with tf.name_scope('lr'):\n",
    "        # Verringert Lernrate exponentiell, abhäging von der aktuellen Trainigsiteration\n",
    "        lr = end_learning_rate +  tf.train.exponential_decay(exp_decay_lr, iteration, 10000, 1/math.e)\n",
    "\n",
    "    # Gradient Descent optimizer mit entsprechender Lernrate und Minimieren des Loss\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    \n",
    "    # normalize embeddings to be in range [0, 1]\n",
    "    '''normalized_embeddings = tf.math.divide(\n",
    "        tf.subtract(\n",
    "            embeddings,\n",
    "            tf.reduce_min(embeddings)\n",
    "        ),\n",
    "        tf.maximum(\n",
    "            tf.subtract(\n",
    "                tf.reduce_max(embeddings),\n",
    "                tf.reduce_min(embeddings)\n",
    "            ),\n",
    "            epsilon\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #normalized_embeddings = tf.to_float(normalized_embeddings)\n",
    "    normalized_embeddings = tf.dtypes.cast(normalized_embeddings, tf.float32)'''\n",
    " \n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: \n",
    "Alle Vorbereitungsschritte des Notebooks werden hier zusammengeführt. Das Modell wird mit den eingestellten Parametern und den definierten Input-Daten trainiert, die Zwischenstände werden ausgegeben und die finalen Word-Embeddings werden gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "NB2sTAXdXE5a",
    "outputId": "df06d536-cb21-4ee5-e5c9-2e26b7aeb7eb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration-Step: 0\n",
      "\tAverage loss:\t 324.087890625 \n",
      "\tlearning-rate:\t 1.0\n",
      "Iteration-Step: 2000\n",
      "\tAverage loss:\t 147.48916181945802 \n",
      "\tlearning-rate:\t 0.8368577\n",
      "Iteration-Step: 4000\n",
      "\tAverage loss:\t 83.62571663999557 \n",
      "\tlearning-rate:\t 0.7032881\n",
      "Iteration-Step: 6000\n",
      "\tAverage loss:\t 59.75910635614395 \n",
      "\tlearning-rate:\t 0.5939305\n",
      "Iteration-Step: 8000\n",
      "\tAverage loss:\t 46.12099146902561 \n",
      "\tlearning-rate:\t 0.5043961\n",
      "Iteration-Step: 10000\n",
      "\tAverage loss:\t 37.31725548797846 \n",
      "\tlearning-rate:\t 0.4310915\n",
      "Iteration-Step: 12000\n",
      "\tAverage loss:\t 30.817964761555196 \n",
      "\tlearning-rate:\t 0.37107483\n",
      "Iteration-Step: 14000\n",
      "\tAverage loss:\t 26.153631504297255 \n",
      "\tlearning-rate:\t 0.32193726\n",
      "Iteration-Step: 16000\n",
      "\tAverage loss:\t 22.184831806361675 \n",
      "\tlearning-rate:\t 0.2817069\n",
      "Iteration-Step: 18000\n",
      "\tAverage loss:\t 20.39656142038107 \n",
      "\tlearning-rate:\t 0.24876902\n",
      "Iteration-Step: 20000\n",
      "\tAverage loss:\t 18.16517237865925 \n",
      "\tlearning-rate:\t 0.22180176\n",
      "Iteration-Step: 22000\n",
      "\tAverage loss:\t 16.89321248012781 \n",
      "\tlearning-rate:\t 0.19972284\n",
      "Iteration-Step: 24000\n",
      "\tAverage loss:\t 15.726911895751954 \n",
      "\tlearning-rate:\t 0.18164617\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    # Initialisieren alle Variablen\n",
    "    init.run()\n",
    "  \n",
    "    average_loss = 0\n",
    "  \n",
    "    # Train:\n",
    "    for step in xrange(num_steps):\n",
    "        # generieren der Batches\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size, targets_list, labels_list)\n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels, iteration: step}\n",
    "    \n",
    "        # Ausführen eines einzelnen Update Steps, durch Evaluierung des GradientDescent Optimizers\n",
    "        # Minimieren des Loss und Updaten der Gewichte\n",
    "        _, loss_val, learn_rate = session.run(\n",
    "            [optimizer, loss, lr],\n",
    "            feed_dict=feed_dict)\n",
    "    \n",
    "        average_loss += loss_val\n",
    "        \n",
    "        # print Learing Rate:\n",
    "        if step % print_every_x_step == 0: \n",
    "            if step > 0:\n",
    "                average_loss /= print_every_x_step\n",
    "            print('Iteration-Step:', step)\n",
    "            print('\\tAverage loss:\\t', average_loss, '\\n\\tlearning-rate:\\t', learn_rate)\n",
    "            average_loss = 0\n",
    "        \n",
    "    # Generierte Embeddings für weitere Schritte verfügbar machen:\n",
    "    #final_embeddings = normalized_embeddings.eval()\n",
    "    final_embeddings = embeddings.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dokumenten-Vektoren generieren:\n",
    "Die im vorherigen Schritt trainierten Word-Embeddings können nun genutzt werden, um pro Anfragetext einen Dokumenten-Vektor aus den Word-Embeddings der jeweiligen Wörter des Textes abzuleiten.\n",
    "Dabei werden alle Word-Embeddings eines Dokuments spaltenweise gemittelt, um dieses Dokument dann anhand eines einzelnen Vektors zu repräsentieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_embedding(doc):\n",
    "    '''\n",
    "    :param doc: list of sentences with lemmatized words\n",
    "    :return: document vector\n",
    "    '''\n",
    "    word_vecs = np.array([\n",
    "        final_embeddings[word_2_index_dict[word]] for sent in doc for word in sent if word in word_2_index_dict\n",
    "    ])\n",
    "    return np.mean(word_vecs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dokumenten-Vektoren für alle Anfragen generieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['doc_vector'] = data['preprocessed'].apply(lambda prepr_text: get_doc_embedding(prepr_text) if prepr_text else np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch vereinzelte Fehler im Preprocessing entstehen einige Null-Rows die hier manuell korriegiert werden müssen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description     0\n",
       "preprocessed    0\n",
       "textrank        0\n",
       "title           0\n",
       "doc_vector      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description     0\n",
       "preprocessed    0\n",
       "textrank        0\n",
       "title           0\n",
       "doc_vector      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auszug aus den Daten mit Dokumenten-Vektoren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>textrank</th>\n",
       "      <th>title</th>\n",
       "      <th>doc_vector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85996</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, wirtshaus], [hof, starnberg...</td>\n",
       "      <td>[[hof, Hof, 1.2479166667000001], [tutzinger, T...</td>\n",
       "      <td>Kontrollbericht zu Wirtshaus Tutzinger Hof, St...</td>\n",
       "      <td>[-0.23179139, 0.27382377, 0.44830117, 0.304698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34119</th>\n",
       "      <td>Die Mitteilung der Firma Atos an die BRAK in d...</td>\n",
       "      <td>[[mitteilung, firma, atos, brak], [mitteilung,...</td>\n",
       "      <td>[[ifg-anfrage, IFG-Anfrage, 1.2137986111], [18...</td>\n",
       "      <td>Mitteilung der Firma Atos an die BRAK</td>\n",
       "      <td>[0.34767908, 0.42688254, 0.484126, 0.454184, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Abschrift des Telefonates von Bundespräsident ...</td>\n",
       "      <td>[[abschrift, telefonanruf], [abschrift, telefo...</td>\n",
       "      <td>[[abschrift, Abschrift, 1.647328125], [christi...</td>\n",
       "      <td>„Abschrift eines Telefonanrufes“</td>\n",
       "      <td>[0.30048302, 0.35346866, 0.36373973, 0.4459112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Ich bitte um Übersendung des Gutachtens \"Recht...</td>\n",
       "      <td>[[gutachten], [rechtsfrage, kontext, abgeordne...</td>\n",
       "      <td>[[rechtsfrage, Rechtsfragen, 1.26435], [kontex...</td>\n",
       "      <td>Gutachten \"Rechtsfragen im Kontext der Abgeord...</td>\n",
       "      <td>[-0.35373476, 0.053725757, 0.28752273, 0.25282...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39396</th>\n",
       "      <td>1. Wann haben die beiden letzten lebensmittelr...</td>\n",
       "      <td>[[kontrollbericht, regenbogen], [arbeit, gmbh]...</td>\n",
       "      <td>[[arbeit, Arbeit, 1.1761979167], [gmbh, GmbH, ...</td>\n",
       "      <td>Kontrollbericht zu Regenbogen Arbeit gemeinnüt...</td>\n",
       "      <td>[-0.0548466, 0.35513285, 0.2104664, 0.22997937...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "id                                                         \n",
       "85996  1. Wann haben die beiden letzten lebensmittelr...   \n",
       "34119  Die Mitteilung der Firma Atos an die BRAK in d...   \n",
       "400    Abschrift des Telefonates von Bundespräsident ...   \n",
       "495    Ich bitte um Übersendung des Gutachtens \"Recht...   \n",
       "39396  1. Wann haben die beiden letzten lebensmittelr...   \n",
       "\n",
       "                                            preprocessed  \\\n",
       "id                                                         \n",
       "85996  [[kontrollbericht, wirtshaus], [hof, starnberg...   \n",
       "34119  [[mitteilung, firma, atos, brak], [mitteilung,...   \n",
       "400    [[abschrift, telefonanruf], [abschrift, telefo...   \n",
       "495    [[gutachten], [rechtsfrage, kontext, abgeordne...   \n",
       "39396  [[kontrollbericht, regenbogen], [arbeit, gmbh]...   \n",
       "\n",
       "                                                textrank  \\\n",
       "id                                                         \n",
       "85996  [[hof, Hof, 1.2479166667000001], [tutzinger, T...   \n",
       "34119  [[ifg-anfrage, IFG-Anfrage, 1.2137986111], [18...   \n",
       "400    [[abschrift, Abschrift, 1.647328125], [christi...   \n",
       "495    [[rechtsfrage, Rechtsfragen, 1.26435], [kontex...   \n",
       "39396  [[arbeit, Arbeit, 1.1761979167], [gmbh, GmbH, ...   \n",
       "\n",
       "                                                   title  \\\n",
       "id                                                         \n",
       "85996  Kontrollbericht zu Wirtshaus Tutzinger Hof, St...   \n",
       "34119              Mitteilung der Firma Atos an die BRAK   \n",
       "400                     „Abschrift eines Telefonanrufes“   \n",
       "495    Gutachten \"Rechtsfragen im Kontext der Abgeord...   \n",
       "39396  Kontrollbericht zu Regenbogen Arbeit gemeinnüt...   \n",
       "\n",
       "                                              doc_vector  \n",
       "id                                                        \n",
       "85996  [-0.23179139, 0.27382377, 0.44830117, 0.304698...  \n",
       "34119  [0.34767908, 0.42688254, 0.484126, 0.454184, 0...  \n",
       "400    [0.30048302, 0.35346866, 0.36373973, 0.4459112...  \n",
       "495    [-0.35373476, 0.053725757, 0.28752273, 0.25282...  \n",
       "39396  [-0.0548466, 0.35513285, 0.2104664, 0.22997937...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity:\n",
    "Cosine Similarity ist eine gängige Möglichkeit, um die Ähnlichkeit zweier Vektoren zu ermitteln. Mithilfe des Abstandswinkels zwischen den beiden Vektoren wird ein Wert zwischen 0 und 1 erzeugt, welcher das Ähnlichkeitsmaß ausdrückt. Einfache, 2-Dimensionale Vektoren können hierbei noch per Hand errechnet werden. Cosine-Similarity funktioniert jedoch mit einer beliebigen Anzahl von Vektor-Dimensionen und ist somit für den Vergleich unserer Dokumenten- oder Wort-Vektoren hervorragend geeignet.\n",
    "\n",
    "Formel:\n",
    "![image](Images/Cosine_Similarity_Formula.png)\n",
    "\n",
    "\n",
    "Quelle: [CSM]\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "|Person/Eigenschaft|  EG1 \t| EG2 \t|  EG3 \t|\n",
    "|:-----------:\t|:----:\t|:---:\t|:----:\t|\n",
    "|  Konstantin \t| 10 \t| 50 \t|  200 \t|\n",
    "|  Sebastian  \t|  400 \t| 100 \t| 20 \t|\n",
    "| Prof. Herta \t|  10 \t| 5 \t|  1 \t|\n",
    "\n",
    "Ähnlichkeit von Konstantin und Sebastian: <br>\n",
    "Cosine_Similarity ( [10,50,200] , [400, 100, 20]) = 0.15\n",
    "\n",
    "Ähnlichkeit von Sebastian und Prof. Herta: <br>\n",
    "Cosine_Similarity ( [400, 100, 20], [10, 5, 1]) = 0.23\n",
    "\n",
    "Ähnlichkeit von Konstantin und Prof. Herta: <br>\n",
    "Cosine_Similarity ( [10,50,200], [10, 5, 1]) = 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(v1, v2):\n",
    "    n1 = np.linalg.norm(v1)\n",
    "    n2 = np.linalg.norm(v2)\n",
    "    return np.dot(v1, v2) / n1 / n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity for herausgabe and bekleidung\n",
      "\t 0.5734157\n"
     ]
    }
   ],
   "source": [
    "#negativbeispiel\n",
    "word1 = 'herausgabe'\n",
    "word2 = 'bekleidung'\n",
    "print('cosine similarity for', word1, 'and', word2)\n",
    "print('\\t', similarity(final_embeddings[word_2_index_dict[word1]], final_embeddings[word_2_index_dict[word2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity for bfr and iarc\n",
      "\t 0.68144995\n"
     ]
    }
   ],
   "source": [
    "#positivbeispiel\n",
    "word1 = 'bfr'\n",
    "word2 = 'iarc'\n",
    "print('cosine similarity for', word1, 'and', word2)\n",
    "print('\\t', similarity(final_embeddings[word_2_index_dict[word1]], final_embeddings[word_2_index_dict[word2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_similarity(df, id_1, id_2):\n",
    "    print('Doc #1:')\n",
    "    print('\\tTitel:', df.loc[id_1]['title'])\n",
    "    \n",
    "    print('\\nDoc #2:')\n",
    "    print('\\tTitel:', df.loc[id_2]['title'])\n",
    "    \n",
    "    print('\\nSimilarity [0-1]:', similarity(df.loc[id_1]['doc_vector'], df.loc[id_2]['doc_vector']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc #1:\n",
      "\tTitel: Kontrollbericht zu Bartz, Arzfeld\n",
      "\n",
      "Doc #2:\n",
      "\tTitel: Kontrollbericht zu Mamma Italia, Esslingen am Neckar\n",
      "\n",
      "Similarity [0-1]: 0.9425657\n"
     ]
    }
   ],
   "source": [
    "#positivbesipiel\n",
    "doc_similarity(data, 58945, 48729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc #1:\n",
      "\tTitel: Kontrollbericht zu Bartz, Arzfeld\n",
      "\n",
      "Doc #2:\n",
      "\tTitel: Ortsumgehung Barnstorf, Landreis Diepholz\n",
      "\n",
      "Similarity [0-1]: 0.7853049\n"
     ]
    }
   ],
   "source": [
    "#negativbeispiel\n",
    "doc_similarity(data, 58945, 58948)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den errechneten Document-Embeddings erhalten wir eine hochdimensionale (in unserem Fall 300) und komplexe Datenmatrix, die sich dank des t-SNE Algorithmus in geringeren Dimensionen, meist 2- oder 3-dimensional, visualisieren lässt. Natürlich erzeugt diese Verringerung einen gewissen Informationsverlust, der wie im folgendem Beschrieben möglichst gering gehalten werden soll. Eine Darstellung unserer Document-Embeddings mittels t-SNE ist besonders geeignet um Strukturen im visualisierten Datensatz, wie lokale Nachbarschaften oder Wort-/Dokumenten-Gruppierung, zu erkennen. Ähnliche Anfragen werden sich somit voraussichtlich clustern und es entsteht eine dreidimensionale Visualisierung, die einen ersten Überblick über die semantischen Zusammenhänge zwischen den Anfragetexten gibt.\n",
    "\n",
    "## t-SNE Grundprinzip:\n",
    "Wie so oft, muss das Rad nicht neu erfunden werden und man kann eine optimierte Implementierung des t-SNE bereits über das sklearn-kit beziehen. Um zu verstehen, was sich im Hintergrund abspielt, hier ein Versuch die Funktionsweise anhand eines Beispiels zu erläutern:\n",
    "\n",
    "**Das Ziel**: Punkte aus dem 2-dimensionalen Raum, 1-dimensional darzustellen.\n",
    "\n",
    "<img src=\"Images/tSNE_Ziel.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**Abstände Messen:** Dazu wird ein Punkt in den Fokus genommen und die Abstände zu den anderen Punkten wird normalverteilt gemessen. Aus der höheren Dimension wird also die Entfernung auf der reduzierten Dimension abgebildet und dann die Entfernung zur Normalverteilungskurve gemessen.\n",
    "\n",
    "<img src=\"Images/tSNE_Normalverteilt.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**Normalverteilung in Matrix überführen:** Dadurch ist es möglich, eine Matrix aufzubauen, wo zu jedem Punkt die Entfernung zu einem anderen Punkt (bzw. dessen Entfernung zur Normalverteilungskurve) abgebildet werden kann. Eine Entfernung von einem Punkt zu sich selbst macht hierbei natürlich keinen Sinn.\n",
    "\n",
    "<img src=\"Images/tSNE_Matrix1.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**Wiederholung mit t-Verteilung:** Im nächsten Schritt wiederholen wird der gesamte Prozess bis hierhin wiederholt, jedoch nicht mit der t-Verteilung und einem Freiheitsgrad (Cauchy-Verteilung) anstelle der Normalverteilung. Es entsteht eine weit unpräzisere Anordnung der Punkte in unserer t-Matrix:\n",
    "\n",
    "<img src=\"Images/tSNE_Matrix2.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "Auch auf die x-Achse projeziert ergeben die Entfernungen (noch) keinen Sinn:\n",
    "\n",
    "<img src=\"Images/tSNE_t_map.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**t-Verteilung und Normalverteilung angleichen:** Im nächsten Schritt versuchen wir, die Punkte in der niedrigeren Dimension (hier: 1-D, bzw. x-Achse) der t-Verteilung so lange zu verschieben, bis dieser denen, der Normalverteilung gleichen. Dazu schiebt der t-SNE Algorithmus immer einen Punkt in der Matrix näher an seine Ziel-Koordinate und vollzieht den gleichen Schritt auf der x-Achse.\n",
    "\n",
    "<img src=\"Images/tSNE_t_finish.png\" alt=\"drawing\" width=\"300\"/>\n",
    "Quelle: [TSN]\n",
    "\n",
    "**Weiterer Verlauf:** Im Beispiel wurde von 2- auf 1-Dimensionalität reduziert. Voreingestellte Parameter im Notebook trainieren jedoch Word-Embeddings mit deutlich mehr Dimensionen (hier: 300). Schrittweise reduziert t-SNE die Dimensionen, eine nach der anderen, bis zur gewünschten Ziel-Dimension. Für normale Bildschirme wären das die Dimensionen 1-3 (Beispiel siehe folgende Kapitel).\n",
    "\n",
    "\n",
    "### Warum wird die t-Verteilung hier benötigt? \n",
    "Hier wird es kompliziert: Das zugrunde liegende Verfahren erfordert ein tiefer gehendes mathematisches Verständnis von Verteilungsfunktionen und sprengt den Rahmen des Notebooks. Hilfreiche Links und Sekundärliteratur finden sich [hier](https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm) und [hier](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf). \n",
    "<br><br>Eine kurze Erklärung in eigenen Worten:\n",
    "Der Ansatz für die Nutzung der t-Verteilung liegt im Unterschied der Verteilungsfunktionen. \n",
    "Würde beim Reduzieren der Dimensionen eines Datensatzes die Normalverteilung herangezogen werden, so käme es zu einer Disbalance der Verteilung von Punkten und deren Distanz zu Ihren Nachbarn. Der Grund hierfür ist der große Unterschied des Maßes einer Entfernung in unterschiedlichen Dimensionen, welche der Algorithmus versucht abzubilden. Um dieser Divergenz an Maßen gerecht zu werden, nutzt t-SNE die t-Verteilung (daher auch das \"t\"), welche in den Außenbereichen einen viel geringeren Abstieg hat und generell flacher und nicht so intensiv gipfelnd ist wie die Normalverteilung. Konkret bedeutet das: Trotzdem zwei Punkte in der Ausgangsdimension sehr weit voneinander entfernt sind, können diese in der niedrigeren Dimension eine Ähnlichkeit aufweisen.\n",
    "Quelle: [TDS]\n",
    "\n",
    "### Hyperparameter\n",
    "\n",
    "Neben den Input-Daten, der Zieldimension und der Lern-Rate gibt es zwei entscheidende Parameter, die helfen, das meiste aus t-SNE herauszuholen: perplexity und Iterationsanzahl.\n",
    "\n",
    "Beim Tunen der **Anzahl an Iterationen** konnten auf den FragDenStaat Datensatz beste Ergebnisse bei ca. 1000 Iterationen festgestellt werden. Diese Zahl stellt jedoch keine fixe Empfehlung dar und muss je nach Grunddatenmenge und Struktur des Datensatzes ausprobiert und angepasst werden. Am Beispiel in der folgenden Grafik lässt sich demonstrativ erkennen, dass bei zu wenigen Iterationen eine schlechte, punktlastige Gruppierung erfolgt. Tritt dieses Symptom beim Plotten der Graphen auf, so ist höchstwahrscheinlich das Training zu früh beendet worden. \n",
    "\n",
    "<img src=\"Images/tSNE_iterations.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "Quelle: [HYP] \n",
    "\n",
    "\n",
    "**Perplexity**, dass zweite wichtige Feature bei der Feineinstellung des t-SNE bestimmt, wie die Gewichtung von lokalen und globalen Eigenschaften der Punkte in unserem Datensatz in die Erstellung der niedrig-dimensionalen Plots mit einfließen soll. Die Auswirkungen verschiedener Werte bei der perplexity sind weitreichend und zugleich nur schwer nachvollziehbar. Während des Trainings wurde hier mit viel Try-And-Error ein idealer Wert versucht anzunähern (hier: 25). Im bebilderten Beispiel wird ein Datensatz mit zwei Clustern und unterschiedlichen perplexity-Werten (2-100) mittels t-SNE neu berechnet. Im Paper [TODO]: Quelle [\"Visualizing Data using t-SNE\"](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) wird empfohlen, die perplexity Werte zwischen fünf und 50 zu initialisieren. Im Beispiel können wir das ursprüngliche Clustering, wenn auch in unterschiedlichen Formen und Intensitänten, gut nachvollziehen. Werte außerhalb dieses empfohlenen Bereichs erzeugen aber gänzlich andere Strukturen. Zu geringe perplexity-Werte (2) zeigen Cluster mit zu hoher lokaler Dominanz. Bei zu hohen perplexity-Werten (100) werden die beiden Cluster vereint und können gar nicht mehr unterschieden werden.\n",
    "Abschließend lässt sich zusammenfassen, dass der perplexity-Wert eine grobe Richtung vorgibt, wie viele enge Nachbarn ein Punkt unseres Datensatzes hat und individuell für jeden Datensatz ermittelt werden muss.\n",
    "\n",
    "<img src=\"Images/tSNE_perplexity.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "Quelle: [HYP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tsne_doc(data_df, amount, dimension=2, perplexity=30, learning_rate=200, n_iter=5000):\n",
    "    '''\n",
    "    computes tsne emebeddings for random set of documents\n",
    "    :param data_df: pandas datafram with at least doc_vector and title columns\n",
    "    :param amount: amount of documents to generate tsne for\n",
    "    :param dimension: 2 for 2D or 3 for 3D\n",
    "    '''\n",
    "    tsne = TSNE(perplexity=perplexity, learning_rate=learning_rate, n_components=dimension, init='pca', n_iter=n_iter, method='exact', verbose=1)\n",
    "    sample = data_df.sample(n=amount)\n",
    "\n",
    "    doc_vecs = np.array([doc_vec for doc_vec in sample['doc_vector'].values])\n",
    "    tsne_embeddings = tsne.fit_transform(doc_vecs)\n",
    "\n",
    "    labels = sample['title'].values\n",
    "    return tsne_embeddings, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaktiver 2D/3D Plot mit ploty\n",
    "Mithilfe von Plotly können wir nun einen ersten 2- oder 3-Dimensionalen Plot unserer Daten die mittels t-SNE errechnet wurden, versuchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_plot_tsne(tsne_embeddings, labels, dimension=3):\n",
    "    \n",
    "    marker=dict(\n",
    "                size=6,\n",
    "                line=dict(\n",
    "                    color='rgb(225, 225, 225)',\n",
    "                    width=0.5\n",
    "                ),\n",
    "                opacity=1\n",
    "            )\n",
    "    \n",
    "    if dimension==3:\n",
    "        x, y, z = zip(*tsne_embeddings)\n",
    "        \n",
    "        trace1 = go.Scatter3d(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            z=z,\n",
    "            mode='markers',\n",
    "            marker=marker,\n",
    "            text=labels,\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "    else:\n",
    "        x, y = zip(*tsne_embeddings)\n",
    "        \n",
    "        trace1 = go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode='markers',\n",
    "            marker=marker,\n",
    "            text=labels,\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "    \n",
    "    \n",
    "\n",
    "    data = [trace1]\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        ),\n",
    "        xaxis = dict(\n",
    "            zeroline = False\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            zeroline = False\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        #paper_bgcolor= 'rgb(240, 240, 240)',\n",
    "        #plot_bgcolor= 'rgb(240, 240, 240)'\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D TSNE Visualisierung für Stichprobe von Anfragen\n",
    "Im finalen Abschnitt des Notebooks reduzieren wir die Dimensionen einer Stichprobe (Umfang: 200 Dokumente) mittels t-SNE auf 3D und visualisieren diese dann mit Plotly interaktiv.\n",
    "\n",
    "**Achtung:** Hier gibt es nur Ergebnisse zu sehen, wenn das Modell trainiert und der Datensatz eingeladen wurde. Eine Darstellung auf GitHub selbst ist somit leider nicht möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computed conditional probabilities for sample 200 / 200\n",
      "[t-SNE] Mean sigma: 0.805618\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 47.699146\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.223914\n"
     ]
    }
   ],
   "source": [
    "plot_x_docs = 200\n",
    "tsne_embeddings_3d, labels_3d = compute_tsne_doc(\n",
    "    data, \n",
    "    plot_x_docs, \n",
    "    dimension=3,\n",
    "    perplexity=25,\n",
    "    learning_rate=10,\n",
    "    n_iter=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "line": {
           "color": "rgb(225, 225, 225)",
           "width": 0.5
          },
          "opacity": 1,
          "size": 6
         },
         "mode": "markers",
         "text": [
          "Studie \"zu den Political Net Activists\" des Instituts für Demoskopie in Allensbach",
          "Kontrollbericht zu Valentino, Berlin",
          "Hygienekontrollbericht für \"El Mexicano\"",
          "Kontrollbericht zu Edeka, Berlin",
          "Vollständige, detaillierte Belegungspläne der Schwimmhallen im Bezirk Steglitz Zehlendorf",
          "Pflege von Grünflächen in Hochstadt",
          "NRW Zentralabitur 2007",
          "Kontrollbericht zu Heinzler am See, Immenstaad am Bodensee",
          "Kontrollbericht zu Sythener Grill, Haltern am See",
          "Zielvereinbarung mit der Bundesagentur für Arbeit - Kommunales Jobcenter Landratsamt Schmalkalden-Meiningen Suhl",
          "Anzahl Geschwindigkeitsübertretungen Marienburger Straße",
          "Beschluss ohne Unterschrift des Richters?",
          "(Rahmen)Verträge über Werbeflächen in der Stadt",
          "Kontrollbericht zu REWE, Mannheim",
          "Kontrollbericht zu Hofgut Schönbronn, Buch am Wald",
          "Zielvereinbarung mit der Bundesagentur für Arbeit - Jobcenter Stadt Ansbach",
          "Gutachterliche Bewertung der Berechnungen der GEZ zu diskutierten Modellen und Modellvarianten in Verbindung mit der künftigen Rundfunkfinanzierung",
          "Kontrollbericht zu Da Cosimo, Kiel",
          "Kontrollbericht zu Mr. Chen Hannover, Hannover",
          "Kampagne \"Thüringen braucht dich\"",
          "Neue Mitte Altona / Verlagerung Bahnhof Altona nach Diebsteich",
          "Jobcenter Märkischer Kreis: 2014 Niederschriften Trägerversammlung ",
          "Brückenneubau geeignet für Rettungsfahrzeuge",
          "WD 3 - 158/12 – Stiftungsbeteiligungen des Bundes",
          "Neubauten für die Peter-Jordan Schule auf dem Gelände der Gleisbergschule in Mainz Gonsenheim",
          "Verteilungsschlüssel Wahlgruppen der Vollversammlung",
          "Erfüllung Ihrer Pflicht zu Veröffentlichungen aus Drucksache 19/351",
          "Sondergutachten zur Prüfung Betrugsfall Eventus e G(Wohnungsgenossenschaft)",
          "Studie \"Politisch Netzaktive und Politik in Deutschland\" von TNS Infratest",
          "Stellungnahme von Außenhandelsverband für Mineralöl und Energie e.V.-verband zu Entwurf eines Gesetzes zur Änderung des EEG 2014 (sog. Schienenbahn-Novelle)",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Kontrollbericht zu Kentucky Fried Chicken, Berlin",
          "zeitliche Angaben zu den Cyber-Angriffsformen nach der Definition des BSI",
          "MAIS NRW: 2015 Förderung von Erwerbslosenberatungsstellen in NRW",
          "Kontrollbericht zu EDEKA Junius, Glinde",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Geschenke an MitarbeiterInnen der Behörde",
          "Alarm und Ausrückordnung Ihrer Feuerwehr",
          "Gender Pay Gap Statistiken",
          "Kontrollbericht zu Mexikanisches Restaurant Dos Parejas, Altlandsberg",
          "Protokoll einer öffentlichen Sitzung des 5. Untersuchungsausschusses",
          "Förderungen des IASS",
          "Kontrollbericht zu Restaurant Ziegelbusch, Darmstadt",
          "Kontrollbericht zu fischerklause, Gersdorf",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "PE 6 - 011/13 – EU-Rede des britischen Premierministers David Cameron und Umsetzungsoptionen der darin geäußerten Vorstellungen für eine Reform der EU",
          "Kontrollbericht zu Van May, Berlin",
          "Kontrollbericht zu Café del sol, Moers",
          "Kontrollbericht zu Pizzeria Restaurant Orllati, Neumarkt i",
          "Kontrollbericht zu Gasthaus \"Zur Fähre\", Oberbillig",
          "Beitragsschuldner",
          "Grafiken der Touristischen Unterrichtungstafeln an der A6",
          "Abitur-Aufgaben im Fach Physik im Jahr 2013 in Nordrhein-Westfalen",
          "Arbeitsplatzbeschreibungen bei Jobcentern und Optionskommunen",
          "IFG Anfrage: EASY Daten, Asylgeschäftsstatistik, verordnungsgebundenes Ermessen, Flussmanagement",
          "Kontrollbericht zu Altenessener Biergarten, Essen",
          "Gutachten HWP",
          "Linked Open Data",
          "Kontrollbericht zu Kleiner Chinese",
          "Kontrollbericht zu Bar Alimentari, Frankfurt am Main",
          "Verträge und Plandaten betreffend der Kooperation des Internetproviders m-net und dem Main-Kinzig-Kreis",
          "Kontrollbericht zu Essecke, Paderborn",
          "Kontrollbericht zu Junge Die Bäckerei, Norderstedt",
          " EU-Richtlinie 2007/46",
          "Kontrollbericht zu Stadtbäckerei, Gießen",
          "IFG: Handlungsleitfaden zur Beweisaufnahme",
          "Kontrollbericht zu Backwerk, Villingen-Schwenningen",
          "Übersendung aller derzeit gültigen internen Weisungen des Jobcenters Herne bzgl. Außendiensten",
          "Abitur-Aufgaben im Fach Geographie im Jahr 2016 in Niedersachsen",
          "Datengrundlage des Berichts \"Ein Jahr Markttransparenzstelle für Kraftstoffe (MTS-K): Eine erste Zwischenbilanz\"",
          "Kontrollbericht: Bundesverwaltungsamt (2) (Begleitung bei Termin mit Fr. BfDI und Infobesuch AZR)",
          "Kontrollbericht zu Sultan-Markt, Kiel",
          "Dokument der Staatsanwaltschaft Gera erwähnt in der Satiresendung Extra 3 (das sogenannte „F*ck-Dich-Urteil“)",
          "Kontrollbericht zu Zum Kirchenwirt, Anzing",
          "Reparationszahlungen",
          "Kontrollbericht zu Klosterbräu Gaststätte, Zwiefalten",
          "Kontrollbericht zu voll Allwörden, Mölln",
          "Kontrollbericht zu Asia Bistro Son Nam, Altdorf b",
          "Stabsstelle \"Digitale Entwicklung, Smart City und Innovation\"",
          "Kontrollbericht zu Pizzeria Calabria, Manching",
          "Detaillierte Rohdaten angezeigter Straftaten",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Gutachten zur Anwendbarkeit des IFG auf den Wissenschaftlichen Dienst",
          "Grenze für die freihändige Vergabe im BMWi",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Begründung für exorbitanten Stellenaufwuchs im Auswärtigen Amt",
          "Kontrollbericht zu Renoir, Bremen",
          "Kontrollbericht zu Planet Oriental, Köln",
          "Gutachten zu netzbasierter Kommunikation",
          "Statistiken der Website-Aufrufe",
          "Kontrollbericht zu Kleiner Gürzenich, Eschweiler",
          "Kontrollbericht zu GolfParkGudensberg Bistro, Gudensberg",
          "DNA-Tests in der Notunterkunft Ruschestraße, Berlin Lichtenberg",
          "Kontrollbericht zu Cocoon Restaurant & Bar, Bamberg",
          "Finanzverfassungsrechtliche Fragen zur Ausgestaltung des Europäischen Stabilitätsmechanismus (ESM) ",
          "Kontrollbericht zu Restaurant Mimi, Nürnberg",
          "Kontrollbericht zu Bäckerei Künkel, Pohlheim",
          "Bau von Radwegen an Landesstraßen im Landkreis Verden und Nachbarlandkreisen",
          "Anzahl und Erfahrungen mit der Mitgliederinitiative nach § 11b HG NRW",
          "Kontrollbericht zu Moonlight, Magdeburg",
          "WD 3 - 160/11 – Alkoholverbot im öffentlichen Personenverkehr",
          "Kontrollbericht zu Euro Döner, Offenburg",
          "Gutachten der Bundesanwaltschaft zur Spiegel-Affäre",
          "Kontrollbericht zu Vereinsgaststätte TSV Wacker 50 e.V. Neutraubling, Neutraubling",
          "Lärmbelästigung wegen evtl Sondernutzungsrechten von Altwarenhändlern",
          "Abitur-Aufgaben im Fach Geschichte im Jahr 2018 in Nordrhein-Westfalen",
          "Bußgelder für Umweltzone ohne Umweltplakette befahren - Tatbestand 141621",
          "Antrag IZG/IWG Informationen ISA Portal",
          "Kontrollbericht zu Seray Imbiss, Nürnberg",
          "Hochwasserschäden 2017 Wernigerode",
          "Kontrollbericht zu Fleischerei Adams, Trier",
          "Studie \"Politisch Netzaktive und Politik in Deutschland\" von TNS Infratest",
          "Kontrollbericht zu Bootshaus Kombüse",
          "Informationen zu Abendessen mit Herrn Ackermann im April 2008",
          "Kontrollbericht zu Ya Karim, Berlin",
          "Dienstanweisungen zur Behandlung von Notenwidersrüchen",
          "Kontrollbericht zu Hotel Gasthof Krancher, Rüdesheim am Rhein",
          "Kontrollbericht zu Chinarestaurant Jadehaus, Nienburg",
          "WD 4 - 121/12 – Informationsaustausch bei Doppelbesteuerungsabkommen (DBA), Tax Information Exchange Agreements (TIEAs) und im Rahmen der EU-Zinsrichtlinie",
          "Asylbewerberunterkünfte: Standorte und Belegungszahlen",
          "Filesharing - Klagen obwohl Filesharing per Urheberrechtsgesetz erlaubt ist",
          "Kontrollbericht zu Alt Breckenheim, Wiesbaden",
          "komplette Liste/Auflistung  aller konkreten behandelten Eingaben und Beschwerden im Ausschuss für Eingaben und Beschwerden der Landeshauptstadt Potsdam",
          "Verpflichtungen nach dem Gesetz über die förmliche Verpflichtung nichtbeamteter Personen",
          "Kontrollbericht zu Backhaus Mahl, Sigmaringen",
          "Kontrollbericht zu Tenmanya Chinarestaurant, Lörrach",
          "Kontrollbericht zu Zum Wilde Männle, Oberstdorf",
          "WD 5 - 044/06 – Fragen zum Gesetzentwurf zur Änderung des Pflanzenschutzgesetzes",
          "Anzahl der Gesetze 2010-2019",
          "Anzahl der Ampelanlagen in Deutschland",
          "Kontrollbericht zu El Sombrero, Saarbrücken",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Befand sich auf dem Gelände von Selters am Steinfels, Selters am Taunus ein Bordell?",
          "Kontrollbericht zu Brotgarten, Kiel",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Drogen und Suchtberichte vor dem Jahr 2002 im pdf-Format o.ä.",
          "Kontrollbericht zu Hongkong Garten, Bad Wörishofen",
          "Kontrollbericht zu Sultan Grill, Magdeburg",
          "Stellungnahme von Verein Deutscher Zementwerke zu Entwurf eines Zweiten Gesetzes zur Änderung des Kreislaufwirtschaftsgesetzes",
          "Stellungnahme von Milchindustrie-Verband e.V. zu Entwurf eines Verpackungsgesetzes",
          "Zensur-Vorwurf von Akif Pirinçci ",
          "Abitur-Aufgaben im Fach Deutsch im Jahr 2015 in Schleswig-Holstein",
          "Kontrollbericht zu Metzgerei & Partyservice Egeler, Ammerbuch",
          "Kontrollbericht zu Chie-Tu Huang, Hamburg",
          "Kontrollbericht zu Schäftlarner Einkehr Grill-Restaurant, Schäftlarn",
          "Kontrollbericht zu Classic, Mainz",
          "PE 6 - 127/14 – Unionsrechtliche Anforderungen an ein Punktsystem bei der Zuwanderung",
          "WD 8 - 012/10 – Aus-und Weiterbildung in der Tourismusbranche",
          "Kontrollbericht zu Pizzeria Rai, Lensahn",
          "Kontrollbericht zu Koenigs, Kornwestheim",
          "Fleisch-, Milch-, und Eierproduktion und Exporte in Deutschland 2016",
          "Kontrollbericht zu La Romantica, Bad Saulgau",
          "Kontrollbericht zu Restaurant & Pension Akropolis",
          "Kontrollbericht zu Kaiser Kebap, Saarbrücken",
          "Kontrollbericht zu Pizzeria Juvenilja, Dortmund",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Kontrollbericht zu Mevlana Grill, Braunschweig",
          "Kontrollbericht zu Mix Markt, Nürnberg",
          "Bundesministerium für Arbeit und Soziales (BMAS): BMAS Antwort auf Kleine Anfrage der Grünen in 2014-09-26 Süddeutsche Zeitung Artikel \"Steigende Verwaltungskosten: Jobcentern fehlt das Geld\"",
          "Sind japanische Produkte unbedenklich verzehrbar?",
          "Stellungnahme von Stifterverband für die Deutsche Wissenschaft e. V. zu Entwurf eines Gesetzes zur Anpassung der Abgabenordnung an den Zollkodex der Union und zur Änderung weiterer steuerlicher Vorschriften",
          "Kontrollbericht zu Loui & Jules, Bremen",
          "Kontrollbericht zu Santa Lucia, Eisingen",
          "Besetzung von Rettungsmitteln im Rettungsdienstbereich Hohenlohekreis",
          "Anhang zu den Empfehlungen für die Konzeption und Umsetzung einer Film- und Medienförderung in Rheinland-Pfalz aus dem Jahr 2003",
          "Weisungen des Jobcenters - Jobcenter Landkreis Schwarzwald-Baar-Kreis - AA Villingen-Schwenningen",
          "Kontrollbericht zu Der kleine Muck, Leverkusen",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Kontrollbericht zu Dogan, Hannover",
          "Kontrollbericht zu Augustiner am Dante, München",
          "Kontrollbericht zu McDonald's, Marktredwitz",
          "Übereinkommen zum Schutz des Menschen bei der automatischen Verarbeitung personenbezogener Daten",
          "IFG-Antrag: Überlastungsanzeigen Handlungsempfehlungen, Anwendungshinweise, Verwaltungsvorschriften",
          "Sicherheitsaudits des Projekts \"Sichere Implementierung einer allgemeinen Kryptobibliothek\"",
          "Hafennautiker",
          "Ankern auf der Alten Oder",
          "IFG-Antrag: Zielvereinbarung des Jobcenters",
          "Stellungnahme von ver.di zu Gesetz zur Einführung einer Speicherpflicht und einer Höchstspeicherfrist für Verkehrsdaten",
          "Kontrollbericht zu Vaihinger Marktstüble, Stuttgart",
          "Kontrollbericht zu Restaurant Hessischer Hof, Bad Karlshafen",
          "Speicherung/Weiterleitung von Daten aus dem kostenfreien WLAN-Angebot an Sicherheitsbehörden",
          "Stellungnahme des BfR zur IARC- Monographie über Glyphosat",
          "Antrag IFG Ausgaben Toilettenpapier 2016 und 2017",
          "Fahrradstraße Rheingoldweg Austausches des Verkehrszeichens VZ 1020-30",
          "Anfrage Datenbestände staatsgefährdender Gewaltakten in der BRD",
          "Kontrollbericht zu Zur Post, Wiehl",
          "Kontrollbericht zu LIDO Kirsons Charlottenstraße, Berlin",
          "Umgang mit der Presse / Bürgermeister Arne Raue",
          "Kontrollbericht zu Royal Gourmet  Chinarestaurant, Berlin",
          "WF V 201/05 – Transparenz von Agrarbeihilfen",
          "Kontrollbericht zu Döner, Pirna",
          "Beitragspflicht für Direktversicherungen",
          "Homöopathische Leistungen bei der DAK Gesundheit",
          "Vollständige, detaillierte Belegungspläne der Schwimmhallen im Bezirk Lichtenberg Hohenschönhausen",
          "Dokument \"Unser gemeinsamer, freier Rundfunk ARD\"",
          "Kontrollbericht zu Toro Blanco, Detmold",
          "Stellungnahme von Arbeitgeberverband der finanzdienstleistenden Wirtschaft e.V.",
          "Bericht und Verwendung Regionalisierungsmittel",
          "Kontrollbericht zu Schneppenheim Grillhähnchen, Kerpen"
         ],
         "type": "scatter3d",
         "uid": "bd8721c5-d690-41e4-986f-b9083892f309",
         "x": [
          6.168927192687988,
          -11.121631622314453,
          11.479552268981934,
          -11.241833686828613,
          9.917619705200195,
          10.21982192993164,
          3.225975751876831,
          -7.432499408721924,
          -6.708348274230957,
          5.806454658508301,
          8.730667114257812,
          8.03372573852539,
          5.098569869995117,
          -4.949374198913574,
          -8.044683456420898,
          5.487791538238525,
          8.534627914428711,
          -10.56540584564209,
          -8.232489585876465,
          9.776632308959961,
          9.065376281738281,
          3.6418519020080566,
          9.582080841064453,
          2.2805652618408203,
          10.145270347595215,
          10.504411697387695,
          6.652740478515625,
          7.618292331695557,
          -0.705126941204071,
          2.910176992416382,
          -2.379027843475342,
          -8.879701614379883,
          5.758282661437988,
          7.794428825378418,
          -6.53762674331665,
          -2.379027843475342,
          4.652172565460205,
          11.804696083068848,
          7.558255672454834,
          -8.652588844299316,
          3.170379400253296,
          7.558182239532471,
          -7.388070583343506,
          -9.528499603271484,
          -2.379027843475342,
          5.85972261428833,
          -10.20996379852295,
          -6.251412391662598,
          -6.951737403869629,
          -8.581668853759766,
          9.779167175292969,
          10.440459251403809,
          1.8214004039764404,
          8.660685539245605,
          8.326662063598633,
          -10.015485763549805,
          3.9812521934509277,
          8.513679504394531,
          -10.090075492858887,
          -7.47998571395874,
          8.02093505859375,
          -8.910104751586914,
          -7.023399353027344,
          7.817943096160889,
          -7.187897205352783,
          6.130333423614502,
          -9.003259658813477,
          6.394160270690918,
          1.565246343612671,
          6.594142436981201,
          9.194052696228027,
          -10.40315055847168,
          7.530143737792969,
          -8.809311866760254,
          7.400639533996582,
          -7.455035209655762,
          -9.855648040771484,
          -5.45834493637085,
          11.072944641113281,
          -7.511014461517334,
          9.718165397644043,
          2.107377529144287,
          -2.379027843475342,
          2.261859178543091,
          11.723676681518555,
          -2.379027843475342,
          7.89981746673584,
          -10.460400581359863,
          -8.35531997680664,
          2.9871764183044434,
          8.002161979675293,
          -10.407386779785156,
          -5.539544582366943,
          8.624673843383789,
          -7.18202543258667,
          2.881027936935425,
          -9.253357887268066,
          -7.483710289001465,
          9.283822059631348,
          2.9990859031677246,
          -9.178753852844238,
          3.237380266189575,
          -10.975883483886719,
          7.1020097732543945,
          -7.7365522384643555,
          10.365694046020508,
          1.820670247077942,
          9.049504280090332,
          5.854058265686035,
          -9.317652702331543,
          11.656611442565918,
          -7.55033540725708,
          -0.705126941204071,
          -10.622282028198242,
          4.4871954917907715,
          -10.243058204650879,
          7.549762725830078,
          -7.67616605758667,
          -7.697309494018555,
          5.4827561378479,
          9.742809295654297,
          8.917222023010254,
          -5.4808735847473145,
          9.851938247680664,
          6.60118293762207,
          -7.664643287658691,
          -7.733962059020996,
          -8.729920387268066,
          2.33396315574646,
          1.6269482374191284,
          8.893416404724121,
          -6.417338848114014,
          -2.379027843475342,
          9.497730255126953,
          -10.436381340026855,
          -2.379027843475342,
          9.685258865356445,
          -7.701084613800049,
          -6.261923789978027,
          1.697502613067627,
          1.6170923709869385,
          9.959707260131836,
          1.5706878900527954,
          -6.06899356842041,
          -10.74942398071289,
          -9.427620887756348,
          -9.040040016174316,
          5.275052070617676,
          3.283872127532959,
          -7.622734069824219,
          -8.142823219299316,
          8.47864055633545,
          -5.836912155151367,
          -6.544163227081299,
          -6.077287197113037,
          -7.639467716217041,
          -2.0102899074554443,
          -6.4247565269470215,
          -9.822172164916992,
          3.028195858001709,
          11.518377304077148,
          2.4499964714050293,
          -8.54349422454834,
          -8.54376220703125,
          5.920773029327393,
          9.400506019592285,
          4.966229438781738,
          -9.040407180786133,
          2.1073648929595947,
          -8.326496124267578,
          -7.181062698364258,
          -9.153355598449707,
          5.7294535636901855,
          7.092586040496826,
          2.1073648929595947,
          8.758472442626953,
          10.761933326721191,
          5.9818549156188965,
          2.475757122039795,
          -9.83322525024414,
          -6.22422981262207,
          5.377840042114258,
          -2.0102899074554443,
          2.7802388668060303,
          9.514961242675781,
          4.844126224517822,
          -9.753777503967285,
          -9.669258117675781,
          5.804889678955078,
          -8.873875617980957,
          3.7461657524108887,
          -9.872241020202637,
          7.792803764343262,
          7.7730536460876465,
          9.83763313293457,
          4.548633575439453,
          -7.103701591491699,
          4.0604095458984375,
          7.073482036590576,
          -9.165987014770508
         ],
         "y": [
          1.5787461996078491,
          -7.108259201049805,
          4.877545356750488,
          -7.3158979415893555,
          5.329698085784912,
          7.464607238769531,
          -1.3925718069076538,
          -0.25917699933052063,
          -4.611158847808838,
          -1.7595546245574951,
          1.8405084609985352,
          2.295776844024658,
          -1.7156323194503784,
          -7.102993965148926,
          -0.7581515312194824,
          -1.7799252271652222,
          6.069714069366455,
          -5.0564446449279785,
          -4.026468753814697,
          5.377030372619629,
          5.989136219024658,
          -0.3860822319984436,
          7.527798652648926,
          3.583827018737793,
          6.682489395141602,
          3.7308099269866943,
          1.8466728925704956,
          7.702773571014404,
          0.881964385509491,
          2.5803346633911133,
          2.09731125831604,
          -5.267539024353027,
          0.813775360584259,
          4.426096439361572,
          -1.6351429224014282,
          2.09731125831604,
          -0.4931730329990387,
          8.321165084838867,
          7.007246494293213,
          -2.9890897274017334,
          -0.6937694549560547,
          2.2716526985168457,
          -7.256290435791016,
          -4.851956844329834,
          2.09731125831604,
          7.167505264282227,
          -5.880712985992432,
          -5.472413063049316,
          -7.549431800842285,
          -6.155984878540039,
          5.231980800628662,
          9.68698787689209,
          -3.5652313232421875,
          8.518497467041016,
          4.580749034881592,
          -7.742587566375732,
          0.15530049800872803,
          3.523132562637329,
          -6.977900981903076,
          -7.909334182739258,
          9.031428337097168,
          -4.677488327026367,
          -5.347728729248047,
          3.8372483253479004,
          -2.3034393787384033,
          3.224766969680786,
          -1.6030116081237793,
          -0.8531659245491028,
          -4.2299723625183105,
          4.166232585906982,
          7.665635585784912,
          -6.160933017730713,
          7.930167198181152,
          -0.504830002784729,
          0.22429832816123962,
          -3.3710267543792725,
          -2.9409005641937256,
          -3.647900104522705,
          6.943144798278809,
          -7.289466857910156,
          7.905759334564209,
          0.6037446856498718,
          2.09731125831604,
          -0.09243860095739365,
          6.180535316467285,
          2.09731125831604,
          6.114649295806885,
          -6.308925628662109,
          -3.3940486907958984,
          0.5992496013641357,
          1.148930311203003,
          -4.510509490966797,
          -3.441563129425049,
          4.836415767669678,
          -7.22455358505249,
          1.5212035179138184,
          -9.669303894042969,
          -4.93548059463501,
          5.798350811004639,
          -1.061844825744629,
          -4.240664005279541,
          5.559649467468262,
          -8.346189498901367,
          5.7236528396606445,
          1.7622430324554443,
          7.860002517700195,
          -3.5656821727752686,
          3.1663763523101807,
          2.489736557006836,
          -9.507080078125,
          7.463164329528809,
          -3.4407174587249756,
          0.881964385509491,
          -3.3552818298339844,
          0.6208974719047546,
          -5.420870780944824,
          4.444644451141357,
          -4.361355781555176,
          0.6400327086448669,
          4.9846978187561035,
          6.564137935638428,
          6.468423843383789,
          -2.613652229309082,
          2.726710557937622,
          0.08243322372436523,
          -1.816019892692566,
          0.5039768815040588,
          1.332856297492981,
          3.0388593673706055,
          -1.1808298826217651,
          0.2230914831161499,
          -2.8096742630004883,
          2.09731125831604,
          10.155118942260742,
          -5.600005149841309,
          2.09731125831604,
          2.8142614364624023,
          -0.9406991004943848,
          -5.869119644165039,
          2.126629590988159,
          2.1434621810913086,
          8.660506248474121,
          -4.2133049964904785,
          -1.8318198919296265,
          -4.4007463455200195,
          -0.2033536732196808,
          -7.084334850311279,
          6.766865253448486,
          5.653324604034424,
          -7.4039626121521,
          -0.8185179233551025,
          6.169430255889893,
          -5.5288872718811035,
          -6.786988258361816,
          -4.2664289474487305,
          -8.306097984313965,
          1.1836614608764648,
          -5.754119873046875,
          -9.025007247924805,
          -0.31722745299339294,
          4.634760856628418,
          2.2543060779571533,
          -2.332305908203125,
          0.8263515830039978,
          1.3448113203048706,
          7.551368713378906,
          -1.5485974550247192,
          -4.954710960388184,
          0.6037446856498718,
          -4.049571514129639,
          -3.0673410892486572,
          -7.88817024230957,
          1.356378436088562,
          4.421263217926025,
          0.6037446856498718,
          6.951173782348633,
          9.659778594970703,
          -1.8907197713851929,
          1.7323259115219116,
          -8.874245643615723,
          -6.521048069000244,
          2.5252139568328857,
          1.1836614608764648,
          -1.0202494859695435,
          8.779181480407715,
          1.02955961227417,
          -7.329140663146973,
          -1.4347283840179443,
          0.9084786772727966,
          -5.406275749206543,
          5.986858367919922,
          -7.228671550750732,
          3.9483532905578613,
          2.768101453781128,
          5.159814357757568,
          2.6771416664123535,
          -0.2935507297515869,
          2.9347124099731445,
          4.920399188995361,
          0.24352514743804932
         ],
         "z": [
          1.601455569267273,
          -1.4209764003753662,
          -2.365380048751831,
          -1.3440492153167725,
          0.10409172624349594,
          -3.4933924674987793,
          -0.06025335565209389,
          -3.911652088165283,
          -1.4203966856002808,
          3.492358446121216,
          -1.2439099550247192,
          1.7691999673843384,
          -0.04666195437312126,
          0.021124813705682755,
          -2.5790724754333496,
          3.3733692169189453,
          0.7085089683532715,
          2.321798801422119,
          3.149567127227783,
          -2.774657726287842,
          -0.6220132112503052,
          0.057547785341739655,
          -1.8718931674957275,
          -1.0292751789093018,
          -1.2475827932357788,
          -0.7169173359870911,
          -0.28647133708000183,
          -0.9887204170227051,
          -1.6054962873458862,
          1.478468656539917,
          4.946630477905273,
          -2.7679789066314697,
          -0.8176590204238892,
          -1.0092053413391113,
          -2.0488088130950928,
          4.946630477905273,
          -1.406713604927063,
          -0.40045320987701416,
          0.40547066926956177,
          -1.7242534160614014,
          0.8411160707473755,
          -2.1447110176086426,
          1.762075424194336,
          0.9012240171432495,
          4.946630477905273,
          -1.3126943111419678,
          -2.1955761909484863,
          0.310859739780426,
          0.9486374258995056,
          0.07179469615221024,
          2.2723042964935303,
          -1.2761379480361938,
          -1.5139474868774414,
          -1.488094449043274,
          -0.7000367641448975,
          2.123032808303833,
          0.2547819912433624,
          0.2215745598077774,
          0.6351301074028015,
          3.2717926502227783,
          0.22060158848762512,
          -0.21877343952655792,
          0.3612276017665863,
          -3.071540594100952,
          -0.6186994314193726,
          0.18615609407424927,
          -1.5873749256134033,
          2.2780954837799072,
          -1.8581005334854126,
          -2.0168631076812744,
          1.2887482643127441,
          2.5195415019989014,
          -3.0077192783355713,
          -1.0126482248306274,
          -2.481220006942749,
          -1.2554453611373901,
          -0.6643849015235901,
          -0.3700734078884125,
          0.8545390367507935,
          -0.5278700590133667,
          -1.208970069885254,
          -4.527042388916016,
          4.946630477905273,
          -0.997791588306427,
          -0.8625617623329163,
          4.946630477905273,
          -1.0483896732330322,
          0.8325436115264893,
          0.41400450468063354,
          -0.9970138669013977,
          0.37434279918670654,
          0.16231393814086914,
          -0.3089365065097809,
          -1.294734001159668,
          2.13845157623291,
          -0.636929988861084,
          2.4860033988952637,
          0.32017257809638977,
          -1.4040127992630005,
          -0.03140347823500633,
          0.45475924015045166,
          -1.2309610843658447,
          1.2848232984542847,
          -2.6171233654022217,
          -3.785447120666504,
          -1.2352465391159058,
          -1.5158826112747192,
          -0.9083749055862427,
          -1.3843967914581299,
          2.3874928951263428,
          -2.3948416709899902,
          -3.487678289413452,
          -1.6054962873458862,
          1.0704360008239746,
          1.329455018043518,
          -2.0091447830200195,
          1.3658169507980347,
          -3.1260602474212646,
          -3.0687544345855713,
          -0.5602169632911682,
          0.13064391911029816,
          -1.0782893896102905,
          -2.7940785884857178,
          0.7700697779655457,
          -0.5376777648925781,
          -2.3088200092315674,
          -2.888171434402466,
          -2.5484776496887207,
          -0.7823354005813599,
          0.9372397661209106,
          -0.9113397598266602,
          -2.7495667934417725,
          4.946630477905273,
          -1.850044846534729,
          2.2465240955352783,
          4.946630477905273,
          -2.629516363143921,
          -0.29679349064826965,
          -1.6025254726409912,
          1.7923005819320679,
          1.8217236995697021,
          0.11595598608255386,
          -1.8437151908874512,
          -1.6622556447982788,
          -1.3458843231201172,
          -1.571401596069336,
          2.064359664916992,
          -1.2317891120910645,
          -1.2463617324829102,
          -0.4332704246044159,
          -0.2625218629837036,
          -3.902905225753784,
          2.294680118560791,
          1.6537398099899292,
          -2.1473448276519775,
          -0.06363443285226822,
          5.404824733734131,
          -1.3257694244384766,
          0.6634051203727722,
          0.3128427565097809,
          0.833766520023346,
          1.4999468326568604,
          0.7684191465377808,
          -1.9153521060943604,
          -0.34270668029785156,
          -0.8090373277664185,
          2.7724626064300537,
          1.5070732831954956,
          -4.527041912078857,
          2.8889901638031006,
          1.431190848350525,
          -0.9293533563613892,
          -2.649322986602783,
          2.3096845149993896,
          -4.527041912078857,
          -2.170755386352539,
          -2.5004966259002686,
          3.7672061920166016,
          2.1215217113494873,
          0.6634907126426697,
          2.2571794986724854,
          -1.9264179468154907,
          5.404824733734131,
          1.036181092262268,
          -2.630979299545288,
          -0.4162842929363251,
          3.5283725261688232,
          0.5581809878349304,
          0.38562899827957153,
          -2.6862170696258545,
          -1.174749732017517,
          1.8853840827941895,
          -0.19573363661766052,
          -0.9606509804725647,
          0.12598459422588348,
          2.3857944011688232,
          -1.7523497343063354,
          1.0586284399032593,
          -0.5968359708786011,
          -3.0839476585388184
         ]
        }
       ],
       "layout": {
        "height": 800,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "width": 1000,
        "xaxis": {
         "zeroline": false
        },
        "yaxis": {
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"fc04a636-7cc3-4a94-bbe8-fadcf361fb07\" class=\"plotly-graph-div\" style=\"height:800px; width:1000px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"fc04a636-7cc3-4a94-bbe8-fadcf361fb07\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'fc04a636-7cc3-4a94-bbe8-fadcf361fb07',\n",
       "                        [{\"hoverinfo\": \"text\", \"marker\": {\"line\": {\"color\": \"rgb(225, 225, 225)\", \"width\": 0.5}, \"opacity\": 1, \"size\": 6}, \"mode\": \"markers\", \"text\": [\"Studie \\\"zu den Political Net Activists\\\" des Instituts f\\u00fcr Demoskopie in Allensbach\", \"Kontrollbericht zu Valentino, Berlin\", \"Hygienekontrollbericht f\\u00fcr \\\"El Mexicano\\\"\", \"Kontrollbericht zu Edeka, Berlin\", \"Vollst\\u00e4ndige, detaillierte Belegungspl\\u00e4ne der Schwimmhallen im Bezirk Steglitz Zehlendorf\", \"Pflege von Gr\\u00fcnfl\\u00e4chen in Hochstadt\", \"NRW Zentralabitur 2007\", \"Kontrollbericht zu Heinzler am See, Immenstaad am Bodensee\", \"Kontrollbericht zu Sythener Grill, Haltern am See\", \"Zielvereinbarung mit der Bundesagentur f\\u00fcr Arbeit - Kommunales Jobcenter Landratsamt Schmalkalden-Meiningen Suhl\", \"Anzahl Geschwindigkeits\\u00fcbertretungen Marienburger Stra\\u00dfe\", \"Beschluss ohne Unterschrift des Richters?\", \"(Rahmen)Vertr\\u00e4ge \\u00fcber Werbefl\\u00e4chen in der Stadt\", \"Kontrollbericht zu REWE, Mannheim\", \"Kontrollbericht zu Hofgut Sch\\u00f6nbronn, Buch am Wald\", \"Zielvereinbarung mit der Bundesagentur f\\u00fcr Arbeit - Jobcenter Stadt Ansbach\", \"Gutachterliche Bewertung der Berechnungen der GEZ zu diskutierten Modellen und Modellvarianten in Verbindung mit der k\\u00fcnftigen Rundfunkfinanzierung\", \"Kontrollbericht zu Da Cosimo, Kiel\", \"Kontrollbericht zu Mr. Chen Hannover, Hannover\", \"Kampagne \\\"Th\\u00fcringen braucht dich\\\"\", \"Neue Mitte Altona / Verlagerung Bahnhof Altona nach Diebsteich\", \"Jobcenter M\\u00e4rkischer Kreis: 2014 Niederschriften Tr\\u00e4gerversammlung \", \"Br\\u00fcckenneubau geeignet f\\u00fcr Rettungsfahrzeuge\", \"WD 3 - 158/12 \\u2013 Stiftungsbeteiligungen des Bundes\", \"Neubauten f\\u00fcr die Peter-Jordan Schule auf dem Gel\\u00e4nde der Gleisbergschule in Mainz Gonsenheim\", \"Verteilungsschl\\u00fcssel Wahlgruppen der Vollversammlung\", \"Erf\\u00fcllung Ihrer Pflicht zu Ver\\u00f6ffentlichungen aus Drucksache 19/351\", \"Sondergutachten zur Pr\\u00fcfung Betrugsfall Eventus e G(Wohnungsgenossenschaft)\", \"Studie \\\"Politisch Netzaktive und Politik in Deutschland\\\" von TNS Infratest\", \"Stellungnahme von Au\\u00dfenhandelsverband f\\u00fcr Mineral\\u00f6l und Energie e.V.-verband zu Entwurf eines Gesetzes zur \\u00c4nderung des EEG 2014 (sog. Schienenbahn-Novelle)\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Kontrollbericht zu Kentucky Fried Chicken, Berlin\", \"zeitliche Angaben zu den Cyber-Angriffsformen nach der Definition des BSI\", \"MAIS NRW: 2015 F\\u00f6rderung von Erwerbslosenberatungsstellen in NRW\", \"Kontrollbericht zu EDEKA Junius, Glinde\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Geschenke an MitarbeiterInnen der Beh\\u00f6rde\", \"Alarm und Ausr\\u00fcckordnung Ihrer Feuerwehr\", \"Gender Pay Gap Statistiken\", \"Kontrollbericht zu Mexikanisches Restaurant Dos Parejas, Altlandsberg\", \"Protokoll einer \\u00f6ffentlichen Sitzung des 5. Untersuchungsausschusses\", \"F\\u00f6rderungen des IASS\", \"Kontrollbericht zu Restaurant Ziegelbusch, Darmstadt\", \"Kontrollbericht zu fischerklause, Gersdorf\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"PE 6 - 011/13 \\u2013 EU-Rede des britischen Premierministers David Cameron und Umsetzungsoptionen der darin ge\\u00e4u\\u00dferten Vorstellungen f\\u00fcr eine Reform der EU\", \"Kontrollbericht zu Van May, Berlin\", \"Kontrollbericht zu Caf\\u00e9 del sol, Moers\", \"Kontrollbericht zu Pizzeria Restaurant Orllati, Neumarkt i\", \"Kontrollbericht zu Gasthaus \\\"Zur F\\u00e4hre\\\", Oberbillig\", \"Beitragsschuldner\", \"Grafiken der Touristischen Unterrichtungstafeln an der A6\", \"Abitur-Aufgaben im Fach Physik im Jahr 2013 in Nordrhein-Westfalen\", \"Arbeitsplatzbeschreibungen bei Jobcentern und Optionskommunen\", \"IFG Anfrage: EASY Daten, Asylgesch\\u00e4ftsstatistik, verordnungsgebundenes Ermessen, Flussmanagement\", \"Kontrollbericht zu Altenessener Biergarten, Essen\", \"Gutachten HWP\", \"Linked Open Data\", \"Kontrollbericht zu Kleiner Chinese\", \"Kontrollbericht zu Bar Alimentari, Frankfurt am Main\", \"Vertr\\u00e4ge und Plandaten betreffend der Kooperation des Internetproviders m-net und dem Main-Kinzig-Kreis\", \"Kontrollbericht zu Essecke, Paderborn\", \"Kontrollbericht zu Junge Die B\\u00e4ckerei, Norderstedt\", \" EU-Richtlinie 2007/46\", \"Kontrollbericht zu Stadtb\\u00e4ckerei, Gie\\u00dfen\", \"IFG: Handlungsleitfaden zur Beweisaufnahme\", \"Kontrollbericht zu Backwerk, Villingen-Schwenningen\", \"\\u00dcbersendung aller derzeit g\\u00fcltigen internen Weisungen des Jobcenters Herne bzgl. Au\\u00dfendiensten\", \"Abitur-Aufgaben im Fach Geographie im Jahr 2016 in Niedersachsen\", \"Datengrundlage des Berichts \\\"Ein Jahr Markttransparenzstelle f\\u00fcr Kraftstoffe (MTS-K): Eine erste Zwischenbilanz\\\"\", \"Kontrollbericht: Bundesverwaltungsamt (2) (Begleitung bei Termin mit Fr. BfDI und Infobesuch AZR)\", \"Kontrollbericht zu Sultan-Markt, Kiel\", \"Dokument der Staatsanwaltschaft Gera erw\\u00e4hnt in der Satiresendung Extra 3 (das sogenannte \\u201eF*ck-Dich-Urteil\\u201c)\", \"Kontrollbericht zu Zum Kirchenwirt, Anzing\", \"Reparationszahlungen\", \"Kontrollbericht zu Klosterbr\\u00e4u Gastst\\u00e4tte, Zwiefalten\", \"Kontrollbericht zu voll Allw\\u00f6rden, M\\u00f6lln\", \"Kontrollbericht zu Asia Bistro Son Nam, Altdorf b\", \"Stabsstelle \\\"Digitale Entwicklung, Smart City und Innovation\\\"\", \"Kontrollbericht zu Pizzeria Calabria, Manching\", \"Detaillierte Rohdaten angezeigter Straftaten\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Gutachten zur Anwendbarkeit des IFG auf den Wissenschaftlichen Dienst\", \"Grenze f\\u00fcr die freih\\u00e4ndige Vergabe im BMWi\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Begr\\u00fcndung f\\u00fcr exorbitanten Stellenaufwuchs im Ausw\\u00e4rtigen Amt\", \"Kontrollbericht zu Renoir, Bremen\", \"Kontrollbericht zu Planet Oriental, K\\u00f6ln\", \"Gutachten zu netzbasierter Kommunikation\", \"Statistiken der Website-Aufrufe\", \"Kontrollbericht zu Kleiner G\\u00fcrzenich, Eschweiler\", \"Kontrollbericht zu GolfParkGudensberg Bistro, Gudensberg\", \"DNA-Tests in der Notunterkunft Ruschestra\\u00dfe, Berlin Lichtenberg\", \"Kontrollbericht zu Cocoon Restaurant & Bar, Bamberg\", \"Finanzverfassungsrechtliche Fragen zur Ausgestaltung des Europ\\u00e4ischen Stabilit\\u00e4tsmechanismus (ESM) \", \"Kontrollbericht zu Restaurant Mimi, N\\u00fcrnberg\", \"Kontrollbericht zu B\\u00e4ckerei K\\u00fcnkel, Pohlheim\", \"Bau von Radwegen an Landesstra\\u00dfen im Landkreis Verden und Nachbarlandkreisen\", \"Anzahl und Erfahrungen mit der Mitgliederinitiative nach \\u00a7 11b HG NRW\", \"Kontrollbericht zu Moonlight, Magdeburg\", \"WD 3 - 160/11 \\u2013 Alkoholverbot im \\u00f6ffentlichen Personenverkehr\", \"Kontrollbericht zu Euro D\\u00f6ner, Offenburg\", \"Gutachten der Bundesanwaltschaft zur Spiegel-Aff\\u00e4re\", \"Kontrollbericht zu Vereinsgastst\\u00e4tte TSV Wacker 50 e.V. Neutraubling, Neutraubling\", \"L\\u00e4rmbel\\u00e4stigung wegen evtl Sondernutzungsrechten von Altwarenh\\u00e4ndlern\", \"Abitur-Aufgaben im Fach Geschichte im Jahr 2018 in Nordrhein-Westfalen\", \"Bu\\u00dfgelder f\\u00fcr Umweltzone ohne Umweltplakette befahren - Tatbestand 141621\", \"Antrag IZG/IWG Informationen ISA Portal\", \"Kontrollbericht zu Seray Imbiss, N\\u00fcrnberg\", \"Hochwassersch\\u00e4den 2017 Wernigerode\", \"Kontrollbericht zu Fleischerei Adams, Trier\", \"Studie \\\"Politisch Netzaktive und Politik in Deutschland\\\" von TNS Infratest\", \"Kontrollbericht zu Bootshaus Komb\\u00fcse\", \"Informationen zu Abendessen mit Herrn Ackermann im April 2008\", \"Kontrollbericht zu Ya Karim, Berlin\", \"Dienstanweisungen zur Behandlung von Notenwidersr\\u00fcchen\", \"Kontrollbericht zu Hotel Gasthof Krancher, R\\u00fcdesheim am Rhein\", \"Kontrollbericht zu Chinarestaurant Jadehaus, Nienburg\", \"WD 4 - 121/12 \\u2013 Informationsaustausch bei Doppelbesteuerungsabkommen (DBA), Tax Information Exchange Agreements (TIEAs) und im Rahmen der EU-Zinsrichtlinie\", \"Asylbewerberunterk\\u00fcnfte: Standorte und Belegungszahlen\", \"Filesharing - Klagen obwohl Filesharing per Urheberrechtsgesetz erlaubt ist\", \"Kontrollbericht zu Alt Breckenheim, Wiesbaden\", \"komplette Liste/Auflistung  aller konkreten behandelten Eingaben und Beschwerden im Ausschuss f\\u00fcr Eingaben und Beschwerden der Landeshauptstadt Potsdam\", \"Verpflichtungen nach dem Gesetz \\u00fcber die f\\u00f6rmliche Verpflichtung nichtbeamteter Personen\", \"Kontrollbericht zu Backhaus Mahl, Sigmaringen\", \"Kontrollbericht zu Tenmanya Chinarestaurant, L\\u00f6rrach\", \"Kontrollbericht zu Zum Wilde M\\u00e4nnle, Oberstdorf\", \"WD 5 - 044/06 \\u2013 Fragen zum Gesetzentwurf zur \\u00c4nderung des Pflanzenschutzgesetzes\", \"Anzahl der Gesetze 2010-2019\", \"Anzahl der Ampelanlagen in Deutschland\", \"Kontrollbericht zu El Sombrero, Saarbr\\u00fccken\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Befand sich auf dem Gel\\u00e4nde von Selters am Steinfels, Selters am Taunus ein Bordell?\", \"Kontrollbericht zu Brotgarten, Kiel\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Drogen und Suchtberichte vor dem Jahr 2002 im pdf-Format o.\\u00e4.\", \"Kontrollbericht zu Hongkong Garten, Bad W\\u00f6rishofen\", \"Kontrollbericht zu Sultan Grill, Magdeburg\", \"Stellungnahme von Verein Deutscher Zementwerke zu Entwurf eines Zweiten Gesetzes zur \\u00c4nderung des Kreislaufwirtschaftsgesetzes\", \"Stellungnahme von Milchindustrie-Verband e.V. zu Entwurf eines Verpackungsgesetzes\", \"Zensur-Vorwurf von Akif Pirin\\u00e7ci \", \"Abitur-Aufgaben im Fach Deutsch im Jahr 2015 in Schleswig-Holstein\", \"Kontrollbericht zu Metzgerei & Partyservice Egeler, Ammerbuch\", \"Kontrollbericht zu Chie-Tu Huang, Hamburg\", \"Kontrollbericht zu Sch\\u00e4ftlarner Einkehr Grill-Restaurant, Sch\\u00e4ftlarn\", \"Kontrollbericht zu Classic, Mainz\", \"PE 6 - 127/14 \\u2013 Unionsrechtliche Anforderungen an ein Punktsystem bei der Zuwanderung\", \"WD 8 - 012/10 \\u2013 Aus-und Weiterbildung in der Tourismusbranche\", \"Kontrollbericht zu Pizzeria Rai, Lensahn\", \"Kontrollbericht zu Koenigs, Kornwestheim\", \"Fleisch-, Milch-, und Eierproduktion und Exporte in Deutschland 2016\", \"Kontrollbericht zu La Romantica, Bad Saulgau\", \"Kontrollbericht zu Restaurant & Pension Akropolis\", \"Kontrollbericht zu Kaiser Kebap, Saarbr\\u00fccken\", \"Kontrollbericht zu Pizzeria Juvenilja, Dortmund\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Kontrollbericht zu Mevlana Grill, Braunschweig\", \"Kontrollbericht zu Mix Markt, N\\u00fcrnberg\", \"Bundesministerium f\\u00fcr Arbeit und Soziales (BMAS): BMAS Antwort auf Kleine Anfrage der Gr\\u00fcnen in 2014-09-26 S\\u00fcddeutsche Zeitung Artikel \\\"Steigende Verwaltungskosten: Jobcentern fehlt das Geld\\\"\", \"Sind japanische Produkte unbedenklich verzehrbar?\", \"Stellungnahme von Stifterverband f\\u00fcr die Deutsche Wissenschaft e. V. zu Entwurf eines Gesetzes zur Anpassung der Abgabenordnung an den Zollkodex der Union und zur \\u00c4nderung weiterer steuerlicher Vorschriften\", \"Kontrollbericht zu Loui & Jules, Bremen\", \"Kontrollbericht zu Santa Lucia, Eisingen\", \"Besetzung von Rettungsmitteln im Rettungsdienstbereich Hohenlohekreis\", \"Anhang zu den Empfehlungen f\\u00fcr die Konzeption und Umsetzung einer Film- und Medienf\\u00f6rderung in Rheinland-Pfalz aus dem Jahr 2003\", \"Weisungen des Jobcenters - Jobcenter Landkreis Schwarzwald-Baar-Kreis - AA Villingen-Schwenningen\", \"Kontrollbericht zu Der kleine Muck, Leverkusen\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Kontrollbericht zu Dogan, Hannover\", \"Kontrollbericht zu Augustiner am Dante, M\\u00fcnchen\", \"Kontrollbericht zu McDonald's, Marktredwitz\", \"\\u00dcbereinkommen zum Schutz des Menschen bei der automatischen Verarbeitung personenbezogener Daten\", \"IFG-Antrag: \\u00dcberlastungsanzeigen Handlungsempfehlungen, Anwendungshinweise, Verwaltungsvorschriften\", \"Sicherheitsaudits des Projekts \\\"Sichere Implementierung einer allgemeinen Kryptobibliothek\\\"\", \"Hafennautiker\", \"Ankern auf der Alten Oder\", \"IFG-Antrag: Zielvereinbarung des Jobcenters\", \"Stellungnahme von ver.di zu Gesetz zur Einf\\u00fchrung einer Speicherpflicht und einer H\\u00f6chstspeicherfrist f\\u00fcr Verkehrsdaten\", \"Kontrollbericht zu Vaihinger Marktst\\u00fcble, Stuttgart\", \"Kontrollbericht zu Restaurant Hessischer Hof, Bad Karlshafen\", \"Speicherung/Weiterleitung von Daten aus dem kostenfreien WLAN-Angebot an Sicherheitsbeh\\u00f6rden\", \"Stellungnahme des BfR zur IARC- Monographie \\u00fcber Glyphosat\", \"Antrag IFG Ausgaben Toilettenpapier 2016 und 2017\", \"Fahrradstra\\u00dfe Rheingoldweg Austausches des Verkehrszeichens VZ 1020-30\", \"Anfrage Datenbest\\u00e4nde staatsgef\\u00e4hrdender Gewaltakten in der BRD\", \"Kontrollbericht zu Zur Post, Wiehl\", \"Kontrollbericht zu LIDO Kirsons Charlottenstra\\u00dfe, Berlin\", \"Umgang mit der Presse / B\\u00fcrgermeister Arne Raue\", \"Kontrollbericht zu Royal Gourmet  Chinarestaurant, Berlin\", \"WF V 201/05 \\u2013 Transparenz von Agrarbeihilfen\", \"Kontrollbericht zu D\\u00f6ner, Pirna\", \"Beitragspflicht f\\u00fcr Direktversicherungen\", \"Hom\\u00f6opathische Leistungen bei der DAK Gesundheit\", \"Vollst\\u00e4ndige, detaillierte Belegungspl\\u00e4ne der Schwimmhallen im Bezirk Lichtenberg Hohensch\\u00f6nhausen\", \"Dokument \\\"Unser gemeinsamer, freier Rundfunk ARD\\\"\", \"Kontrollbericht zu Toro Blanco, Detmold\", \"Stellungnahme von Arbeitgeberverband der finanzdienstleistenden Wirtschaft e.V.\", \"Bericht und Verwendung Regionalisierungsmittel\", \"Kontrollbericht zu Schneppenheim Grillh\\u00e4hnchen, Kerpen\"], \"type\": \"scatter3d\", \"uid\": \"bd8721c5-d690-41e4-986f-b9083892f309\", \"x\": [6.168927192687988, -11.121631622314453, 11.479552268981934, -11.241833686828613, 9.917619705200195, 10.21982192993164, 3.225975751876831, -7.432499408721924, -6.708348274230957, 5.806454658508301, 8.730667114257812, 8.03372573852539, 5.098569869995117, -4.949374198913574, -8.044683456420898, 5.487791538238525, 8.534627914428711, -10.56540584564209, -8.232489585876465, 9.776632308959961, 9.065376281738281, 3.6418519020080566, 9.582080841064453, 2.2805652618408203, 10.145270347595215, 10.504411697387695, 6.652740478515625, 7.618292331695557, -0.705126941204071, 2.910176992416382, -2.379027843475342, -8.879701614379883, 5.758282661437988, 7.794428825378418, -6.53762674331665, -2.379027843475342, 4.652172565460205, 11.804696083068848, 7.558255672454834, -8.652588844299316, 3.170379400253296, 7.558182239532471, -7.388070583343506, -9.528499603271484, -2.379027843475342, 5.85972261428833, -10.20996379852295, -6.251412391662598, -6.951737403869629, -8.581668853759766, 9.779167175292969, 10.440459251403809, 1.8214004039764404, 8.660685539245605, 8.326662063598633, -10.015485763549805, 3.9812521934509277, 8.513679504394531, -10.090075492858887, -7.47998571395874, 8.02093505859375, -8.910104751586914, -7.023399353027344, 7.817943096160889, -7.187897205352783, 6.130333423614502, -9.003259658813477, 6.394160270690918, 1.565246343612671, 6.594142436981201, 9.194052696228027, -10.40315055847168, 7.530143737792969, -8.809311866760254, 7.400639533996582, -7.455035209655762, -9.855648040771484, -5.45834493637085, 11.072944641113281, -7.511014461517334, 9.718165397644043, 2.107377529144287, -2.379027843475342, 2.261859178543091, 11.723676681518555, -2.379027843475342, 7.89981746673584, -10.460400581359863, -8.35531997680664, 2.9871764183044434, 8.002161979675293, -10.407386779785156, -5.539544582366943, 8.624673843383789, -7.18202543258667, 2.881027936935425, -9.253357887268066, -7.483710289001465, 9.283822059631348, 2.9990859031677246, -9.178753852844238, 3.237380266189575, -10.975883483886719, 7.1020097732543945, -7.7365522384643555, 10.365694046020508, 1.820670247077942, 9.049504280090332, 5.854058265686035, -9.317652702331543, 11.656611442565918, -7.55033540725708, -0.705126941204071, -10.622282028198242, 4.4871954917907715, -10.243058204650879, 7.549762725830078, -7.67616605758667, -7.697309494018555, 5.4827561378479, 9.742809295654297, 8.917222023010254, -5.4808735847473145, 9.851938247680664, 6.60118293762207, -7.664643287658691, -7.733962059020996, -8.729920387268066, 2.33396315574646, 1.6269482374191284, 8.893416404724121, -6.417338848114014, -2.379027843475342, 9.497730255126953, -10.436381340026855, -2.379027843475342, 9.685258865356445, -7.701084613800049, -6.261923789978027, 1.697502613067627, 1.6170923709869385, 9.959707260131836, 1.5706878900527954, -6.06899356842041, -10.74942398071289, -9.427620887756348, -9.040040016174316, 5.275052070617676, 3.283872127532959, -7.622734069824219, -8.142823219299316, 8.47864055633545, -5.836912155151367, -6.544163227081299, -6.077287197113037, -7.639467716217041, -2.0102899074554443, -6.4247565269470215, -9.822172164916992, 3.028195858001709, 11.518377304077148, 2.4499964714050293, -8.54349422454834, -8.54376220703125, 5.920773029327393, 9.400506019592285, 4.966229438781738, -9.040407180786133, 2.1073648929595947, -8.326496124267578, -7.181062698364258, -9.153355598449707, 5.7294535636901855, 7.092586040496826, 2.1073648929595947, 8.758472442626953, 10.761933326721191, 5.9818549156188965, 2.475757122039795, -9.83322525024414, -6.22422981262207, 5.377840042114258, -2.0102899074554443, 2.7802388668060303, 9.514961242675781, 4.844126224517822, -9.753777503967285, -9.669258117675781, 5.804889678955078, -8.873875617980957, 3.7461657524108887, -9.872241020202637, 7.792803764343262, 7.7730536460876465, 9.83763313293457, 4.548633575439453, -7.103701591491699, 4.0604095458984375, 7.073482036590576, -9.165987014770508], \"y\": [1.5787461996078491, -7.108259201049805, 4.877545356750488, -7.3158979415893555, 5.329698085784912, 7.464607238769531, -1.3925718069076538, -0.25917699933052063, -4.611158847808838, -1.7595546245574951, 1.8405084609985352, 2.295776844024658, -1.7156323194503784, -7.102993965148926, -0.7581515312194824, -1.7799252271652222, 6.069714069366455, -5.0564446449279785, -4.026468753814697, 5.377030372619629, 5.989136219024658, -0.3860822319984436, 7.527798652648926, 3.583827018737793, 6.682489395141602, 3.7308099269866943, 1.8466728925704956, 7.702773571014404, 0.881964385509491, 2.5803346633911133, 2.09731125831604, -5.267539024353027, 0.813775360584259, 4.426096439361572, -1.6351429224014282, 2.09731125831604, -0.4931730329990387, 8.321165084838867, 7.007246494293213, -2.9890897274017334, -0.6937694549560547, 2.2716526985168457, -7.256290435791016, -4.851956844329834, 2.09731125831604, 7.167505264282227, -5.880712985992432, -5.472413063049316, -7.549431800842285, -6.155984878540039, 5.231980800628662, 9.68698787689209, -3.5652313232421875, 8.518497467041016, 4.580749034881592, -7.742587566375732, 0.15530049800872803, 3.523132562637329, -6.977900981903076, -7.909334182739258, 9.031428337097168, -4.677488327026367, -5.347728729248047, 3.8372483253479004, -2.3034393787384033, 3.224766969680786, -1.6030116081237793, -0.8531659245491028, -4.2299723625183105, 4.166232585906982, 7.665635585784912, -6.160933017730713, 7.930167198181152, -0.504830002784729, 0.22429832816123962, -3.3710267543792725, -2.9409005641937256, -3.647900104522705, 6.943144798278809, -7.289466857910156, 7.905759334564209, 0.6037446856498718, 2.09731125831604, -0.09243860095739365, 6.180535316467285, 2.09731125831604, 6.114649295806885, -6.308925628662109, -3.3940486907958984, 0.5992496013641357, 1.148930311203003, -4.510509490966797, -3.441563129425049, 4.836415767669678, -7.22455358505249, 1.5212035179138184, -9.669303894042969, -4.93548059463501, 5.798350811004639, -1.061844825744629, -4.240664005279541, 5.559649467468262, -8.346189498901367, 5.7236528396606445, 1.7622430324554443, 7.860002517700195, -3.5656821727752686, 3.1663763523101807, 2.489736557006836, -9.507080078125, 7.463164329528809, -3.4407174587249756, 0.881964385509491, -3.3552818298339844, 0.6208974719047546, -5.420870780944824, 4.444644451141357, -4.361355781555176, 0.6400327086448669, 4.9846978187561035, 6.564137935638428, 6.468423843383789, -2.613652229309082, 2.726710557937622, 0.08243322372436523, -1.816019892692566, 0.5039768815040588, 1.332856297492981, 3.0388593673706055, -1.1808298826217651, 0.2230914831161499, -2.8096742630004883, 2.09731125831604, 10.155118942260742, -5.600005149841309, 2.09731125831604, 2.8142614364624023, -0.9406991004943848, -5.869119644165039, 2.126629590988159, 2.1434621810913086, 8.660506248474121, -4.2133049964904785, -1.8318198919296265, -4.4007463455200195, -0.2033536732196808, -7.084334850311279, 6.766865253448486, 5.653324604034424, -7.4039626121521, -0.8185179233551025, 6.169430255889893, -5.5288872718811035, -6.786988258361816, -4.2664289474487305, -8.306097984313965, 1.1836614608764648, -5.754119873046875, -9.025007247924805, -0.31722745299339294, 4.634760856628418, 2.2543060779571533, -2.332305908203125, 0.8263515830039978, 1.3448113203048706, 7.551368713378906, -1.5485974550247192, -4.954710960388184, 0.6037446856498718, -4.049571514129639, -3.0673410892486572, -7.88817024230957, 1.356378436088562, 4.421263217926025, 0.6037446856498718, 6.951173782348633, 9.659778594970703, -1.8907197713851929, 1.7323259115219116, -8.874245643615723, -6.521048069000244, 2.5252139568328857, 1.1836614608764648, -1.0202494859695435, 8.779181480407715, 1.02955961227417, -7.329140663146973, -1.4347283840179443, 0.9084786772727966, -5.406275749206543, 5.986858367919922, -7.228671550750732, 3.9483532905578613, 2.768101453781128, 5.159814357757568, 2.6771416664123535, -0.2935507297515869, 2.9347124099731445, 4.920399188995361, 0.24352514743804932], \"z\": [1.601455569267273, -1.4209764003753662, -2.365380048751831, -1.3440492153167725, 0.10409172624349594, -3.4933924674987793, -0.06025335565209389, -3.911652088165283, -1.4203966856002808, 3.492358446121216, -1.2439099550247192, 1.7691999673843384, -0.04666195437312126, 0.021124813705682755, -2.5790724754333496, 3.3733692169189453, 0.7085089683532715, 2.321798801422119, 3.149567127227783, -2.774657726287842, -0.6220132112503052, 0.057547785341739655, -1.8718931674957275, -1.0292751789093018, -1.2475827932357788, -0.7169173359870911, -0.28647133708000183, -0.9887204170227051, -1.6054962873458862, 1.478468656539917, 4.946630477905273, -2.7679789066314697, -0.8176590204238892, -1.0092053413391113, -2.0488088130950928, 4.946630477905273, -1.406713604927063, -0.40045320987701416, 0.40547066926956177, -1.7242534160614014, 0.8411160707473755, -2.1447110176086426, 1.762075424194336, 0.9012240171432495, 4.946630477905273, -1.3126943111419678, -2.1955761909484863, 0.310859739780426, 0.9486374258995056, 0.07179469615221024, 2.2723042964935303, -1.2761379480361938, -1.5139474868774414, -1.488094449043274, -0.7000367641448975, 2.123032808303833, 0.2547819912433624, 0.2215745598077774, 0.6351301074028015, 3.2717926502227783, 0.22060158848762512, -0.21877343952655792, 0.3612276017665863, -3.071540594100952, -0.6186994314193726, 0.18615609407424927, -1.5873749256134033, 2.2780954837799072, -1.8581005334854126, -2.0168631076812744, 1.2887482643127441, 2.5195415019989014, -3.0077192783355713, -1.0126482248306274, -2.481220006942749, -1.2554453611373901, -0.6643849015235901, -0.3700734078884125, 0.8545390367507935, -0.5278700590133667, -1.208970069885254, -4.527042388916016, 4.946630477905273, -0.997791588306427, -0.8625617623329163, 4.946630477905273, -1.0483896732330322, 0.8325436115264893, 0.41400450468063354, -0.9970138669013977, 0.37434279918670654, 0.16231393814086914, -0.3089365065097809, -1.294734001159668, 2.13845157623291, -0.636929988861084, 2.4860033988952637, 0.32017257809638977, -1.4040127992630005, -0.03140347823500633, 0.45475924015045166, -1.2309610843658447, 1.2848232984542847, -2.6171233654022217, -3.785447120666504, -1.2352465391159058, -1.5158826112747192, -0.9083749055862427, -1.3843967914581299, 2.3874928951263428, -2.3948416709899902, -3.487678289413452, -1.6054962873458862, 1.0704360008239746, 1.329455018043518, -2.0091447830200195, 1.3658169507980347, -3.1260602474212646, -3.0687544345855713, -0.5602169632911682, 0.13064391911029816, -1.0782893896102905, -2.7940785884857178, 0.7700697779655457, -0.5376777648925781, -2.3088200092315674, -2.888171434402466, -2.5484776496887207, -0.7823354005813599, 0.9372397661209106, -0.9113397598266602, -2.7495667934417725, 4.946630477905273, -1.850044846534729, 2.2465240955352783, 4.946630477905273, -2.629516363143921, -0.29679349064826965, -1.6025254726409912, 1.7923005819320679, 1.8217236995697021, 0.11595598608255386, -1.8437151908874512, -1.6622556447982788, -1.3458843231201172, -1.571401596069336, 2.064359664916992, -1.2317891120910645, -1.2463617324829102, -0.4332704246044159, -0.2625218629837036, -3.902905225753784, 2.294680118560791, 1.6537398099899292, -2.1473448276519775, -0.06363443285226822, 5.404824733734131, -1.3257694244384766, 0.6634051203727722, 0.3128427565097809, 0.833766520023346, 1.4999468326568604, 0.7684191465377808, -1.9153521060943604, -0.34270668029785156, -0.8090373277664185, 2.7724626064300537, 1.5070732831954956, -4.527041912078857, 2.8889901638031006, 1.431190848350525, -0.9293533563613892, -2.649322986602783, 2.3096845149993896, -4.527041912078857, -2.170755386352539, -2.5004966259002686, 3.7672061920166016, 2.1215217113494873, 0.6634907126426697, 2.2571794986724854, -1.9264179468154907, 5.404824733734131, 1.036181092262268, -2.630979299545288, -0.4162842929363251, 3.5283725261688232, 0.5581809878349304, 0.38562899827957153, -2.6862170696258545, -1.174749732017517, 1.8853840827941895, -0.19573363661766052, -0.9606509804725647, 0.12598459422588348, 2.3857944011688232, -1.7523497343063354, 1.0586284399032593, -0.5968359708786011, -3.0839476585388184]}],\n",
       "                        {\"height\": 800, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"width\": 1000, \"xaxis\": {\"zeroline\": false}, \"yaxis\": {\"zeroline\": false}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fc04a636-7cc3-4a94-bbe8-fadcf361fb07');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotly_plot_tsne(tsne_embeddings_3d, labels_3d, dimension=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"WED\"></a>[WED]\n",
    "        </td>\n",
    "        <td>\n",
    "The Illustrated Word2vec – Jay Alammar – Visualizing machine ....\" 27 März. 2019, http://jalammar.github.io/illustrated-word2vec/. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"SAM\"></a>[SAM]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Word2Vec Tutorial - The Skip-Gram Model · Chris McCormick.\" 19 Apr.. 2016, http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"SWS\"></a>[SWS]\n",
    "        </td>\n",
    "        <td>\n",
    "\"The Illustrated Word2vec – Jay Alammar – Visualizing machine ....\" 27 März. 2019, http://jalammar.github.io/illustrated-word2vec/. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"NCE\"></a>[NCE]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Notes on Noise Contrastive Estimation and Negative Sampling.\" http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"CSM\"></a>[CSM]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Cosine similarity - Wikipedia.\" https://en.wikipedia.org/wiki/Cosine_similarity. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"TSN\"></a>[TSN]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Visualizing data using t-SNE - SlideShare.\" https://www.slideshare.net/KyeongUkJang/visualizing-data-using-tsne-149111155. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"TDS\"></a>[TDS]\n",
    "        </td>\n",
    "        <td>\n",
    "\"Visualizing Data using t-SNE - Journal of Machine Learning Research.\" http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a id=\"HYP\"></a>[HYP]\n",
    "        </td>\n",
    "        <td>\n",
    "\"How to Use t-SNE Effectively - Distill.pub.\" 13 Okt.. 2016, https://distill.pub/2016/misread-tsne/. Aufgerufen am 22 Juni. 2019.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FDS_Word2Vec.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python3.6.7 (testpy3)",
   "language": "python",
   "name": "testpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
